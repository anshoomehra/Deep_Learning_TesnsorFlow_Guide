{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created By: Anshoo Mehra\n",
    "Dated: September 21st 2017\n",
    "\n",
    "# Tensorflow Guide Chronological Order ..\n",
    "\n",
    "All Credit to Udacity, all labs & explanation below is excerpt from class labs. Intent is to try all key examples & keep refrence to key highlights for future reference.\n",
    "\n",
    "I created this notebook for personal reference, however if this helps anyone in general please feel free to refer & consider Udacity policy/lceinses prior sharing ahead. I apologize documentation is fairly limited, it is just to the point to revise concepts than using this as primary guide to learn .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called hello_constant\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders (Can't be modified like as Constant shown above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    x = tf.placeholder(tf.int32)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # TODO: Feed the x tensor 123\n",
    "        output = sess.run(x, feed_dict={x:123})\n",
    "\n",
    "    return output\n",
    "\n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "123\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "vx = tf.Variable(5)\n",
    "\n",
    "# The tf.Variable class creates a tensor with an initial value that\n",
    "# can be modified, much like a normal Python variable. This tensor\n",
    "# stores its state in the session, so you must initialize the state\n",
    "# of the tensor manually. You'll use the tf.global_variables_initializer()\n",
    "# function to initialize the state of all the Variable tensors.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(vx))\n",
    "    print(sess.run(vx.assign(123)))\n",
    "    print(sess.run(vx.assign_add(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 6 10 2\n"
     ]
    }
   ],
   "source": [
    "x = tf.add(5, 2) #7\n",
    "y = tf.subtract(10, 4) # 6\n",
    "z = tf.multiply(2, 5)  # 10\n",
    "f = tf.div(4,2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        x_ = sess.run(x)\n",
    "        y_ = sess.run(y)\n",
    "        z_ = sess.run(z)\n",
    "        f_ = sess.run(f)\n",
    "\n",
    "print (x_, y_, z_, f_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "    #sess.run(tf.subtract(tf.constant(2.0),tf.constant(1))) \n",
    "\n",
    "## TRY TO UNCOMMENT ABOVE TO SEE THE ERROR MESSAGE..\n",
    "\n",
    "# Fails with ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int32:\n",
    "# That's because the constant 1 is an integer but the constant 2.0 \n",
    "# is a floating point value and subtract expects them to match.# In cases like these, you can either make sure your data is all \n",
    "# of the same type, or you can cast a value to another type. In this case,\n",
    "# converting the 2.0 to an integer before subtracting, like so, will give \n",
    "# the correct result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# In cases like these, you can either make sure your data is all \n",
    "# of the same type, or you can cast a value to another type. In this case,\n",
    "# converting the 2.0 to an integer before subtracting, like so, will give \n",
    "# the correct result:\n",
    "\n",
    "dummy = tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Math Function & Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TODO: Convert the following to TensorFlow:\n",
    "#x = 10\n",
    "#y = 2\n",
    "#z = x/y - 1\n",
    "\n",
    "# TODO: Print z from a session\n",
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.subtract(tf.div(x,y),tf.constant(1))\n",
    "f = tf.cast(z, tf.float32)\n",
    "## OR z = tf.div(x,y) - 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)\n",
    "    output = sess.run(f)\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming everyone knows Linear Combination Equation y = xW + b \n",
    "\n",
    "y = Logits\n",
    "x = Inputs\n",
    "W = Weights\n",
    "b = Bias\n",
    "\n",
    "Linear Equation will give is Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Softmax\n",
    "\n",
    "Softmax Function Convert Logits to Probabilities (All Probabilities Add to 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "        \n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65900117  0.24243298  0.09856589]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "\n",
    "    return output\n",
    "\n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding \n",
    "\n",
    "y = [ .5, .6, .9]\n",
    "\n",
    "y_one_hot_encoded = [ 0, 0, 1]\n",
    "\n",
    "So the hightest probability gets marked 1 and rest 0 as simple as that ...\n",
    "\n",
    "One Hot Encoding works really well but One problem with One Hot Encoding is that once classes grow to thousands or millions, vector becomes really large & very inefficient. This can be solved with embeddings, we will see that later.\n",
    "\n",
    "However, this method makes the process very simple, we have just 2 vectors, one vector contains probabilities of classes and other vector one-hot encodeding for labels. So if we have a way to measure distance between these two Vectors, that can help us classify and this process of measuring distance is called **Cross-Entropy.\n",
    "\n",
    "**Cross-Entropy will give us small distance for Right Class and higher distance for Incorrect Classes.**\n",
    "\n",
    "### Cross Entropy\n",
    "\n",
    "D(S,L) = - Σᵢ Lᵢ * log(Sᵢ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Process is called \" Multinomial Logistics Classification \"\n",
    "\n",
    "\n",
    "INPUT **--linear model--**> LOGITS > **--softmax--** > PROBABILITIES > **--cross_entropy--** < 1_HOT_LABELS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how to compute Cross Entropy in Tesnforflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "# ToDo: Print cross entropy from session\n",
    "cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={softmax: softmax_data, one_hot: one_hot_data}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost there, since most of us will be trying to train models on CPU, concept called mini-batching is something we must learn to not run short on memory and be stranded in middle of nowhere ..\n",
    "\n",
    "Mini-batching is a technique for training on subsets of the dataset instead of all the data at one time. This provides the ability to train a model, even if a computer lacks the memory to store the entire dataset.\n",
    "\n",
    "Mini-batching is computationally inefficient, since you can't calculate the loss simultaneously across all samples. However, this is a small price to pay in order to be able to run the model at all.\n",
    "\n",
    "It's also quite useful combined with SGD. The idea is to randomly shuffle the data at the start of each epoch, then create the mini-batches. For each mini-batch, you train the network weights with gradient descent. Since these batches are random, you're performing SGD with each batch.\n",
    "\n",
    "**TensorFlow Mini-batching**\n",
    "In order to use mini-batching, you must first divide your data into batches.\n",
    "\n",
    "Unfortunately, it's sometimes impossible to divide the data into batches of exactly equal size. For example, imagine you'd like to create batches of 128 samples each from a dataset of 1000 samples. Since 128 does not evenly divide into 1000, you'd wind up with 7 batches of 128 samples, and 1 batch of 104 samples. (7*128 + 1*104 = 1000)\n",
    "\n",
    "In that case, the size of the batches would vary, so you need to take advantage of TensorFlow's tf.placeholder() function to receive the varying batch sizes.\n",
    "\n",
    "Continuing the example, if each sample had n_input = 784 features and n_classes = 10 possible labels, the dimensions for features would be [None, n_input] and labels would be [None, n_classes].\n",
    "\n",
    "features = tf.placeholder(tf.float32, [**None**, n_input]) <br>\n",
    "labels = tf.placeholder(tf.float32, [**None**, n_classes])\n",
    "\n",
    "What does None do here?\n",
    "\n",
    "The None dimension is a placeholder for the batch size. At runtime, TensorFlow will accept any batch size greater than 0.\n",
    "\n",
    "Going back to our earlier example, this setup allows you to feed features and labels into the model as either the batches of 128 samples or the single batch of 104 samples.\n",
    "\n",
    "Let's understand it better with a example .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['F11', 'F12', 'F13', 'F14'],\n",
      "   ['F21', 'F22', 'F23', 'F24'],\n",
      "   ['F31', 'F32', 'F33', 'F34']],\n",
      "  [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]],\n",
      " [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "\n",
    "\n",
    "# 4 Samples of features\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "example_batches = batches(3, example_features, example_labels)\n",
    "\n",
    "pprint(example_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs \n",
    "\n",
    "With mini-batching the accuracy is low, but you probably know that you could train on the dataset more than once. You can train a model using the dataset multiple times.\n",
    "\n",
    "An **epoch** is a single forward and backward pass of the whole dataset. This is used to increase the accuracy of the model without requiring more data. This section will cover epochs in TensorFlow and how to choose the right number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, let's put it all together and run the below lab. \n",
    "\n",
    "**If it appear confusing, try to going to last commneted lab & understand one step at a time & if need be going back to above examples .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Handwritten Numbers (Image) Classification using MNIST database by applying ..\n",
    "### Linear Function / Logistics Regression ( y= xW + b )with Tensforflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the weights with random numbers from a normal distribution is good practice. Randomizing the weights helps the model from becoming stuck in the same place every time you train it.\n",
    "\n",
    "Similarly, choosing weights from a normal distribution prevents any one weight from overwhelming other weights. You'll use the tf.truncated_normal() function to generate random numbers from a normal distribution.\n",
    "\n",
    "The tf.truncated_normal() function returns a tensor with random values from a normal distribution whose magnitude is no more than 2 standard deviations from the mean.\n",
    "\n",
    "Since the weights are already helping prevent the model from getting stuck, you don't need to randomize the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    # TODO: Return weights\n",
    "    return tf.Variable(tf.random_normal([n_features, n_labels]))\n",
    "\n",
    "\n",
    "def biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    # TODO: Return biases\n",
    "    return tf.Variable(tf.random_normal[n_labels])\n",
    "\n",
    "\n",
    "def linear(input, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param input: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(input, w), b)\n",
    "\n",
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "    \n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0    - Cost: 1.78     Valid Accuracy: 0.727\n",
      "Epoch: 1    - Cost: 1.27     Valid Accuracy: 0.799\n",
      "Epoch: 2    - Cost: 1.06     Valid Accuracy: 0.824\n",
      "Epoch: 3    - Cost: 0.939    Valid Accuracy: 0.841\n",
      "Epoch: 4    - Cost: 0.85     Valid Accuracy: 0.852\n",
      "Epoch: 5    - Cost: 0.783    Valid Accuracy: 0.86 \n",
      "Epoch: 6    - Cost: 0.731    Valid Accuracy: 0.866\n",
      "Epoch: 7    - Cost: 0.69     Valid Accuracy: 0.87 \n",
      "Epoch: 8    - Cost: 0.656    Valid Accuracy: 0.874\n",
      "Epoch: 9    - Cost: 0.629    Valid Accuracy: 0.879\n",
      "Epoch: 10   - Cost: 0.607    Valid Accuracy: 0.881\n",
      "Epoch: 11   - Cost: 0.587    Valid Accuracy: 0.883\n",
      "Epoch: 12   - Cost: 0.57     Valid Accuracy: 0.886\n",
      "Epoch: 13   - Cost: 0.554    Valid Accuracy: 0.889\n",
      "Epoch: 14   - Cost: 0.54     Valid Accuracy: 0.89 \n",
      "Epoch: 15   - Cost: 0.528    Valid Accuracy: 0.892\n",
      "Epoch: 16   - Cost: 0.516    Valid Accuracy: 0.892\n",
      "Epoch: 17   - Cost: 0.505    Valid Accuracy: 0.892\n",
      "Epoch: 18   - Cost: 0.495    Valid Accuracy: 0.894\n",
      "Epoch: 19   - Cost: 0.486    Valid Accuracy: 0.896\n",
      "Epoch: 20   - Cost: 0.477    Valid Accuracy: 0.897\n",
      "Epoch: 21   - Cost: 0.468    Valid Accuracy: 0.897\n",
      "Epoch: 22   - Cost: 0.46     Valid Accuracy: 0.899\n",
      "Epoch: 23   - Cost: 0.453    Valid Accuracy: 0.9  \n",
      "Epoch: 24   - Cost: 0.446    Valid Accuracy: 0.9  \n",
      "Epoch: 25   - Cost: 0.439    Valid Accuracy: 0.901\n",
      "Epoch: 26   - Cost: 0.433    Valid Accuracy: 0.902\n",
      "Epoch: 27   - Cost: 0.427    Valid Accuracy: 0.902\n",
      "Epoch: 28   - Cost: 0.421    Valid Accuracy: 0.903\n",
      "Epoch: 29   - Cost: 0.415    Valid Accuracy: 0.904\n",
      "Epoch: 30   - Cost: 0.41     Valid Accuracy: 0.905\n",
      "Epoch: 31   - Cost: 0.405    Valid Accuracy: 0.906\n",
      "Epoch: 32   - Cost: 0.4      Valid Accuracy: 0.907\n",
      "Epoch: 33   - Cost: 0.395    Valid Accuracy: 0.907\n",
      "Epoch: 34   - Cost: 0.391    Valid Accuracy: 0.908\n",
      "Epoch: 35   - Cost: 0.386    Valid Accuracy: 0.908\n",
      "Epoch: 36   - Cost: 0.382    Valid Accuracy: 0.908\n",
      "Epoch: 37   - Cost: 0.378    Valid Accuracy: 0.908\n",
      "Epoch: 38   - Cost: 0.374    Valid Accuracy: 0.909\n",
      "Epoch: 39   - Cost: 0.371    Valid Accuracy: 0.91 \n",
      "Epoch: 40   - Cost: 0.367    Valid Accuracy: 0.91 \n",
      "Epoch: 41   - Cost: 0.364    Valid Accuracy: 0.911\n",
      "Epoch: 42   - Cost: 0.36     Valid Accuracy: 0.911\n",
      "Epoch: 43   - Cost: 0.357    Valid Accuracy: 0.911\n",
      "Epoch: 44   - Cost: 0.354    Valid Accuracy: 0.911\n",
      "Epoch: 45   - Cost: 0.351    Valid Accuracy: 0.912\n",
      "Epoch: 46   - Cost: 0.348    Valid Accuracy: 0.912\n",
      "Epoch: 47   - Cost: 0.345    Valid Accuracy: 0.912\n",
      "Epoch: 48   - Cost: 0.343    Valid Accuracy: 0.912\n",
      "Epoch: 49   - Cost: 0.34     Valid Accuracy: 0.912\n",
      "Epoch: 50   - Cost: 0.338    Valid Accuracy: 0.912\n",
      "Epoch: 51   - Cost: 0.335    Valid Accuracy: 0.913\n",
      "Epoch: 52   - Cost: 0.333    Valid Accuracy: 0.913\n",
      "Epoch: 53   - Cost: 0.33     Valid Accuracy: 0.912\n",
      "Epoch: 54   - Cost: 0.328    Valid Accuracy: 0.913\n",
      "Epoch: 55   - Cost: 0.326    Valid Accuracy: 0.913\n",
      "Epoch: 56   - Cost: 0.324    Valid Accuracy: 0.913\n",
      "Epoch: 57   - Cost: 0.322    Valid Accuracy: 0.913\n",
      "Epoch: 58   - Cost: 0.32     Valid Accuracy: 0.913\n",
      "Epoch: 59   - Cost: 0.318    Valid Accuracy: 0.913\n",
      "Epoch: 60   - Cost: 0.316    Valid Accuracy: 0.914\n",
      "Epoch: 61   - Cost: 0.314    Valid Accuracy: 0.914\n",
      "Epoch: 62   - Cost: 0.312    Valid Accuracy: 0.914\n",
      "Epoch: 63   - Cost: 0.311    Valid Accuracy: 0.914\n",
      "Epoch: 64   - Cost: 0.309    Valid Accuracy: 0.915\n",
      "Epoch: 65   - Cost: 0.307    Valid Accuracy: 0.915\n",
      "Epoch: 66   - Cost: 0.306    Valid Accuracy: 0.915\n",
      "Epoch: 67   - Cost: 0.304    Valid Accuracy: 0.915\n",
      "Epoch: 68   - Cost: 0.303    Valid Accuracy: 0.915\n",
      "Epoch: 69   - Cost: 0.301    Valid Accuracy: 0.915\n",
      "Epoch: 70   - Cost: 0.3      Valid Accuracy: 0.915\n",
      "Epoch: 71   - Cost: 0.298    Valid Accuracy: 0.916\n",
      "Epoch: 72   - Cost: 0.297    Valid Accuracy: 0.916\n",
      "Epoch: 73   - Cost: 0.296    Valid Accuracy: 0.916\n",
      "Epoch: 74   - Cost: 0.294    Valid Accuracy: 0.916\n",
      "Epoch: 75   - Cost: 0.293    Valid Accuracy: 0.916\n",
      "Epoch: 76   - Cost: 0.292    Valid Accuracy: 0.917\n",
      "Epoch: 77   - Cost: 0.291    Valid Accuracy: 0.917\n",
      "Epoch: 78   - Cost: 0.289    Valid Accuracy: 0.917\n",
      "Epoch: 79   - Cost: 0.288    Valid Accuracy: 0.917\n",
      "Epoch: 80   - Cost: 0.287    Valid Accuracy: 0.917\n",
      "Epoch: 81   - Cost: 0.286    Valid Accuracy: 0.917\n",
      "Epoch: 82   - Cost: 0.285    Valid Accuracy: 0.917\n",
      "Epoch: 83   - Cost: 0.284    Valid Accuracy: 0.917\n",
      "Epoch: 84   - Cost: 0.283    Valid Accuracy: 0.917\n",
      "Epoch: 85   - Cost: 0.282    Valid Accuracy: 0.917\n",
      "Epoch: 86   - Cost: 0.281    Valid Accuracy: 0.918\n",
      "Epoch: 87   - Cost: 0.28     Valid Accuracy: 0.918\n",
      "Epoch: 88   - Cost: 0.279    Valid Accuracy: 0.917\n",
      "Epoch: 89   - Cost: 0.278    Valid Accuracy: 0.917\n",
      "Epoch: 90   - Cost: 0.277    Valid Accuracy: 0.917\n",
      "Epoch: 91   - Cost: 0.276    Valid Accuracy: 0.918\n",
      "Epoch: 92   - Cost: 0.275    Valid Accuracy: 0.917\n",
      "Epoch: 93   - Cost: 0.274    Valid Accuracy: 0.918\n",
      "Epoch: 94   - Cost: 0.274    Valid Accuracy: 0.918\n",
      "Epoch: 95   - Cost: 0.273    Valid Accuracy: 0.918\n",
      "Epoch: 96   - Cost: 0.272    Valid Accuracy: 0.918\n",
      "Epoch: 97   - Cost: 0.271    Valid Accuracy: 0.919\n",
      "Epoch: 98   - Cost: 0.27     Valid Accuracy: 0.919\n",
      "Epoch: 99   - Cost: 0.27     Valid Accuracy: 0.919\n",
      "Epoch: 100  - Cost: 0.269    Valid Accuracy: 0.919\n",
      "Epoch: 101  - Cost: 0.268    Valid Accuracy: 0.919\n",
      "Epoch: 102  - Cost: 0.267    Valid Accuracy: 0.919\n",
      "Epoch: 103  - Cost: 0.267    Valid Accuracy: 0.919\n",
      "Epoch: 104  - Cost: 0.266    Valid Accuracy: 0.919\n",
      "Epoch: 105  - Cost: 0.265    Valid Accuracy: 0.919\n",
      "Epoch: 106  - Cost: 0.264    Valid Accuracy: 0.919\n",
      "Epoch: 107  - Cost: 0.264    Valid Accuracy: 0.919\n",
      "Epoch: 108  - Cost: 0.263    Valid Accuracy: 0.919\n",
      "Epoch: 109  - Cost: 0.262    Valid Accuracy: 0.919\n",
      "Epoch: 110  - Cost: 0.262    Valid Accuracy: 0.919\n",
      "Epoch: 111  - Cost: 0.261    Valid Accuracy: 0.919\n",
      "Epoch: 112  - Cost: 0.261    Valid Accuracy: 0.919\n",
      "Epoch: 113  - Cost: 0.26     Valid Accuracy: 0.919\n",
      "Epoch: 114  - Cost: 0.259    Valid Accuracy: 0.919\n",
      "Epoch: 115  - Cost: 0.259    Valid Accuracy: 0.919\n",
      "Epoch: 116  - Cost: 0.258    Valid Accuracy: 0.919\n",
      "Epoch: 117  - Cost: 0.258    Valid Accuracy: 0.919\n",
      "Epoch: 118  - Cost: 0.257    Valid Accuracy: 0.919\n",
      "Epoch: 119  - Cost: 0.256    Valid Accuracy: 0.919\n",
      "Epoch: 120  - Cost: 0.256    Valid Accuracy: 0.919\n",
      "Epoch: 121  - Cost: 0.255    Valid Accuracy: 0.919\n",
      "Epoch: 122  - Cost: 0.255    Valid Accuracy: 0.919\n",
      "Epoch: 123  - Cost: 0.254    Valid Accuracy: 0.919\n",
      "Epoch: 124  - Cost: 0.254    Valid Accuracy: 0.919\n",
      "Epoch: 125  - Cost: 0.253    Valid Accuracy: 0.919\n",
      "Epoch: 126  - Cost: 0.253    Valid Accuracy: 0.919\n",
      "Epoch: 127  - Cost: 0.252    Valid Accuracy: 0.92 \n",
      "Epoch: 128  - Cost: 0.252    Valid Accuracy: 0.92 \n",
      "Epoch: 129  - Cost: 0.251    Valid Accuracy: 0.92 \n",
      "Epoch: 130  - Cost: 0.251    Valid Accuracy: 0.92 \n",
      "Epoch: 131  - Cost: 0.25     Valid Accuracy: 0.92 \n",
      "Epoch: 132  - Cost: 0.25     Valid Accuracy: 0.92 \n",
      "Epoch: 133  - Cost: 0.249    Valid Accuracy: 0.92 \n",
      "Epoch: 134  - Cost: 0.249    Valid Accuracy: 0.92 \n",
      "Epoch: 135  - Cost: 0.248    Valid Accuracy: 0.92 \n",
      "Epoch: 136  - Cost: 0.248    Valid Accuracy: 0.92 \n",
      "Epoch: 137  - Cost: 0.247    Valid Accuracy: 0.92 \n",
      "Epoch: 138  - Cost: 0.247    Valid Accuracy: 0.92 \n",
      "Epoch: 139  - Cost: 0.246    Valid Accuracy: 0.921\n",
      "Epoch: 140  - Cost: 0.246    Valid Accuracy: 0.921\n",
      "Epoch: 141  - Cost: 0.246    Valid Accuracy: 0.921\n",
      "Epoch: 142  - Cost: 0.245    Valid Accuracy: 0.922\n",
      "Epoch: 143  - Cost: 0.245    Valid Accuracy: 0.922\n",
      "Epoch: 144  - Cost: 0.244    Valid Accuracy: 0.922\n",
      "Epoch: 145  - Cost: 0.244    Valid Accuracy: 0.922\n",
      "Epoch: 146  - Cost: 0.244    Valid Accuracy: 0.922\n",
      "Epoch: 147  - Cost: 0.243    Valid Accuracy: 0.922\n",
      "Epoch: 148  - Cost: 0.243    Valid Accuracy: 0.922\n",
      "Epoch: 149  - Cost: 0.242    Valid Accuracy: 0.922\n",
      "Epoch: 150  - Cost: 0.242    Valid Accuracy: 0.922\n",
      "Epoch: 151  - Cost: 0.242    Valid Accuracy: 0.922\n",
      "Epoch: 152  - Cost: 0.241    Valid Accuracy: 0.921\n",
      "Epoch: 153  - Cost: 0.241    Valid Accuracy: 0.921\n",
      "Epoch: 154  - Cost: 0.24     Valid Accuracy: 0.921\n",
      "Epoch: 155  - Cost: 0.24     Valid Accuracy: 0.921\n",
      "Epoch: 156  - Cost: 0.24     Valid Accuracy: 0.921\n",
      "Epoch: 157  - Cost: 0.239    Valid Accuracy: 0.922\n",
      "Epoch: 158  - Cost: 0.239    Valid Accuracy: 0.921\n",
      "Epoch: 159  - Cost: 0.239    Valid Accuracy: 0.921\n",
      "Epoch: 160  - Cost: 0.238    Valid Accuracy: 0.921\n",
      "Epoch: 161  - Cost: 0.238    Valid Accuracy: 0.921\n",
      "Epoch: 162  - Cost: 0.238    Valid Accuracy: 0.922\n",
      "Epoch: 163  - Cost: 0.237    Valid Accuracy: 0.922\n",
      "Epoch: 164  - Cost: 0.237    Valid Accuracy: 0.922\n",
      "Epoch: 165  - Cost: 0.237    Valid Accuracy: 0.921\n",
      "Epoch: 166  - Cost: 0.236    Valid Accuracy: 0.921\n",
      "Epoch: 167  - Cost: 0.236    Valid Accuracy: 0.922\n",
      "Epoch: 168  - Cost: 0.236    Valid Accuracy: 0.922\n",
      "Epoch: 169  - Cost: 0.235    Valid Accuracy: 0.922\n",
      "Epoch: 170  - Cost: 0.235    Valid Accuracy: 0.922\n",
      "Epoch: 171  - Cost: 0.235    Valid Accuracy: 0.922\n",
      "Epoch: 172  - Cost: 0.234    Valid Accuracy: 0.922\n",
      "Epoch: 173  - Cost: 0.234    Valid Accuracy: 0.922\n",
      "Epoch: 174  - Cost: 0.234    Valid Accuracy: 0.922\n",
      "Epoch: 175  - Cost: 0.233    Valid Accuracy: 0.922\n",
      "Epoch: 176  - Cost: 0.233    Valid Accuracy: 0.922\n",
      "Epoch: 177  - Cost: 0.233    Valid Accuracy: 0.922\n",
      "Epoch: 178  - Cost: 0.232    Valid Accuracy: 0.922\n",
      "Epoch: 179  - Cost: 0.232    Valid Accuracy: 0.922\n",
      "Epoch: 180  - Cost: 0.232    Valid Accuracy: 0.922\n",
      "Epoch: 181  - Cost: 0.232    Valid Accuracy: 0.923\n",
      "Epoch: 182  - Cost: 0.231    Valid Accuracy: 0.923\n",
      "Epoch: 183  - Cost: 0.231    Valid Accuracy: 0.923\n",
      "Epoch: 184  - Cost: 0.231    Valid Accuracy: 0.923\n",
      "Epoch: 185  - Cost: 0.23     Valid Accuracy: 0.923\n",
      "Epoch: 186  - Cost: 0.23     Valid Accuracy: 0.923\n",
      "Epoch: 187  - Cost: 0.23     Valid Accuracy: 0.922\n",
      "Epoch: 188  - Cost: 0.23     Valid Accuracy: 0.922\n",
      "Epoch: 189  - Cost: 0.229    Valid Accuracy: 0.923\n",
      "Epoch: 190  - Cost: 0.229    Valid Accuracy: 0.923\n",
      "Epoch: 191  - Cost: 0.229    Valid Accuracy: 0.923\n",
      "Epoch: 192  - Cost: 0.229    Valid Accuracy: 0.923\n",
      "Epoch: 193  - Cost: 0.228    Valid Accuracy: 0.923\n",
      "Epoch: 194  - Cost: 0.228    Valid Accuracy: 0.922\n",
      "Epoch: 195  - Cost: 0.228    Valid Accuracy: 0.923\n",
      "Epoch: 196  - Cost: 0.228    Valid Accuracy: 0.923\n",
      "Epoch: 197  - Cost: 0.227    Valid Accuracy: 0.923\n",
      "Epoch: 198  - Cost: 0.227    Valid Accuracy: 0.923\n",
      "Epoch: 199  - Cost: 0.227    Valid Accuracy: 0.923\n",
      "Epoch: 200  - Cost: 0.227    Valid Accuracy: 0.923\n",
      "Epoch: 201  - Cost: 0.226    Valid Accuracy: 0.923\n",
      "Epoch: 202  - Cost: 0.226    Valid Accuracy: 0.923\n",
      "Epoch: 203  - Cost: 0.226    Valid Accuracy: 0.923\n",
      "Epoch: 204  - Cost: 0.226    Valid Accuracy: 0.923\n",
      "Epoch: 205  - Cost: 0.225    Valid Accuracy: 0.923\n",
      "Epoch: 206  - Cost: 0.225    Valid Accuracy: 0.923\n",
      "Epoch: 207  - Cost: 0.225    Valid Accuracy: 0.923\n",
      "Epoch: 208  - Cost: 0.225    Valid Accuracy: 0.923\n",
      "Epoch: 209  - Cost: 0.224    Valid Accuracy: 0.923\n",
      "Epoch: 210  - Cost: 0.224    Valid Accuracy: 0.923\n",
      "Epoch: 211  - Cost: 0.224    Valid Accuracy: 0.923\n",
      "Epoch: 212  - Cost: 0.224    Valid Accuracy: 0.923\n",
      "Epoch: 213  - Cost: 0.223    Valid Accuracy: 0.923\n",
      "Epoch: 214  - Cost: 0.223    Valid Accuracy: 0.923\n",
      "Epoch: 215  - Cost: 0.223    Valid Accuracy: 0.923\n",
      "Epoch: 216  - Cost: 0.223    Valid Accuracy: 0.923\n",
      "Epoch: 217  - Cost: 0.223    Valid Accuracy: 0.923\n",
      "Epoch: 218  - Cost: 0.222    Valid Accuracy: 0.923\n",
      "Epoch: 219  - Cost: 0.222    Valid Accuracy: 0.923\n",
      "Epoch: 220  - Cost: 0.222    Valid Accuracy: 0.923\n",
      "Epoch: 221  - Cost: 0.222    Valid Accuracy: 0.924\n",
      "Epoch: 222  - Cost: 0.221    Valid Accuracy: 0.924\n",
      "Epoch: 223  - Cost: 0.221    Valid Accuracy: 0.924\n",
      "Epoch: 224  - Cost: 0.221    Valid Accuracy: 0.924\n",
      "Epoch: 225  - Cost: 0.221    Valid Accuracy: 0.924\n",
      "Epoch: 226  - Cost: 0.221    Valid Accuracy: 0.924\n",
      "Epoch: 227  - Cost: 0.22     Valid Accuracy: 0.924\n",
      "Epoch: 228  - Cost: 0.22     Valid Accuracy: 0.924\n",
      "Epoch: 229  - Cost: 0.22     Valid Accuracy: 0.924\n",
      "Epoch: 230  - Cost: 0.22     Valid Accuracy: 0.924\n",
      "Epoch: 231  - Cost: 0.22     Valid Accuracy: 0.924\n",
      "Epoch: 232  - Cost: 0.219    Valid Accuracy: 0.924\n",
      "Epoch: 233  - Cost: 0.219    Valid Accuracy: 0.924\n",
      "Epoch: 234  - Cost: 0.219    Valid Accuracy: 0.924\n",
      "Epoch: 235  - Cost: 0.219    Valid Accuracy: 0.924\n",
      "Epoch: 236  - Cost: 0.219    Valid Accuracy: 0.924\n",
      "Epoch: 237  - Cost: 0.218    Valid Accuracy: 0.924\n",
      "Epoch: 238  - Cost: 0.218    Valid Accuracy: 0.924\n",
      "Epoch: 239  - Cost: 0.218    Valid Accuracy: 0.924\n",
      "Epoch: 240  - Cost: 0.218    Valid Accuracy: 0.924\n",
      "Epoch: 241  - Cost: 0.218    Valid Accuracy: 0.924\n",
      "Epoch: 242  - Cost: 0.218    Valid Accuracy: 0.924\n",
      "Epoch: 243  - Cost: 0.217    Valid Accuracy: 0.924\n",
      "Epoch: 244  - Cost: 0.217    Valid Accuracy: 0.924\n",
      "Epoch: 245  - Cost: 0.217    Valid Accuracy: 0.924\n",
      "Epoch: 246  - Cost: 0.217    Valid Accuracy: 0.924\n",
      "Epoch: 247  - Cost: 0.217    Valid Accuracy: 0.924\n",
      "Epoch: 248  - Cost: 0.216    Valid Accuracy: 0.924\n",
      "Epoch: 249  - Cost: 0.216    Valid Accuracy: 0.924\n",
      "Epoch: 250  - Cost: 0.216    Valid Accuracy: 0.924\n",
      "Epoch: 251  - Cost: 0.216    Valid Accuracy: 0.924\n",
      "Epoch: 252  - Cost: 0.216    Valid Accuracy: 0.923\n",
      "Epoch: 253  - Cost: 0.216    Valid Accuracy: 0.923\n",
      "Epoch: 254  - Cost: 0.215    Valid Accuracy: 0.923\n",
      "Epoch: 255  - Cost: 0.215    Valid Accuracy: 0.924\n",
      "Epoch: 256  - Cost: 0.215    Valid Accuracy: 0.924\n",
      "Epoch: 257  - Cost: 0.215    Valid Accuracy: 0.924\n",
      "Epoch: 258  - Cost: 0.215    Valid Accuracy: 0.924\n",
      "Epoch: 259  - Cost: 0.215    Valid Accuracy: 0.923\n",
      "Epoch: 260  - Cost: 0.214    Valid Accuracy: 0.923\n",
      "Epoch: 261  - Cost: 0.214    Valid Accuracy: 0.923\n",
      "Epoch: 262  - Cost: 0.214    Valid Accuracy: 0.923\n",
      "Epoch: 263  - Cost: 0.214    Valid Accuracy: 0.923\n",
      "Epoch: 264  - Cost: 0.214    Valid Accuracy: 0.923\n",
      "Epoch: 265  - Cost: 0.214    Valid Accuracy: 0.923\n",
      "Epoch: 266  - Cost: 0.213    Valid Accuracy: 0.923\n",
      "Epoch: 267  - Cost: 0.213    Valid Accuracy: 0.923\n",
      "Epoch: 268  - Cost: 0.213    Valid Accuracy: 0.923\n",
      "Epoch: 269  - Cost: 0.213    Valid Accuracy: 0.923\n",
      "Epoch: 270  - Cost: 0.213    Valid Accuracy: 0.923\n",
      "Epoch: 271  - Cost: 0.213    Valid Accuracy: 0.924\n",
      "Epoch: 272  - Cost: 0.213    Valid Accuracy: 0.924\n",
      "Epoch: 273  - Cost: 0.212    Valid Accuracy: 0.924\n",
      "Epoch: 274  - Cost: 0.212    Valid Accuracy: 0.924\n",
      "Epoch: 275  - Cost: 0.212    Valid Accuracy: 0.924\n",
      "Epoch: 276  - Cost: 0.212    Valid Accuracy: 0.924\n",
      "Epoch: 277  - Cost: 0.212    Valid Accuracy: 0.924\n",
      "Epoch: 278  - Cost: 0.212    Valid Accuracy: 0.924\n",
      "Epoch: 279  - Cost: 0.211    Valid Accuracy: 0.924\n",
      "Epoch: 280  - Cost: 0.211    Valid Accuracy: 0.924\n",
      "Epoch: 281  - Cost: 0.211    Valid Accuracy: 0.924\n",
      "Epoch: 282  - Cost: 0.211    Valid Accuracy: 0.925\n",
      "Epoch: 283  - Cost: 0.211    Valid Accuracy: 0.924\n",
      "Epoch: 284  - Cost: 0.211    Valid Accuracy: 0.924\n",
      "Epoch: 285  - Cost: 0.211    Valid Accuracy: 0.924\n",
      "Epoch: 286  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 287  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 288  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 289  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 290  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 291  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 292  - Cost: 0.21     Valid Accuracy: 0.924\n",
      "Epoch: 293  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 294  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 295  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 296  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 297  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 298  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 299  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 300  - Cost: 0.209    Valid Accuracy: 0.924\n",
      "Epoch: 301  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 302  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 303  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 304  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 305  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 306  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 307  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 308  - Cost: 0.208    Valid Accuracy: 0.924\n",
      "Epoch: 309  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 310  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 311  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 312  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 313  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 314  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 315  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 316  - Cost: 0.207    Valid Accuracy: 0.924\n",
      "Epoch: 317  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 318  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 319  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 320  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 321  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 322  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 323  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 324  - Cost: 0.206    Valid Accuracy: 0.924\n",
      "Epoch: 325  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 326  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 327  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 328  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 329  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 330  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 331  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 332  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 333  - Cost: 0.205    Valid Accuracy: 0.924\n",
      "Epoch: 334  - Cost: 0.204    Valid Accuracy: 0.924\n",
      "Epoch: 335  - Cost: 0.204    Valid Accuracy: 0.924\n",
      "Epoch: 336  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 337  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 338  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 339  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 340  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 341  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 342  - Cost: 0.204    Valid Accuracy: 0.925\n",
      "Epoch: 343  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 344  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 345  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 346  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 347  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 348  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 349  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 350  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 351  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 352  - Cost: 0.203    Valid Accuracy: 0.925\n",
      "Epoch: 353  - Cost: 0.202    Valid Accuracy: 0.925\n",
      "Epoch: 354  - Cost: 0.202    Valid Accuracy: 0.925\n",
      "Epoch: 355  - Cost: 0.202    Valid Accuracy: 0.925\n",
      "Epoch: 356  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 357  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 358  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 359  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 360  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 361  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 362  - Cost: 0.202    Valid Accuracy: 0.924\n",
      "Epoch: 363  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 364  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 365  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 366  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 367  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 368  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 369  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 370  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 371  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 372  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 373  - Cost: 0.201    Valid Accuracy: 0.924\n",
      "Epoch: 374  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 375  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 376  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 377  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 378  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 379  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 380  - Cost: 0.2      Valid Accuracy: 0.924\n",
      "Epoch: 381  - Cost: 0.2      Valid Accuracy: 0.925\n",
      "Epoch: 382  - Cost: 0.2      Valid Accuracy: 0.925\n",
      "Epoch: 383  - Cost: 0.2      Valid Accuracy: 0.925\n",
      "Epoch: 384  - Cost: 0.2      Valid Accuracy: 0.925\n",
      "Epoch: 385  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 386  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 387  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 388  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 389  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 390  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 391  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 392  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 393  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 394  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 395  - Cost: 0.199    Valid Accuracy: 0.925\n",
      "Epoch: 396  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 397  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 398  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 399  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 400  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 401  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 402  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 403  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 404  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 405  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 406  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 407  - Cost: 0.198    Valid Accuracy: 0.925\n",
      "Epoch: 408  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 409  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 410  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 411  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 412  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 413  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 414  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 415  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 416  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 417  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 418  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 419  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 420  - Cost: 0.197    Valid Accuracy: 0.925\n",
      "Epoch: 421  - Cost: 0.196    Valid Accuracy: 0.925\n",
      "Epoch: 422  - Cost: 0.196    Valid Accuracy: 0.925\n",
      "Epoch: 423  - Cost: 0.196    Valid Accuracy: 0.925\n",
      "Epoch: 424  - Cost: 0.196    Valid Accuracy: 0.925\n",
      "Epoch: 425  - Cost: 0.196    Valid Accuracy: 0.925\n",
      "Epoch: 426  - Cost: 0.196    Valid Accuracy: 0.925\n",
      "Epoch: 427  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 428  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 429  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 430  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 431  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 432  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 433  - Cost: 0.196    Valid Accuracy: 0.926\n",
      "Epoch: 434  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 435  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 436  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 437  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 438  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 439  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 440  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 441  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 442  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 443  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 444  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 445  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 446  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 447  - Cost: 0.195    Valid Accuracy: 0.926\n",
      "Epoch: 448  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 449  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 450  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 451  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 452  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 453  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 454  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 455  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 456  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 457  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 458  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 459  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 460  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 461  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 462  - Cost: 0.194    Valid Accuracy: 0.926\n",
      "Epoch: 463  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 464  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 465  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 466  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 467  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 468  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 469  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 470  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 471  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 472  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 473  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 474  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 475  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 476  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 477  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 478  - Cost: 0.193    Valid Accuracy: 0.926\n",
      "Epoch: 479  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 480  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 481  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 482  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 483  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 484  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 485  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 486  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 487  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 488  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 489  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 490  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 491  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 492  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 493  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 494  - Cost: 0.192    Valid Accuracy: 0.926\n",
      "Epoch: 495  - Cost: 0.191    Valid Accuracy: 0.926\n",
      "Epoch: 496  - Cost: 0.191    Valid Accuracy: 0.926\n",
      "Epoch: 497  - Cost: 0.191    Valid Accuracy: 0.926\n",
      "Epoch: 498  - Cost: 0.191    Valid Accuracy: 0.926\n",
      "Epoch: 499  - Cost: 0.191    Valid Accuracy: 0.926\n",
      "Test Accuracy: 0.92330002784729\n"
     ]
    }
   ],
   "source": [
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "learn_rate = 0.09\n",
    "\n",
    "train_batches = batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### SOMETHING TO TRY TO GET HANG OF IT ... IF ABOVE IS TOO COMPLEX .. \n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# ## Above Block Helper Functions can be modlarized to separate file .. if so\n",
    "# ## below import\n",
    "# #from quiz import weights, biases, linear \n",
    "\n",
    "# def mnist_features_labels(n_labels):\n",
    "#     \"\"\"\n",
    "#     Gets the first <n> labels from the MNIST dataset\n",
    "#     :param n_labels: Number of labels to use\n",
    "#     :return: Tuple of feature list and label list\n",
    "#     \"\"\"\n",
    "#     mnist_features = []\n",
    "#     mnist_labels = []\n",
    "\n",
    "#     #mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "#     mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "#     # In order to make quizzes run faster, we're only looking at 10000 images\n",
    "#     for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n",
    "        \n",
    "#         #print (\"Before Checking\", mnist_feature, mnist_label)\n",
    "        \n",
    "#         # Add features and labels if it's for the first <n>th labels\n",
    "#         # In this eample since n_labels is 3, ie. features & labels for only numbers 0, 1, 2 will be retrieved\n",
    "#         # from dataset remember each feature is 28*28 image and is flattened to 784 (1*784 Matrix)\n",
    "#         if mnist_label[:n_labels].any():\n",
    "#             #If Label is any of top 3, add feature for current index record\n",
    "#             mnist_features.append(mnist_feature)\n",
    "#             #If Label is any of top 3, add label values for just top 3 indexes, we do not need rest as we are not\n",
    "#             # looking to classify anything after number 3..\n",
    "#             mnist_labels.append(mnist_label[:n_labels])\n",
    "\n",
    "#     return mnist_features, mnist_labels\n",
    "\n",
    "\n",
    "# # Number of features (28*28 image is 784 features)\n",
    "# n_features = 784\n",
    "# # Number of labels\n",
    "# n_labels = 3\n",
    "\n",
    "# # Features and Labels\n",
    "# features = tf.placeholder(tf.float32)\n",
    "# labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# # Weights and Biases\n",
    "# w = weights(n_features, n_labels)\n",
    "# b = biases(n_labels)\n",
    "\n",
    "# # Linear Function xW + b\n",
    "# logits = linear(features, w, b)\n",
    "\n",
    "\n",
    "# # Training data\n",
    "# train_features, train_labels = mnist_features_labels(n_labels)\n",
    "\n",
    "# with tf.Session() as session:\n",
    "#     session.run(tf.global_variables_initializer())\n",
    "\n",
    "#     # Softmax (Thus far we studied Sigmoid, it will be good to google understanding differences between them)\n",
    "#     prediction = tf.nn.softmax(logits)\n",
    "\n",
    "#     # Cross entropy\n",
    "#     # This quantifies how far off the predictions were.\n",
    "#     # You'll learn more about this in future lessons.\n",
    "#     cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "#     # Training loss\n",
    "#     # You'll learn more about this in future lessons.\n",
    "#     loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#     # Rate at which the weights are changed\n",
    "#     # You'll learn more about this in future lessons.\n",
    "#     learning_rate = 0.08\n",
    "\n",
    "#     # Gradient Descent\n",
    "#     # This is the method used to train the model\n",
    "#     # You'll learn more about this in future lessons.\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#     # Run optimizer and get loss\n",
    "#     _, l = session.run(\n",
    "#         [optimizer, loss],\n",
    "#         feed_dict={features: train_features, labels: train_labels})\n",
    "\n",
    "# # Print loss\n",
    "# print('Loss: {}'.format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU (Rectified Linear Units) \n",
    "\n",
    "So far we have build classifier which is very robust for Linear Operations but are limited and can't perform non-linear operations example, additive operation X1 + X2 can be performed but X1 * X2 can't be performed.\n",
    "\n",
    "Being linear in nature it has many advantages:\n",
    "- Big Matrix multiplies is exactly what GPUs are designed for, so can run fairly efficiently.\n",
    "- Linear Operations are very stable, we can mathamatically demonstrate that small changes in input reflect small changes in output & will not spike to large outputs arbitrarily.\n",
    "- Derivaties are nice as well for Linear Functions, they demostrate constant output & hence super stable.\n",
    "\n",
    "**So we would like to have our parameters be inside big linear functions but we would also like our Model to perform non-linear operations to solve more complex problems ..**  \n",
    "\n",
    "One of the ways we can introduce non-linearalities to our model is by injecting RELUs to the our model. RELUs are fairly simple, they are linear when x >0 and 0 everywhere else ..Also, when x < 0 derivative is also, and when x > 0 derivative is constant.\n",
    "\n",
    "So to implement this in practice without complicating what we have studied..\n",
    "\n",
    "We will take our INPUTS+WEIGHT+BIAS >>FEED>> RELU LAYERS >>FEED>> CLASSIFIER ..\n",
    "\n",
    "This simple approach helps us make the whole model non-linear && as added advantage, we will have another parameter to fine tune, i.e. RELU LAYERS (denoted as H).. This is just simple example we can make these layers as deep we want .. \n",
    "\n",
    "The above network example applies RELU function to the hidden_layer, effectively turning off any negative weights and acting like an on/off switch. Adding additional layers, like the output layer, after an activation function turns the model into a nonlinear function. This nonlinearity allows the network to solve more complex problems.\n",
    "\n",
    "**Congrats, with this we will build our first Neural Network using Tensorflow..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.11000013   8.44000053]\n",
      " [  0.           0.        ]\n",
      " [ 24.01000214  38.23999786]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "output = None\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(logits))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With concepts cleared out, let's re-build classifier we build earlier to Classify Letters over MNIST database using Deep Network with RELUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost= 1.249434471\n",
      "Epoch: 0002 cost= 1.622592926\n",
      "Epoch: 0003 cost= 0.485644400\n",
      "Epoch: 0004 cost= 0.066994786\n",
      "Epoch: 0005 cost= 0.506596088\n",
      "Epoch: 0006 cost= 0.166660339\n",
      "Epoch: 0007 cost= 0.256506383\n",
      "Epoch: 0008 cost= 0.263688326\n",
      "Epoch: 0009 cost= 0.333746374\n",
      "Epoch: 0010 cost= 0.026917888\n",
      "Epoch: 0011 cost= 0.496636808\n",
      "Epoch: 0012 cost= 0.096257575\n",
      "Epoch: 0013 cost= 0.130075336\n",
      "Epoch: 0014 cost= 0.016562125\n",
      "Epoch: 0015 cost= 0.442557871\n",
      "Epoch: 0016 cost= 0.000909301\n",
      "Epoch: 0017 cost= 0.050810650\n",
      "Epoch: 0018 cost= 0.119163290\n",
      "Epoch: 0019 cost= 0.095426545\n",
      "Epoch: 0020 cost= 0.048861191\n",
      "Epoch: 0021 cost= 0.032808296\n",
      "Epoch: 0022 cost= 0.000551221\n",
      "Epoch: 0023 cost= 0.004125504\n",
      "Epoch: 0024 cost= 0.014760466\n",
      "Epoch: 0025 cost= 0.011153132\n",
      "Epoch: 0026 cost= 0.075658090\n",
      "Epoch: 0027 cost= 0.005784245\n",
      "Epoch: 0028 cost= 0.007925835\n",
      "Epoch: 0029 cost= 0.003174786\n",
      "Epoch: 0030 cost= 0.003076249\n",
      "Epoch: 0031 cost= 0.029149173\n",
      "Epoch: 0032 cost= 0.030580617\n",
      "Epoch: 0033 cost= 0.004655944\n",
      "Epoch: 0034 cost= 0.013816878\n",
      "Epoch: 0035 cost= 0.001643364\n",
      "Epoch: 0036 cost= 0.003914074\n",
      "Epoch: 0037 cost= 0.008597786\n",
      "Epoch: 0038 cost= 0.002397714\n",
      "Epoch: 0039 cost= 0.092483468\n",
      "Epoch: 0040 cost= 0.134689078\n",
      "Epoch: 0041 cost= 0.003107164\n",
      "Epoch: 0042 cost= 0.004388066\n",
      "Epoch: 0043 cost= 0.000891262\n",
      "Epoch: 0044 cost= 0.002558383\n",
      "Epoch: 0045 cost= 0.002144343\n",
      "Epoch: 0046 cost= 0.004052005\n",
      "Epoch: 0047 cost= 0.002812854\n",
      "Epoch: 0048 cost= 0.001424284\n",
      "Epoch: 0049 cost= 0.006402115\n",
      "Epoch: 0050 cost= 0.005919845\n",
      "Epoch: 0051 cost= 0.002332540\n",
      "Epoch: 0052 cost= 0.002286406\n",
      "Epoch: 0053 cost= 0.004551953\n",
      "Epoch: 0054 cost= 0.004770549\n",
      "Epoch: 0055 cost= 0.002396626\n",
      "Epoch: 0056 cost= 0.000918483\n",
      "Epoch: 0057 cost= 0.002041943\n",
      "Epoch: 0058 cost= 0.375828087\n",
      "Epoch: 0059 cost= 0.002945546\n",
      "Epoch: 0060 cost= 0.004492044\n",
      "Epoch: 0061 cost= 0.376678884\n",
      "Epoch: 0062 cost= 0.002590696\n",
      "Epoch: 0063 cost= 0.002348452\n",
      "Epoch: 0064 cost= 0.003903465\n",
      "Epoch: 0065 cost= 0.003196680\n",
      "Epoch: 0066 cost= 0.001641080\n",
      "Epoch: 0067 cost= 0.001887426\n",
      "Epoch: 0068 cost= 0.002536958\n",
      "Epoch: 0069 cost= 0.002654558\n",
      "Epoch: 0070 cost= 0.003958832\n",
      "Epoch: 0071 cost= 0.004273287\n",
      "Epoch: 0072 cost= 0.002145013\n",
      "Epoch: 0073 cost= 0.002364846\n",
      "Epoch: 0074 cost= 0.002368058\n",
      "Epoch: 0075 cost= 0.003149861\n",
      "Epoch: 0076 cost= 0.002514724\n",
      "Epoch: 0077 cost= 0.001768814\n",
      "Epoch: 0078 cost= 0.003125429\n",
      "Epoch: 0079 cost= 0.002524872\n",
      "Epoch: 0080 cost= 0.001021472\n",
      "Epoch: 0081 cost= 0.002957968\n",
      "Epoch: 0082 cost= 0.000898850\n",
      "Epoch: 0083 cost= 0.003599687\n",
      "Epoch: 0084 cost= 0.001165407\n",
      "Epoch: 0085 cost= 0.003206704\n",
      "Epoch: 0086 cost= 0.001372273\n",
      "Epoch: 0087 cost= 0.001038914\n",
      "Epoch: 0088 cost= 0.003833085\n",
      "Epoch: 0089 cost= 0.001522997\n",
      "Epoch: 0090 cost= 0.002180582\n",
      "Epoch: 0091 cost= 0.002081346\n",
      "Epoch: 0092 cost= 0.002030239\n",
      "Epoch: 0093 cost= 0.002138759\n",
      "Epoch: 0094 cost= 0.001220315\n",
      "Epoch: 0095 cost= 0.001876623\n",
      "Epoch: 0096 cost= 0.002632816\n",
      "Epoch: 0097 cost= 0.002017175\n",
      "Epoch: 0098 cost= 0.002332957\n",
      "Epoch: 0099 cost= 0.002028798\n",
      "Epoch: 0100 cost= 0.002090413\n",
      "Optimization Finished!\n",
      "Accuracy: 0.960938\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#You'll use the MNIST dataset provided by TensorFlow, \n",
    "# which batches and One-Hot encodes the data for you.\n",
    "\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 100\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "#The variable n_hidden_layer determines the size of the hidden\n",
    "#layer in the neural network.This is also known as the width of a layer.\n",
    "n_hidden_layer = 256 # layer number of features\n",
    "\n",
    "# Deep neural networks use multiple layers with each layer requiring\n",
    "# it's own weight and bias. The 'hidden_layer' weight and bias is for\n",
    "# the hidden layer. The 'out' weight and bias is for the output layer.\n",
    "# If the neural network were deeper, there would be weights and biases\n",
    "# for each additional layer.\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# The MNIST data is made up of 28px by 28px images with a single channel.\n",
    "# The tf.reshape() function above reshapes the 28px by 28px matrices in x\n",
    "# into row vectors of 784px.\n",
    "x_flat = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "# You've seen the linear function \n",
    "# tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "# before, also known as xw + b. Combining linear functions together using\n",
    "# a ReLU will give you a two layer network.\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "#             The MNIST library in TensorFlow provides the ability to\n",
    "#             receive the dataset in batches. Calling the\n",
    "#             mnist.train.next_batch() function returns a subset of\n",
    "#             the training data.\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(c))\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    # Decrease test_size if you don't have enough memory\n",
    "    test_size = 256\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images[:test_size], y: mnist.test.labels[:test_size]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model could take awfully long time, hence would not wantto loose outr trained model. Thankfully Tensorflow let us save an restore model.. Let's see simple example again with save n restore of model parameters/variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Remove previous Tensors and Operations\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.09\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.10559999942779541\n",
      "Epoch 10  - Validation Accuracy: 0.24699999392032623\n",
      "Epoch 20  - Validation Accuracy: 0.4171999990940094\n",
      "Epoch 30  - Validation Accuracy: 0.5181999802589417\n",
      "Epoch 40  - Validation Accuracy: 0.5831999778747559\n",
      "Epoch 50  - Validation Accuracy: 0.6276000142097473\n",
      "Epoch 60  - Validation Accuracy: 0.6592000126838684\n",
      "Epoch 70  - Validation Accuracy: 0.6855999827384949\n",
      "Epoch 80  - Validation Accuracy: 0.704800009727478\n",
      "Epoch 90  - Validation Accuracy: 0.7203999757766724\n",
      "Trained Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "save_file = './train_model.ckpt'\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_model.ckpt\n",
      "Test Accuracy: 0.7242000102996826\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Weights and Biases into a New Model\n",
    "\n",
    "Sometimes you might want to adjust, or \"finetune\" a model that you have already trained and saved.\n",
    "\n",
    "However, loading saved Variables directly into a modified model can generate errors. Let's go over how to avoid these problems.\n",
    "\n",
    "Naming Error<br>\n",
    "TensorFlow uses a string identifier for Tensors and Operations called name. If a name is not given, TensorFlow will create one automatically. TensorFlow will give the first node the name <Type>, and then give the name <Type>_<number> for the subsequent nodes. Let's see how this can affect loading a model with a different order of weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: Variable:0\n",
      "Save Bias: Variable_1:0\n",
      "Load Weights: Variable_1:0\n",
      "Load Bias: Variable:0\n",
      "INFO:tensorflow:Restoring parameters from model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [2,3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-90-02cf5d745f8d>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 274, in assign\n    validate_shape=validate_shape)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 43, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [2,3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [2,3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-02cf5d745f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Load the weights and bias - ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1560\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [2,3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n\nCaused by op 'save/Assign', defined at:\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-90-02cf5d745f8d>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 274, in assign\n    validate_shape=validate_shape)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 43, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/IntroToTensorFlow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [2,3]\n\t [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable, save/RestoreV2)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = 'model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - ERROR\n",
    "    saver.restore(sess, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the name properties for weights and bias are different than when you saved the model. This is why the code produces the \"Assign requires shapes of both tensors to match\" error. The code saver.restore(sess, save_file) is trying to load weight data into bias and bias data into weights.\n",
    "\n",
    "Instead of letting TensorFlow set the name property, let's set it manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: weights_0:0\n",
      "Save Bias: bias_0:0\n",
      "Load Weights: weights_0:0\n",
      "Load Bias: bias_0:0\n",
      "INFO:tensorflow:Restoring parameters from model.ckpt\n",
      "Loaded Weights and Bias successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = 'model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Regularization To Avoid Overfitting\n",
    "\n",
    "**First Method** - It does not change network model,it is simply adding another term to the overall loss which penalize large weights. Another hyper parameter to tune unfortunately.\n",
    "\n",
    "**Second Method - Dropouts** - It has become very popular, basically in the network intermediate activation nodes, drop half or certain percentage of nodes to value zero, it force network to have redundant representation as network can't rely on activations all the time and is force to learn from others, in other words it is forced learn to take consensus from all nodes ensuring targets are achieved.\n",
    "\n",
    "Certainly evaluation can't depend randomness of dropouts we want something deterministic, hence to get consensus opinion, we have to average activations. Make sure to scale remaining activations by factor of 2.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.57999945   8.45999908]\n",
      " [  0.           0.        ]\n",
      " [ 14.28000069  33.09999847]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model with Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print logits from a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(logits, feed_dict={keep_prob: 0.5}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to learn about CNNs\n",
    "\n",
    "Covnets are networks which build on the idea to share parameters across space ..\n",
    "\n",
    "As simple as example, if we are learning to classify image of cats, it does not matter if the image is on left corner or right corner of image, but if we do not share the weights and ask network to individually identify cats on left and cats on right, it has to do lot of work to achieve this goal which sounds unnecessary in this example..\n",
    "\n",
    "Similarly, if we are training on text, meaning of Cat does not change at every occurence, hence it will make sense to share weights for classification of cat, however for text based learning we use method called embeddings or RNNs, we will talk more on this subject in later sections.\n",
    "\n",
    "At the end of CNNs as output, all the spatial information is squeezed out and only content is left. As example : Say it start with with full image & progress as mentioned, if you notice depth is increasing with every step emphasizing content 256x256xRGB >> 128x128x16 >> 64x64x64 >> 32x32x256 >> Classifier\n",
    "\n",
    "Lingo: \n",
    "\n",
    "PATCH == KERNEL == FILTER ==  IS NETWORK LAYER YOU RUN AS SUBSET\n",
    "\n",
    "FEATURE MAP == EACH SET OF FEATURES, in image with RGB, each R, G, B space is seperate feature map and applying \n",
    "\n",
    "PATCH/KERNEL we output/transform too N FEATURE MAPS. So in this example, trasforming 3 Feature Maps to K Feature Maps.\n",
    "\n",
    "STRIDE: Number of Pixels being shifted each time KERNEL Moves.<br>\n",
    "Stride of One means: Output is roughly same size as input. <br>\n",
    "Stride of Two means: Output is roughly half the size of input.<br>\n",
    "Roughly is used as it depends on how edging is processed, if filter do not pass the image edge it is called 'VALID PADDING', if Filter go beyond image edge, padding is needed to the input image to match the output and is called 'SAME PADDING'\n",
    "\n",
    "Filters are very agrressive in nature and cause information loss, couple techniques whcih can be applied to minimize loss are ** Max Pooling and Average Pooling**. Idea is to run 1 Stride but somehow combine similar information features/keep relevant features eventually shrinking the size of layer as CNN would do with higher depth. How it performs this is beyond scope here ..\n",
    "\n",
    "Recently, pooling layers have fallen out of favor. Some reasons are:\n",
    "\n",
    "- Recent datasets are so big and complex we're more concerned about underfitting.\n",
    "- Dropout is a much better regularizer.\n",
    "- Pooling results in a loss of information. Think about the max pooling operation as an example. We only keep the largest of n numbers, thereby disregarding n-1 numbers completely.\n",
    "\n",
    "**LENET-5 & ALEXNET are good reads on how they best make use of these concepets .. **\n",
    "\n",
    "**1x1 Covnets** - Helps coverting Linear Model of Convolutions to deeper Non-Linear..\n",
    "\n",
    "**Inception Module**So we have so many choices as listed above, Inception Module is stack of combination - what it does is compose the mdule in the following way using all above:\n",
    "- Average Pooling followed by 1x1\n",
    "- 1x1 Conv\n",
    "- 1x1 followed by 3x3\n",
    "- 1x1 followed by 5x5\n",
    "At the top concatinate the output from all above mentioned as one module .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch  1, Batch   1 - Loss: 77001.3125 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch   2 - Loss: 54442.8828 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch   3 - Loss: 39964.0156 Validation Accuracy: 0.140625\n",
      "Epoch  1, Batch   4 - Loss: 36289.2656 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch   5 - Loss: 37250.7773 Validation Accuracy: 0.179688\n",
      "Epoch  1, Batch   6 - Loss: 29698.1523 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch   7 - Loss: 29642.5586 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch   8 - Loss: 28352.6934 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch   9 - Loss: 24100.8594 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  10 - Loss: 26219.5645 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  11 - Loss: 25974.4375 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  12 - Loss: 25824.3633 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  13 - Loss: 22417.5703 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  14 - Loss: 24916.4453 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  15 - Loss: 20022.2949 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  16 - Loss: 18859.0234 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  17 - Loss: 20989.5820 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  18 - Loss: 22009.6953 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  19 - Loss: 20167.1484 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  20 - Loss: 19598.6016 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  21 - Loss: 18388.2656 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  22 - Loss: 17751.8867 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  23 - Loss: 20646.8555 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  24 - Loss: 19428.0332 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  25 - Loss: 14689.8613 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  26 - Loss: 17139.7266 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  27 - Loss: 15546.2422 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  28 - Loss: 16113.9141 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  29 - Loss: 16127.9150 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  30 - Loss: 14670.4932 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  31 - Loss: 19389.9648 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  32 - Loss: 15827.9316 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  33 - Loss: 15280.8623 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  34 - Loss: 15118.5146 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  35 - Loss: 12981.7227 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  36 - Loss: 14976.2422 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  37 - Loss: 13877.9844 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  38 - Loss: 14692.2646 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  39 - Loss: 14317.8887 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  40 - Loss: 12951.4521 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  41 - Loss: 11663.3672 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  42 - Loss: 12009.3164 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  43 - Loss: 10474.7363 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  44 - Loss: 11526.5273 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  45 - Loss: 14033.7539 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  46 - Loss: 11295.0283 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  47 - Loss: 11047.1172 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  48 - Loss: 10042.6289 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  49 - Loss: 10952.7832 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  50 - Loss: 12058.0361 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  51 - Loss:  8609.6992 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  52 - Loss: 11809.1309 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  53 - Loss: 12206.2480 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  54 - Loss:  9267.8594 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  55 - Loss: 10720.5674 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  56 - Loss: 10340.0879 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  57 - Loss: 12278.2793 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  58 - Loss: 10533.7871 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  59 - Loss: 10556.1641 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  60 - Loss: 10068.3984 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  61 - Loss:  6901.8496 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  62 - Loss:  8479.5098 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  63 - Loss: 10883.4531 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  64 - Loss:  8056.1763 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  65 - Loss:  9516.9141 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  66 - Loss:  9261.2773 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  67 - Loss: 10395.5635 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  68 - Loss:  9230.7852 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  69 - Loss:  7907.5176 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  70 - Loss:  9142.7500 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  71 - Loss:  8096.7217 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  72 - Loss:  7059.1367 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  73 - Loss:  8110.7139 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  74 - Loss:  6042.5371 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  75 - Loss:  7943.7090 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  76 - Loss:  6423.8228 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  77 - Loss:  8663.2803 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  78 - Loss:  6348.4302 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  79 - Loss:  8428.2861 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  80 - Loss:  7787.7925 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  81 - Loss:  7466.4160 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  82 - Loss:  6961.6230 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  83 - Loss:  5127.8994 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  84 - Loss:  7618.8018 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  85 - Loss:  7296.0615 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  86 - Loss:  8424.7539 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  87 - Loss:  6783.3979 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  88 - Loss:  5617.3057 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  89 - Loss:  6603.2158 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  90 - Loss:  6450.2676 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  91 - Loss:  6410.7363 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  92 - Loss:  6333.3184 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  93 - Loss:  5249.9238 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  94 - Loss:  7744.6479 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  95 - Loss:  5843.9453 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  96 - Loss:  5266.7446 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  97 - Loss:  5207.8047 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  98 - Loss:  7483.7065 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  99 - Loss:  6663.4976 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 100 - Loss:  5874.8760 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 101 - Loss:  6208.6802 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 102 - Loss:  7101.8188 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 103 - Loss:  5878.2173 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 104 - Loss:  6950.2168 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 105 - Loss:  6091.5518 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 106 - Loss:  5826.2046 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 107 - Loss:  5996.3750 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 108 - Loss:  5529.9238 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 109 - Loss:  6041.2832 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 110 - Loss:  7855.7646 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 111 - Loss:  5374.0479 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 112 - Loss:  4390.4238 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 113 - Loss:  4954.7939 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 114 - Loss:  6151.3809 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 115 - Loss:  5083.3643 Validation Accuracy: 0.593750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 116 - Loss:  5350.3320 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 117 - Loss:  4975.5225 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 118 - Loss:  4816.0186 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 119 - Loss:  4516.6782 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 120 - Loss:  5973.2788 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 121 - Loss:  5220.0732 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 122 - Loss:  4716.8896 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 123 - Loss:  5006.6011 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 124 - Loss:  6145.7373 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 125 - Loss:  5559.1699 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 126 - Loss:  3920.5278 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 127 - Loss:  5595.6968 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 128 - Loss:  5206.4297 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 129 - Loss:  4634.2490 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 130 - Loss:  5783.4634 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 131 - Loss:  6569.5312 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 132 - Loss:  4468.2930 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 133 - Loss:  4835.6328 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 134 - Loss:  3697.6313 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 135 - Loss:  5069.9971 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 136 - Loss:  4623.5596 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 137 - Loss:  4397.9785 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 138 - Loss:  5765.2769 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 139 - Loss:  5255.5410 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 140 - Loss:  4330.9707 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 141 - Loss:  5439.0576 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 142 - Loss:  3945.1357 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 143 - Loss:  4260.2432 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 144 - Loss:  2922.1868 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 145 - Loss:  4960.2974 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 146 - Loss:  3480.7900 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 147 - Loss:  4439.2368 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 148 - Loss:  4645.8540 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 149 - Loss:  5272.7480 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 150 - Loss:  3375.3904 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 151 - Loss:  4492.6421 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 152 - Loss:  2956.6472 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 153 - Loss:  4223.4277 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 154 - Loss:  4584.5205 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 155 - Loss:  3262.6509 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 156 - Loss:  4816.1875 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 157 - Loss:  3703.5547 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 158 - Loss:  4552.7441 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 159 - Loss:  4273.6245 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 160 - Loss:  4084.7744 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 161 - Loss:  4072.2720 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 162 - Loss:  4188.1025 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 163 - Loss:  3525.9197 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 164 - Loss:  5062.3643 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 165 - Loss:  3853.7666 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 166 - Loss:  4677.8760 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 167 - Loss:  4187.3569 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 168 - Loss:  3034.1621 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 169 - Loss:  4269.5615 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 170 - Loss:  2979.5571 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 171 - Loss:  4611.3535 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 172 - Loss:  4137.0742 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 173 - Loss:  4655.9448 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 174 - Loss:  3816.7817 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 175 - Loss:  3088.8555 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 176 - Loss:  3264.5312 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 177 - Loss:  3667.9128 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 178 - Loss:  4591.8662 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 179 - Loss:  3909.8391 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 180 - Loss:  4129.2729 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 181 - Loss:  4693.1694 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 182 - Loss:  4382.3188 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 183 - Loss:  3407.1299 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 184 - Loss:  4401.0132 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 185 - Loss:  2747.8022 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 186 - Loss:  3401.8987 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 187 - Loss:  3853.7349 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 188 - Loss:  3844.2515 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 189 - Loss:  3304.5842 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 190 - Loss:  3710.8640 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 191 - Loss:  3699.6311 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 192 - Loss:  3362.6416 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 193 - Loss:  2913.9731 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 194 - Loss:  2798.4580 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 195 - Loss:  3170.1404 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 196 - Loss:  3589.6963 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 197 - Loss:  3049.3774 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 198 - Loss:  2698.3311 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 199 - Loss:  3137.6978 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 200 - Loss:  3865.1436 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 201 - Loss:  2774.7944 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 202 - Loss:  3891.5100 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 203 - Loss:  2994.2427 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 204 - Loss:  3188.1001 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 205 - Loss:  3547.9097 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 206 - Loss:  3457.2100 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 207 - Loss:  3110.0017 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 208 - Loss:  2871.7439 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 209 - Loss:  2539.5903 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 210 - Loss:  3561.8528 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 211 - Loss:  3584.4590 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 212 - Loss:  2450.3599 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 213 - Loss:  2497.5850 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 214 - Loss:  2469.7354 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 215 - Loss:  3086.2727 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 216 - Loss:  2324.1370 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 217 - Loss:  3870.1855 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 218 - Loss:  3372.8193 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 219 - Loss:  2864.2471 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 220 - Loss:  2683.6882 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 221 - Loss:  3446.5984 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 222 - Loss:  3563.5146 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 223 - Loss:  2441.4434 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 224 - Loss:  3152.7461 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 225 - Loss:  2433.4141 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 226 - Loss:  2733.0735 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 227 - Loss:  4023.8989 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 228 - Loss:  3070.9377 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 229 - Loss:  2881.2520 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 230 - Loss:  2326.0046 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 231 - Loss:  2653.9116 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 232 - Loss:  3103.6013 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 233 - Loss:  3080.9783 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 234 - Loss:  3179.1245 Validation Accuracy: 0.683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 235 - Loss:  3676.8247 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 236 - Loss:  3429.7500 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 237 - Loss:  2507.9690 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 238 - Loss:  3406.7322 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 239 - Loss:  3769.9946 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 240 - Loss:  2092.0459 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 241 - Loss:  2531.0740 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 242 - Loss:  2430.4731 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 243 - Loss:  2416.0869 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 244 - Loss:  2989.4473 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 245 - Loss:  2159.5251 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 246 - Loss:  3192.8699 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 247 - Loss:  2476.9446 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 248 - Loss:  2637.2134 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 249 - Loss:  2828.8960 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 250 - Loss:  2597.8369 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 251 - Loss:  2049.2014 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 252 - Loss:  3043.2168 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 253 - Loss:  2133.9902 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 254 - Loss:  2308.6196 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 255 - Loss:  2634.5623 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 256 - Loss:  2732.5928 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 257 - Loss:  2178.6392 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 258 - Loss:  1930.8741 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 259 - Loss:  2186.9229 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 260 - Loss:  2340.0081 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 261 - Loss:  2241.7588 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 262 - Loss:  1991.9446 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 263 - Loss:  1845.3629 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 264 - Loss:  2715.4014 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 265 - Loss:  2778.0339 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 266 - Loss:  3038.6699 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 267 - Loss:  3907.2070 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 268 - Loss:  1768.4735 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 269 - Loss:  2317.6042 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 270 - Loss:  2495.8250 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 271 - Loss:  2682.7734 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 272 - Loss:  2742.4775 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 273 - Loss:  2445.3235 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 274 - Loss:  2474.4392 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 275 - Loss:  2288.3440 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 276 - Loss:  2665.7007 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 277 - Loss:  2679.4287 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 278 - Loss:  1446.2863 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 279 - Loss:  1713.0979 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 280 - Loss:  2311.9065 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 281 - Loss:  4091.7007 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 282 - Loss:  2885.3901 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 283 - Loss:  1968.6006 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 284 - Loss:  2677.9023 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 285 - Loss:  2197.8799 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 286 - Loss:  2243.8804 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 287 - Loss:  2128.6470 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 288 - Loss:  2304.4053 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 289 - Loss:  2794.7844 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 290 - Loss:  1827.4988 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 291 - Loss:  2775.8872 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 292 - Loss:  2716.8892 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 293 - Loss:  2906.5859 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 294 - Loss:  1842.6694 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 295 - Loss:  2782.5623 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 296 - Loss:  2392.0303 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 297 - Loss:  2108.5146 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 298 - Loss:  2102.9087 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 299 - Loss:  2826.9478 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 300 - Loss:  2109.0063 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 301 - Loss:  2363.4514 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 302 - Loss:  2619.6084 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 303 - Loss:  2105.3909 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 304 - Loss:  3023.4797 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 305 - Loss:  2476.5471 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 306 - Loss:  2065.7349 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 307 - Loss:  2222.7000 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 308 - Loss:  2880.4844 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 309 - Loss:  1846.3132 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 310 - Loss:  1581.2919 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 311 - Loss:  2417.1575 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 312 - Loss:  2309.0908 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 313 - Loss:  2228.7432 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 314 - Loss:  2556.4111 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 315 - Loss:  2422.3997 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 316 - Loss:  1753.6331 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 317 - Loss:  2595.2021 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 318 - Loss:  2813.5552 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 319 - Loss:  2643.6045 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 320 - Loss:  3447.8550 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 321 - Loss:  2045.0461 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 322 - Loss:  2178.2612 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 323 - Loss:  2095.9856 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 324 - Loss:  2193.1548 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 325 - Loss:  2158.7095 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 326 - Loss:  2203.0579 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 327 - Loss:  1635.1316 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 328 - Loss:  2008.4640 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 329 - Loss:  1784.9753 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 330 - Loss:  1132.0262 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 331 - Loss:  2671.1697 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 332 - Loss:  2507.9661 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 333 - Loss:  2392.7803 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 334 - Loss:  2232.5164 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 335 - Loss:  1889.2537 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 336 - Loss:  2585.4434 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 337 - Loss:  2877.5537 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 338 - Loss:  2507.7251 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 339 - Loss:  1942.2538 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 340 - Loss:  1472.7837 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 341 - Loss:  1910.7411 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 342 - Loss:  1612.5675 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 343 - Loss:  1338.0618 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 344 - Loss:  2270.3984 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 345 - Loss:  1311.9590 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 346 - Loss:  1609.9670 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 347 - Loss:  1916.8212 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 348 - Loss:  2360.3784 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 349 - Loss:  2247.8374 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 350 - Loss:  1346.7295 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 351 - Loss:  1164.8892 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 352 - Loss:  2545.2002 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 353 - Loss:  2764.1143 Validation Accuracy: 0.714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 354 - Loss:  1869.6760 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 355 - Loss:  1724.4590 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 356 - Loss:  1969.2212 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 357 - Loss:  2367.9307 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 358 - Loss:  2025.3516 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 359 - Loss:  2235.3105 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 360 - Loss:  2776.2827 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 361 - Loss:  1723.9233 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 362 - Loss:  1492.4822 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 363 - Loss:  1947.5896 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 364 - Loss:  1967.1422 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 365 - Loss:  2563.9111 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 366 - Loss:  1922.9376 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 367 - Loss:  2447.7720 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 368 - Loss:  1940.8672 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 369 - Loss:  2547.2324 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 370 - Loss:  2158.1899 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 371 - Loss:  1979.0940 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 372 - Loss:  2128.8716 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 373 - Loss:  1945.9553 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 374 - Loss:  2207.3518 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 375 - Loss:  2409.8528 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 376 - Loss:  2567.3020 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 377 - Loss:  1641.8375 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 378 - Loss:  2264.9978 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 379 - Loss:  1597.3328 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 380 - Loss:  1195.9235 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 381 - Loss:  1608.6593 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 382 - Loss:  1668.4958 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 383 - Loss:  1761.8005 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 384 - Loss:  2233.4058 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 385 - Loss:  1427.1082 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 386 - Loss:  1915.1426 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 387 - Loss:  1249.5455 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 388 - Loss:  2255.2886 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 389 - Loss:  1514.1760 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 390 - Loss:  1713.8547 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 391 - Loss:  1736.3427 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 392 - Loss:  1804.2701 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 393 - Loss:  1285.1259 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 394 - Loss:  2100.8550 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 395 - Loss:  2113.3381 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 396 - Loss:  2560.8376 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 397 - Loss:  1473.1045 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 398 - Loss:  1542.8518 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 399 - Loss:  1878.0552 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 400 - Loss:  1697.4248 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 401 - Loss:  2126.7612 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 402 - Loss:  1735.1033 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 403 - Loss:  1338.8989 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 404 - Loss:  1887.0629 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 405 - Loss:  1181.9087 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 406 - Loss:  1443.0415 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 407 - Loss:  1869.1836 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 408 - Loss:  2278.8452 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 409 - Loss:  1668.8013 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 410 - Loss:  1955.9419 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 411 - Loss:  1532.2831 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 412 - Loss:  1979.2853 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 413 - Loss:  1375.2534 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 414 - Loss:  1754.3064 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 415 - Loss:  1561.5470 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 416 - Loss:  1272.2805 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 417 - Loss:  1895.0308 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 418 - Loss:  1526.0408 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 419 - Loss:  1613.9570 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 420 - Loss:  2251.6528 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 421 - Loss:  2443.1206 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 422 - Loss:  1729.0013 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 423 - Loss:  1525.8479 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 424 - Loss:  1930.0330 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 425 - Loss:  1481.2031 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 426 - Loss:  1351.5449 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 427 - Loss:  1742.8839 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 428 - Loss:  1968.7417 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 429 - Loss:  1659.6952 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   1 - Loss:  1320.0901 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   2 - Loss:  1897.9349 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   3 - Loss:  2471.2268 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch   4 - Loss:  1801.7266 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   5 - Loss:  1334.1418 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   6 - Loss:  2188.2002 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch   7 - Loss:  1297.5842 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch   8 - Loss:  2276.7764 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch   9 - Loss:  1423.2845 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  10 - Loss:  1327.0061 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  11 - Loss:  2418.6082 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  12 - Loss:  1639.2238 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  13 - Loss:  1465.0698 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  14 - Loss:  1409.7053 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  15 - Loss:  1995.9962 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  16 - Loss:  1385.3867 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  17 - Loss:  1877.3334 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  18 - Loss:  1435.5106 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  19 - Loss:  1950.5643 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  20 - Loss:  1170.7517 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  21 - Loss:  1674.0300 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  22 - Loss:  1359.3706 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  23 - Loss:  2164.5479 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  24 - Loss:  1474.7102 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  25 - Loss:  1784.9504 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  26 - Loss:  1308.5540 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  27 - Loss:  1422.4253 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  28 - Loss:  1516.2397 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  29 - Loss:  1735.8719 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  30 - Loss:  1414.3303 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  31 - Loss:  1549.5210 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  32 - Loss:  1866.9252 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  33 - Loss:  1691.8422 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  34 - Loss:  1700.9344 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  35 - Loss:  1096.3248 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  36 - Loss:  1351.3296 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  37 - Loss:  1856.2773 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  38 - Loss:  1993.7925 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  39 - Loss:  1658.7172 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  40 - Loss:  1104.9604 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  41 - Loss:  1935.6493 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  42 - Loss:   843.8781 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  43 - Loss:  1367.7704 Validation Accuracy: 0.738281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  44 - Loss:  1401.5270 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  45 - Loss:  1405.6310 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  46 - Loss:  1216.3828 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  47 - Loss:  1684.5850 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  48 - Loss:  1306.6262 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  49 - Loss:  1864.8462 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  50 - Loss:  1078.4752 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  51 - Loss:  1487.2583 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  52 - Loss:  2183.1343 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  53 - Loss:  2086.9058 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  54 - Loss:  1696.2123 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  55 - Loss:  1355.5872 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  56 - Loss:  1440.7804 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  57 - Loss:  1378.8058 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  58 - Loss:  1778.8325 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  59 - Loss:  2213.1538 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  60 - Loss:  1821.3860 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  61 - Loss:  1743.9309 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  62 - Loss:  1349.3688 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  63 - Loss:  1683.6234 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  64 - Loss:  1039.9639 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  65 - Loss:  1469.0038 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  66 - Loss:  1684.1820 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  67 - Loss:  1790.9602 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  68 - Loss:  1415.1138 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  69 - Loss:  1744.9478 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  70 - Loss:  1753.9375 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  71 - Loss:  1748.6018 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  72 - Loss:  1503.0681 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  73 - Loss:  1443.0264 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  74 - Loss:  1530.5176 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  75 - Loss:  2039.0718 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  76 - Loss:   755.0809 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  77 - Loss:  1084.2916 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  78 - Loss:  1802.0591 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  79 - Loss:  1640.0925 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  80 - Loss:   773.9386 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  81 - Loss:  1584.8997 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  82 - Loss:  1414.6278 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  83 - Loss:  1728.2313 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  84 - Loss:  1427.9290 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  85 - Loss:  1898.9700 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  86 - Loss:   810.9941 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  87 - Loss:  1401.3906 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  88 - Loss:  1687.1587 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  89 - Loss:  1571.7905 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  90 - Loss:  1800.1471 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  91 - Loss:  1423.0533 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  92 - Loss:   904.5233 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  93 - Loss:  1780.2786 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  94 - Loss:   844.4414 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  95 - Loss:  1107.4058 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  96 - Loss:  1502.4126 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  97 - Loss:  1372.1509 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  98 - Loss:   997.0501 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  99 - Loss:  1282.1920 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 100 - Loss:   934.4765 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 101 - Loss:  1507.2473 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 102 - Loss:  1287.5747 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 103 - Loss:  1140.6790 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 104 - Loss:  1527.9763 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 105 - Loss:  1370.2004 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 106 - Loss:  1215.8269 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 107 - Loss:  1124.4982 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 108 - Loss:  1691.9500 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 109 - Loss:  1727.9812 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 110 - Loss:  1448.2383 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 111 - Loss:  1736.8601 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 112 - Loss:  1243.3986 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 113 - Loss:  1132.9623 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 114 - Loss:  1217.5879 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 115 - Loss:  1483.5276 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 116 - Loss:  1168.2513 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 117 - Loss:  2142.7246 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 118 - Loss:   866.3381 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 119 - Loss:  1465.0729 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 120 - Loss:   873.5753 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 121 - Loss:  1312.2424 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 122 - Loss:  1445.0629 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 123 - Loss:  1521.7235 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 124 - Loss:  1249.2274 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 125 - Loss:  1523.5422 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 126 - Loss:  1444.7458 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 127 - Loss:  1208.6152 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 128 - Loss:  1521.2723 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 129 - Loss:  1016.8512 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 130 - Loss:  1511.5288 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 131 - Loss:  1548.4165 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 132 - Loss:  1128.2469 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 133 - Loss:  1419.3907 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 134 - Loss:  1265.6066 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 135 - Loss:  1471.4292 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 136 - Loss:  1336.0952 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 137 - Loss:  1120.5626 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 138 - Loss:  1206.2521 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 139 - Loss:   808.9554 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 140 - Loss:  1826.1107 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 141 - Loss:   987.2978 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 142 - Loss:  1780.7334 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 143 - Loss:  1192.7455 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 144 - Loss:  1148.7290 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 145 - Loss:  1402.2588 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 146 - Loss:  1221.8925 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 147 - Loss:  1379.7402 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 148 - Loss:  1689.1187 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 149 - Loss:  1800.2209 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 150 - Loss:  1138.8373 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 151 - Loss:  1299.1167 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 152 - Loss:  1520.9268 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 153 - Loss:   932.1472 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 154 - Loss:  1072.9822 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 155 - Loss:   743.0319 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 156 - Loss:  1220.0259 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 157 - Loss:  1415.0513 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 158 - Loss:   881.0696 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 159 - Loss:   883.0256 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 160 - Loss:  1396.7006 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 161 - Loss:  1503.1276 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 162 - Loss:   991.2072 Validation Accuracy: 0.750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 163 - Loss:  1274.1659 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 164 - Loss:  1184.2645 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 165 - Loss:   997.1650 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 166 - Loss:  1315.2631 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 167 - Loss:  1471.5171 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 168 - Loss:  1205.5762 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 169 - Loss:  1191.5208 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 170 - Loss:  1005.4540 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 171 - Loss:  1293.5511 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 172 - Loss:  1393.8995 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 173 - Loss:  1135.9244 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 174 - Loss:  1283.3121 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 175 - Loss:  1132.4807 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 176 - Loss:  1105.3420 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 177 - Loss:  1573.1055 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 178 - Loss:  1349.4739 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 179 - Loss:  1157.7253 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 180 - Loss:   628.8750 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 181 - Loss:  1142.1682 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 182 - Loss:   750.0851 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 183 - Loss:  1212.8834 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 184 - Loss:   937.9730 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 185 - Loss:  1334.2302 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 186 - Loss:  1206.4547 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 187 - Loss:  1563.7799 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 188 - Loss:  1254.9484 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 189 - Loss:  1391.2549 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 190 - Loss:  1273.7906 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 191 - Loss:  1347.6044 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 192 - Loss:  1447.4929 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 193 - Loss:   853.5087 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 194 - Loss:  1080.3372 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 195 - Loss:   741.3380 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 196 - Loss:  1841.5786 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 197 - Loss:  1424.0800 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 198 - Loss:  1492.4497 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 199 - Loss:   515.9612 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 200 - Loss:   960.4603 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 201 - Loss:   807.4099 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 202 - Loss:  1288.0642 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 203 - Loss:   720.8559 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 204 - Loss:  1068.8126 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 205 - Loss:   960.6725 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 206 - Loss:  1426.6665 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 207 - Loss:  1633.0122 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 208 - Loss:  1183.7988 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 209 - Loss:   905.4734 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 210 - Loss:  1264.1296 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 211 - Loss:  1219.3728 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 212 - Loss:  1181.1895 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 213 - Loss:   668.3152 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 214 - Loss:  1219.0701 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 215 - Loss:  1310.3711 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 216 - Loss:  1231.1736 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 217 - Loss:  1396.5366 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 218 - Loss:   979.7490 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 219 - Loss:   996.1329 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 220 - Loss:  1273.2114 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 221 - Loss:  1056.1089 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 222 - Loss:  1108.6080 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 223 - Loss:   809.1798 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 224 - Loss:   979.9358 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 225 - Loss:  1158.1411 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 226 - Loss:  1592.5110 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 227 - Loss:  1421.6167 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 228 - Loss:   328.5763 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 229 - Loss:  1111.5750 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 230 - Loss:  1106.3970 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 231 - Loss:  1162.9557 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 232 - Loss:  1300.8452 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 233 - Loss:  1140.8495 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 234 - Loss:  1490.1619 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 235 - Loss:  1078.4189 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 236 - Loss:  1390.9800 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 237 - Loss:  1106.3639 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 238 - Loss:  1148.4553 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 239 - Loss:   994.9622 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 240 - Loss:  1156.9022 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 241 - Loss:  1125.2747 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 242 - Loss:  1267.4285 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 243 - Loss:   763.3108 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 244 - Loss:  1261.5188 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 245 - Loss:   875.7303 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 246 - Loss:   812.5762 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 247 - Loss:  1349.0508 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 248 - Loss:  1461.6696 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 249 - Loss:  1401.6498 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 250 - Loss:  1186.7583 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 251 - Loss:   753.1903 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 252 - Loss:   853.8964 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 253 - Loss:  1062.3030 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 254 - Loss:   952.8746 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 255 - Loss:  1044.9712 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 256 - Loss:  1172.3698 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 257 - Loss:   915.2566 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 258 - Loss:   833.0784 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 259 - Loss:   742.7378 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 260 - Loss:  1152.3755 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 261 - Loss:   932.1592 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 262 - Loss:  1352.8601 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 263 - Loss:  1391.2339 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 264 - Loss:  1094.7241 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 265 - Loss:  1283.3562 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 266 - Loss:  1260.0116 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 267 - Loss:  1404.0974 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 268 - Loss:  1286.4498 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 269 - Loss:  1012.8241 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 270 - Loss:   916.8038 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 271 - Loss:   779.1483 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 272 - Loss:  1204.4917 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 273 - Loss:  1269.9694 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 274 - Loss:  1025.9475 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 275 - Loss:  1048.9225 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 276 - Loss:  1020.0197 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 277 - Loss:  1327.9432 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 278 - Loss:  1034.5632 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 279 - Loss:  1106.5894 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 280 - Loss:  1380.5793 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 281 - Loss:  1165.6604 Validation Accuracy: 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 282 - Loss:   832.2468 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 283 - Loss:   559.0250 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 284 - Loss:   779.2065 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 285 - Loss:  1050.5597 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 286 - Loss:   776.3518 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 287 - Loss:  1317.3696 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 288 - Loss:  1266.7612 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 289 - Loss:  1376.1737 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 290 - Loss:   799.3616 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 291 - Loss:  1038.1406 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 292 - Loss:  1351.7209 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 293 - Loss:   686.0549 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 294 - Loss:  1130.2842 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 295 - Loss:  1052.6277 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 296 - Loss:  1080.6675 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 297 - Loss:  1229.5823 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 298 - Loss:  1187.1169 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 299 - Loss:   682.4343 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 300 - Loss:  1006.7552 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 301 - Loss:  1188.5115 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 302 - Loss:  1624.7968 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 303 - Loss:   978.1128 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 304 - Loss:  1256.8003 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 305 - Loss:   799.3854 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 306 - Loss:  1195.3904 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 307 - Loss:  1084.0928 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 308 - Loss:   943.4186 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 309 - Loss:   994.6089 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 310 - Loss:   946.2177 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 311 - Loss:   910.0193 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 312 - Loss:   918.4974 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 313 - Loss:  1022.9770 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 314 - Loss:  1113.8011 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 315 - Loss:   812.3787 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 316 - Loss:  1209.9650 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 317 - Loss:  1091.3080 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 318 - Loss:   799.2911 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 319 - Loss:  1153.1210 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 320 - Loss:  1084.9553 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 321 - Loss:  1153.2163 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 322 - Loss:   708.1638 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 323 - Loss:   743.5530 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 324 - Loss:  1024.3196 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 325 - Loss:   964.1742 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 326 - Loss:  1248.3142 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 327 - Loss:   923.8134 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 328 - Loss:   972.1895 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 329 - Loss:  1087.5889 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 330 - Loss:   798.3196 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 331 - Loss:  1121.8779 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 332 - Loss:   728.5272 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 333 - Loss:   541.0199 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 334 - Loss:   718.9353 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 335 - Loss:   774.8973 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 336 - Loss:   710.6768 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 337 - Loss:  1137.0734 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 338 - Loss:   852.1202 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 339 - Loss:   952.4622 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 340 - Loss:  1140.2693 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 341 - Loss:   690.9557 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 342 - Loss:  1311.6370 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 343 - Loss:  1184.7334 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 344 - Loss:   698.4866 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 345 - Loss:  1302.3918 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 346 - Loss:   764.7347 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 347 - Loss:   933.5505 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 348 - Loss:   971.8190 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 349 - Loss:  1104.9443 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 350 - Loss:   724.7419 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 351 - Loss:   956.3975 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 352 - Loss:  1049.7582 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 353 - Loss:  1231.0974 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 354 - Loss:  1064.0372 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 355 - Loss:  1294.5029 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 356 - Loss:  1055.5841 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 357 - Loss:   960.0065 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 358 - Loss:   675.7498 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 359 - Loss:  1072.5171 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 360 - Loss:  1267.3151 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 361 - Loss:   761.5964 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 362 - Loss:   826.6257 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 363 - Loss:   909.8116 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 364 - Loss:   867.9218 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 365 - Loss:   864.4493 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 366 - Loss:   862.5208 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 367 - Loss:   925.9888 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 368 - Loss:  1042.7715 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 369 - Loss:  1194.8842 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 370 - Loss:  1081.4707 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 371 - Loss:   947.3802 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 372 - Loss:  1093.0806 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 373 - Loss:   488.3917 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 374 - Loss:   943.9822 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 375 - Loss:  1814.2334 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 376 - Loss:   874.2548 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 377 - Loss:  1414.9761 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 378 - Loss:   857.3688 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 379 - Loss:  1038.9336 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 380 - Loss:   995.0010 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 381 - Loss:   879.3951 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 382 - Loss:  1012.4377 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 383 - Loss:   699.5326 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 384 - Loss:   749.2274 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 385 - Loss:   894.3646 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 386 - Loss:   946.0178 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 387 - Loss:  1021.5386 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 388 - Loss:  1008.0311 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 389 - Loss:  1083.5756 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 390 - Loss:   827.8196 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 391 - Loss:   616.4857 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 392 - Loss:   838.2079 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 393 - Loss:   706.6813 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 394 - Loss:   778.5187 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 395 - Loss:  1076.9327 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 396 - Loss:   856.3359 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 397 - Loss:   772.6176 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 398 - Loss:   714.4930 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 399 - Loss:  1543.9243 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 400 - Loss:   987.1928 Validation Accuracy: 0.785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 401 - Loss:  1408.2463 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 402 - Loss:   948.2817 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 403 - Loss:  1016.5685 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 404 - Loss:   989.7462 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 405 - Loss:   967.6132 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 406 - Loss:   508.3142 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 407 - Loss:  1414.8564 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 408 - Loss:   479.1297 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 409 - Loss:   515.5109 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 410 - Loss:   927.2025 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 411 - Loss:   697.2164 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 412 - Loss:  1320.3706 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 413 - Loss:  1312.6782 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 414 - Loss:   827.7047 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 415 - Loss:   840.2490 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 416 - Loss:   868.3688 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 417 - Loss:   752.6503 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 418 - Loss:   663.1292 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 419 - Loss:   774.8237 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 420 - Loss:   813.8469 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 421 - Loss:   755.3330 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 422 - Loss:   972.1705 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 423 - Loss:   695.0984 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 424 - Loss:   936.2546 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 425 - Loss:   656.4980 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 426 - Loss:   641.8376 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 427 - Loss:   581.8951 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 428 - Loss:   561.8892 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 429 - Loss:   761.0570 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   1 - Loss:  1233.4833 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   2 - Loss:   708.5503 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   3 - Loss:   722.1197 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch   4 - Loss:   755.9557 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   5 - Loss:   812.7094 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   6 - Loss:   783.1158 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   7 - Loss:  1035.0752 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch   8 - Loss:   742.8947 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   9 - Loss:   799.9949 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  10 - Loss:  1091.3970 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  11 - Loss:  1096.9492 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  12 - Loss:   935.0841 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  13 - Loss:   838.5299 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  14 - Loss:   871.1342 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  15 - Loss:   696.7662 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  16 - Loss:   653.3055 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  17 - Loss:   587.2523 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  18 - Loss:  1012.3368 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  19 - Loss:   776.6501 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  20 - Loss:   991.2512 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  21 - Loss:   505.7603 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  22 - Loss:   763.3917 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  23 - Loss:  1050.7347 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  24 - Loss:   956.9458 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  25 - Loss:  1340.2556 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  26 - Loss:  1203.3687 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  27 - Loss:   761.6068 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  28 - Loss:   466.6458 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  29 - Loss:  1028.3000 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  30 - Loss:   550.7635 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  31 - Loss:   784.5149 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  32 - Loss:   609.6393 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  33 - Loss:  1070.1571 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  34 - Loss:  1537.2595 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  35 - Loss:   505.6340 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  36 - Loss:   861.9678 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  37 - Loss:  1227.9949 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  38 - Loss:   709.2988 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  39 - Loss:   770.6444 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  40 - Loss:   605.4304 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  41 - Loss:   834.3286 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  42 - Loss:   548.7465 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  43 - Loss:   923.9170 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  44 - Loss:   633.4413 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  45 - Loss:  1008.5991 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  46 - Loss:   910.5676 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  47 - Loss:   718.0836 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  48 - Loss:   881.1214 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  49 - Loss:   821.4487 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  50 - Loss:  1031.7065 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  51 - Loss:   693.6287 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  52 - Loss:   666.5775 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  53 - Loss:   846.1389 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  54 - Loss:   709.0348 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  55 - Loss:   603.1717 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  56 - Loss:  1063.2295 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  57 - Loss:   933.2776 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  58 - Loss:   540.2172 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  59 - Loss:   682.4453 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  60 - Loss:   669.4237 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  61 - Loss:   912.4491 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  62 - Loss:   945.6553 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  63 - Loss:  1076.3225 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  64 - Loss:   636.6243 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  65 - Loss:  1226.4709 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  66 - Loss:   968.2715 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  67 - Loss:   640.6496 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  68 - Loss:   730.0514 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  69 - Loss:   814.3800 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  70 - Loss:  1210.7563 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  71 - Loss:  1207.2524 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  72 - Loss:   929.1842 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  73 - Loss:   926.7276 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  74 - Loss:   465.0334 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  75 - Loss:   760.2209 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  76 - Loss:   680.1237 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  77 - Loss:  1015.4342 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  78 - Loss:   668.3055 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch  79 - Loss:   969.1190 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  80 - Loss:   718.9043 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  81 - Loss:   795.3301 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  82 - Loss:  1432.8425 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  83 - Loss:   879.0917 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  84 - Loss:   972.6352 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  85 - Loss:   787.8595 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  86 - Loss:  1090.8574 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  87 - Loss:  1048.2345 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  88 - Loss:  1006.3595 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  89 - Loss:   755.1514 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  90 - Loss:   592.7692 Validation Accuracy: 0.789062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch  91 - Loss:  1066.6829 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  92 - Loss:   709.7827 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  93 - Loss:   992.4597 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  94 - Loss:   937.1753 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  95 - Loss:   907.2180 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  96 - Loss:   792.7299 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  97 - Loss:   665.1042 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  98 - Loss:  1046.2458 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  99 - Loss:   551.6773 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 100 - Loss:   894.9312 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 101 - Loss:   741.6326 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 102 - Loss:   648.1952 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 103 - Loss:   705.5754 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 104 - Loss:   797.1055 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 105 - Loss:   897.5150 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 106 - Loss:   861.1420 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 107 - Loss:   786.8391 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 108 - Loss:   602.8779 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 109 - Loss:   801.6253 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 110 - Loss:   837.0385 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 111 - Loss:   573.5901 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 112 - Loss:   811.8192 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 113 - Loss:   542.6918 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 114 - Loss:   924.0934 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 115 - Loss:   947.6667 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 116 - Loss:   715.4088 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 117 - Loss:   845.1255 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 118 - Loss:   624.6691 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 119 - Loss:   930.5521 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 120 - Loss:   876.8658 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 121 - Loss:   820.4144 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 122 - Loss:   893.7737 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 123 - Loss:   663.5636 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 124 - Loss:   805.7084 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 125 - Loss:   712.0808 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 126 - Loss:   718.9148 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 127 - Loss:   840.3006 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 128 - Loss:   397.9561 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 129 - Loss:   597.4661 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 130 - Loss:   618.4504 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 131 - Loss:   570.2757 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 132 - Loss:   722.7048 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 133 - Loss:   370.6504 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 134 - Loss:   682.3828 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 135 - Loss:  1351.6473 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 136 - Loss:   969.9029 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 137 - Loss:   612.4557 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 138 - Loss:   941.5569 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 139 - Loss:   852.0047 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 140 - Loss:   569.0682 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 141 - Loss:   533.3427 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 142 - Loss:   522.8338 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 143 - Loss:   840.5208 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 144 - Loss:   754.3297 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 145 - Loss:   902.3528 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 146 - Loss:   939.0103 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 147 - Loss:   965.9682 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 148 - Loss:   987.5724 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 149 - Loss:   986.3254 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 150 - Loss:   508.4819 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 151 - Loss:   785.6337 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 152 - Loss:  1224.0002 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 153 - Loss:  1065.6124 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 154 - Loss:   608.3865 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 155 - Loss:   606.1179 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 156 - Loss:   660.8641 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 157 - Loss:   872.1734 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 158 - Loss:   949.0228 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 159 - Loss:   400.6022 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 160 - Loss:   814.8662 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 161 - Loss:   914.7533 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 162 - Loss:   776.6895 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 163 - Loss:   911.3628 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 164 - Loss:   676.5577 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 165 - Loss:   625.0270 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 166 - Loss:   700.0712 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 167 - Loss:   703.0328 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 168 - Loss:   750.0865 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 169 - Loss:   796.0674 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 170 - Loss:   672.5942 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 171 - Loss:   525.8665 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 172 - Loss:   997.6149 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 173 - Loss:   259.5143 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 174 - Loss:   805.9161 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 175 - Loss:   572.2078 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 176 - Loss:   827.7090 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 177 - Loss:   877.7246 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 178 - Loss:  1104.4503 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 179 - Loss:  1016.8354 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 180 - Loss:   843.0273 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 181 - Loss:  1000.3250 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 182 - Loss:   678.9922 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 183 - Loss:   596.5301 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 184 - Loss:   698.9380 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 185 - Loss:   552.7756 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 186 - Loss:   637.0056 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 187 - Loss:   887.4522 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 188 - Loss:   691.3905 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 189 - Loss:   530.5894 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 190 - Loss:   646.4990 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 191 - Loss:   620.2654 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 192 - Loss:   799.2499 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 193 - Loss:   813.3680 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 194 - Loss:   922.2637 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 195 - Loss:   878.1708 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 196 - Loss:   943.8181 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 197 - Loss:   737.4889 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 198 - Loss:   832.3419 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 199 - Loss:  1096.5403 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 200 - Loss:   633.1852 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 201 - Loss:   481.1833 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 202 - Loss:   978.4985 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 203 - Loss:  1127.6176 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 204 - Loss:   645.0220 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 205 - Loss:   912.5446 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 206 - Loss:   616.0750 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 207 - Loss:   826.7238 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 208 - Loss:  1039.8274 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 209 - Loss:  1116.2959 Validation Accuracy: 0.785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch 210 - Loss:   631.3258 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 211 - Loss:   815.4072 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 212 - Loss:  1051.5950 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 213 - Loss:   513.6179 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 214 - Loss:   613.3751 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 215 - Loss:   674.5891 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 216 - Loss:   531.3687 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 217 - Loss:   692.0456 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 218 - Loss:   643.8160 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 219 - Loss:   841.0179 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 220 - Loss:   539.7337 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 221 - Loss:   646.6320 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 222 - Loss:   976.1318 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 223 - Loss:   621.1372 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 224 - Loss:   998.1065 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 225 - Loss:   472.6564 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 226 - Loss:   658.7383 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 227 - Loss:   993.3714 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 228 - Loss:   701.8252 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 229 - Loss:   688.5789 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 230 - Loss:   547.3708 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 231 - Loss:   562.1781 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 232 - Loss:   804.1642 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 233 - Loss:   627.8121 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 234 - Loss:   654.6155 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 235 - Loss:   894.6633 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 236 - Loss:   658.7648 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 237 - Loss:   872.7617 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 238 - Loss:   555.8782 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 239 - Loss:   497.9517 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 240 - Loss:   742.7413 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 241 - Loss:   571.9578 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 242 - Loss:   625.5220 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 243 - Loss:   865.8219 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 244 - Loss:   625.0393 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 245 - Loss:   886.5369 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 246 - Loss:   573.9604 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 247 - Loss:   501.9700 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 248 - Loss:   770.3925 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 249 - Loss:   657.8605 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 250 - Loss:   823.0465 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 251 - Loss:   626.0250 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 252 - Loss:   773.1369 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 253 - Loss:   534.1022 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 254 - Loss:   796.8666 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 255 - Loss:   933.5441 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 256 - Loss:   461.6415 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 257 - Loss:   737.4186 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 258 - Loss:   499.7070 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 259 - Loss:   466.5406 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 260 - Loss:   774.8427 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 261 - Loss:   798.0967 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 262 - Loss:   596.6639 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 263 - Loss:   869.1484 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 264 - Loss:   734.2649 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 265 - Loss:   653.5117 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 266 - Loss:   665.8766 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 267 - Loss:   720.0559 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 268 - Loss:   645.1474 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 269 - Loss:   841.6688 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 270 - Loss:   576.3188 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 271 - Loss:   776.7285 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 272 - Loss:   726.0150 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 273 - Loss:   813.3859 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 274 - Loss:   672.7876 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 275 - Loss:   592.4436 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 276 - Loss:   894.0261 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 277 - Loss:   420.3004 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 278 - Loss:   737.2173 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 279 - Loss:   615.1492 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 280 - Loss:   592.4241 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 281 - Loss:   610.2307 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 282 - Loss:   630.5588 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 283 - Loss:   630.8910 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 284 - Loss:   653.8439 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 285 - Loss:   607.8213 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 286 - Loss:   836.5156 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 287 - Loss:   611.5464 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 288 - Loss:   799.7651 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 289 - Loss:  1049.0934 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 290 - Loss:   813.4773 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 291 - Loss:   662.0095 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 292 - Loss:   729.6505 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 293 - Loss:   501.7968 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 294 - Loss:   605.4340 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 295 - Loss:   642.7416 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 296 - Loss:   674.1514 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 297 - Loss:   570.4842 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 298 - Loss:   644.1119 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 299 - Loss:   918.9335 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 300 - Loss:   695.8401 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 301 - Loss:   672.8684 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 302 - Loss:   682.9269 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 303 - Loss:   599.5486 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 304 - Loss:   796.0874 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 305 - Loss:   610.9517 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 306 - Loss:   972.4758 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 307 - Loss:   424.0451 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 308 - Loss:   731.3609 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 309 - Loss:   621.3920 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 310 - Loss:   875.9430 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 311 - Loss:   799.5247 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 312 - Loss:   610.0459 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 313 - Loss:   679.3468 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 314 - Loss:   653.3894 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 315 - Loss:   399.2673 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 316 - Loss:   714.7148 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 317 - Loss:   602.7852 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 318 - Loss:   537.3105 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 319 - Loss:  1135.0643 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 320 - Loss:   836.3677 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 321 - Loss:   662.0167 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 322 - Loss:   420.5965 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 323 - Loss:   648.8207 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 324 - Loss:   636.2145 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 325 - Loss:   464.2452 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 326 - Loss:   738.3936 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 327 - Loss:   711.0077 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 328 - Loss:   716.8273 Validation Accuracy: 0.804688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch 329 - Loss:   466.0532 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 330 - Loss:   526.2487 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 331 - Loss:   459.4362 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 332 - Loss:   552.1703 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 333 - Loss:   676.1224 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 334 - Loss:   799.0375 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 335 - Loss:   516.0973 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 336 - Loss:   651.4151 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 337 - Loss:   404.4590 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 338 - Loss:   733.9017 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 339 - Loss:   681.2437 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 340 - Loss:   842.6488 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 341 - Loss:   375.9953 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 342 - Loss:   483.4234 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 343 - Loss:   594.8627 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 344 - Loss:   581.5211 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 345 - Loss:   649.9718 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 346 - Loss:   732.4150 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 347 - Loss:   343.0236 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 348 - Loss:   552.9756 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 349 - Loss:   725.6276 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 350 - Loss:   662.9427 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 351 - Loss:   688.4204 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 352 - Loss:   672.3170 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 353 - Loss:   658.6641 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 354 - Loss:   537.4271 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 355 - Loss:   936.5421 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 356 - Loss:   549.5641 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 357 - Loss:   453.1946 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 358 - Loss:   741.3892 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 359 - Loss:   405.3638 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 360 - Loss:   547.7078 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 361 - Loss:   572.7163 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 362 - Loss:   874.6083 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 363 - Loss:   569.5638 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 364 - Loss:   426.8636 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 365 - Loss:   616.5627 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 366 - Loss:   683.1617 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 367 - Loss:   612.4348 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 368 - Loss:   494.6036 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 369 - Loss:   796.6049 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 370 - Loss:   587.1638 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 371 - Loss:   265.9510 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 372 - Loss:   949.0245 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 373 - Loss:   765.6543 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 374 - Loss:   721.4150 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 375 - Loss:   768.5055 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 376 - Loss:   824.8334 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 377 - Loss:   637.6655 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 378 - Loss:   593.3864 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 379 - Loss:   700.6284 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 380 - Loss:   664.3027 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 381 - Loss:   728.8523 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 382 - Loss:   522.9246 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 383 - Loss:   834.7231 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 384 - Loss:   314.8793 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 385 - Loss:   582.7529 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 386 - Loss:   737.6251 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 387 - Loss:   569.2967 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 388 - Loss:   665.4537 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 389 - Loss:   695.9326 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 390 - Loss:   585.0782 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 391 - Loss:   450.6013 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 392 - Loss:   700.4971 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 393 - Loss:   486.7770 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 394 - Loss:   663.0142 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 395 - Loss:   523.6295 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 396 - Loss:   653.3877 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 397 - Loss:   478.3387 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 398 - Loss:   649.6511 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 399 - Loss:   613.0514 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 400 - Loss:   919.1816 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 401 - Loss:   613.3750 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 402 - Loss:   615.3207 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 403 - Loss:   923.7424 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 404 - Loss:   627.8082 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 405 - Loss:   600.3303 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 406 - Loss:   769.1042 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 407 - Loss:   619.3067 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 408 - Loss:   672.8326 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 409 - Loss:   648.2157 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 410 - Loss:   731.2309 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 411 - Loss:   569.6469 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 412 - Loss:   622.1570 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 413 - Loss:   611.2074 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 414 - Loss:   630.0917 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 415 - Loss:   499.2222 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 416 - Loss:   762.6577 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 417 - Loss:   658.3852 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 418 - Loss:  1054.4963 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 419 - Loss:   468.5199 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 420 - Loss:   510.3432 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 421 - Loss:   481.1958 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 422 - Loss:   623.8000 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 423 - Loss:   538.1454 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 424 - Loss:   568.4124 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 425 - Loss:   677.2796 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 426 - Loss:   417.6534 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 427 - Loss:   370.1415 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 428 - Loss:   614.6124 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 429 - Loss:   572.0726 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch   1 - Loss:   700.9805 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch   2 - Loss:   514.6053 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch   3 - Loss:   612.1267 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch   4 - Loss:   640.2468 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch   5 - Loss:   600.8556 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch   6 - Loss:   939.2079 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch   7 - Loss:   578.2546 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch   8 - Loss:   806.6447 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch   9 - Loss:   599.1964 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  10 - Loss:   841.2869 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  11 - Loss:   475.1703 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  12 - Loss:   556.7608 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  13 - Loss:   654.6409 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  14 - Loss:   612.7878 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  15 - Loss:   716.4232 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  16 - Loss:   462.3035 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  17 - Loss:   939.7449 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  18 - Loss:   650.2552 Validation Accuracy: 0.800781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch  19 - Loss:   394.7606 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  20 - Loss:   864.8138 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  21 - Loss:   590.5033 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  22 - Loss:   718.7798 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  23 - Loss:   622.6447 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  24 - Loss:  1042.3215 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  25 - Loss:   553.4059 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  26 - Loss:   801.1517 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  27 - Loss:   331.6179 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  28 - Loss:   986.1506 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  29 - Loss:   718.0825 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  30 - Loss:   434.9366 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  31 - Loss:   664.4824 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  32 - Loss:   504.5627 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  33 - Loss:   385.4778 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  34 - Loss:   590.3326 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  35 - Loss:   601.7880 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  36 - Loss:   458.2300 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  37 - Loss:   525.2629 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  38 - Loss:   520.4701 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  39 - Loss:   649.2601 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  40 - Loss:   591.7786 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  41 - Loss:   426.4124 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  42 - Loss:   625.5952 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  43 - Loss:   647.8900 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  44 - Loss:   597.1561 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  45 - Loss:   648.2395 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  46 - Loss:   753.3547 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  47 - Loss:   549.7484 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  48 - Loss:   654.3950 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  49 - Loss:   987.5021 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  50 - Loss:   753.9618 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  51 - Loss:   723.0394 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  52 - Loss:   775.8977 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  53 - Loss:   355.5555 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  54 - Loss:   539.8123 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  55 - Loss:   455.0408 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  56 - Loss:   421.8784 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  57 - Loss:   324.4054 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  58 - Loss:   426.2604 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  59 - Loss:   396.0156 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  60 - Loss:   507.7587 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  61 - Loss:   558.4481 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  62 - Loss:   813.9139 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  63 - Loss:   665.5062 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  64 - Loss:   635.4996 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  65 - Loss:   487.6702 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  66 - Loss:   505.4722 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  67 - Loss:   517.3918 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  68 - Loss:   825.1186 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  69 - Loss:   702.8911 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  70 - Loss:   558.1500 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  71 - Loss:   715.8113 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  72 - Loss:   706.7564 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  73 - Loss:   506.2634 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  74 - Loss:   394.9408 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  75 - Loss:   502.8317 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  76 - Loss:   740.3965 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  77 - Loss:   415.8289 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  78 - Loss:   592.6392 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  79 - Loss:   678.9102 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  80 - Loss:   512.0510 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  81 - Loss:   600.5311 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  82 - Loss:   550.4587 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  83 - Loss:   434.9064 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  84 - Loss:   680.8510 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  85 - Loss:   368.4144 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  86 - Loss:   390.2170 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  87 - Loss:   406.6722 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  88 - Loss:   611.8387 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  89 - Loss:   588.1090 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  90 - Loss:   665.7115 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  91 - Loss:   632.6687 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  92 - Loss:   471.4975 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  93 - Loss:   433.4792 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  94 - Loss:   546.1765 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  95 - Loss:   705.5659 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  96 - Loss:   671.4260 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  97 - Loss:   757.3766 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  98 - Loss:   557.1696 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  99 - Loss:   614.5798 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 100 - Loss:   539.7083 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 101 - Loss:   644.4180 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 102 - Loss:   211.7912 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 103 - Loss:   508.8420 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 104 - Loss:   443.6863 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 105 - Loss:   727.7469 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 106 - Loss:   713.3761 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 107 - Loss:   584.5634 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 108 - Loss:   732.1796 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 109 - Loss:   719.1404 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 110 - Loss:   592.3445 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 111 - Loss:   662.2262 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 112 - Loss:   618.2507 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 113 - Loss:   799.9421 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 114 - Loss:   547.1398 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 115 - Loss:   555.2386 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 116 - Loss:   607.7213 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 117 - Loss:   466.3060 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 118 - Loss:   596.5902 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 119 - Loss:   406.9806 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 120 - Loss:   602.5015 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 121 - Loss:   547.8632 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 122 - Loss:   381.5842 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 123 - Loss:   662.2764 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 124 - Loss:   757.5474 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 125 - Loss:   591.9760 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 126 - Loss:   642.2551 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 127 - Loss:   633.7513 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 128 - Loss:   721.1949 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 129 - Loss:   765.8663 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 130 - Loss:   614.1489 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 131 - Loss:   489.1921 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 132 - Loss:   600.2744 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 133 - Loss:   628.5392 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 134 - Loss:   781.5729 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 135 - Loss:   624.8207 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 136 - Loss:   549.0491 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 137 - Loss:   208.1336 Validation Accuracy: 0.816406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch 138 - Loss:   508.3243 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 139 - Loss:   300.8898 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 140 - Loss:   392.2956 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 141 - Loss:   686.2223 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 142 - Loss:   528.7405 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 143 - Loss:   757.1906 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 144 - Loss:   640.4359 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 145 - Loss:   479.4574 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 146 - Loss:   378.0776 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 147 - Loss:   611.7232 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 148 - Loss:   838.3909 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 149 - Loss:   418.3577 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 150 - Loss:   543.6155 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 151 - Loss:   410.9091 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 152 - Loss:   508.5953 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 153 - Loss:   775.5223 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 154 - Loss:   542.8010 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 155 - Loss:   386.9453 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 156 - Loss:   421.9495 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 157 - Loss:   498.7774 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 158 - Loss:   537.2344 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 159 - Loss:   631.7861 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 160 - Loss:   473.0662 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 161 - Loss:   711.0820 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 162 - Loss:   577.5424 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 163 - Loss:   528.3245 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 164 - Loss:   319.0707 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 165 - Loss:   684.8013 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 166 - Loss:   558.9095 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 167 - Loss:   635.2953 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 168 - Loss:   552.6754 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 169 - Loss:   493.4127 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 170 - Loss:   738.2371 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 171 - Loss:   565.6610 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 172 - Loss:   529.5750 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 173 - Loss:   758.7896 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 174 - Loss:   785.1760 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 175 - Loss:   649.1294 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 176 - Loss:   506.6588 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 177 - Loss:   489.0373 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 178 - Loss:   508.7289 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 179 - Loss:   345.1813 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 180 - Loss:   400.6926 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 181 - Loss:   361.4459 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 182 - Loss:   487.7830 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 183 - Loss:   627.7565 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 184 - Loss:   360.3416 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 185 - Loss:   418.4236 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 186 - Loss:   619.2936 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 187 - Loss:   633.4630 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 188 - Loss:   622.5623 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 189 - Loss:   641.8761 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 190 - Loss:   703.5034 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 191 - Loss:   264.1620 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 192 - Loss:   590.2287 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 193 - Loss:   428.8062 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 194 - Loss:   566.2603 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 195 - Loss:   565.6611 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 196 - Loss:   577.3794 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 197 - Loss:   815.4619 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 198 - Loss:   639.9197 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 199 - Loss:   360.2402 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 200 - Loss:   402.8710 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 201 - Loss:   338.4014 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 202 - Loss:   719.5780 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 203 - Loss:   562.5928 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 204 - Loss:   462.0352 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 205 - Loss:   439.9169 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 206 - Loss:   639.1365 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 207 - Loss:   518.8287 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 208 - Loss:   579.0527 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 209 - Loss:   866.2039 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 210 - Loss:   616.5086 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 211 - Loss:   432.3287 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 212 - Loss:   408.8066 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 213 - Loss:   484.2923 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 214 - Loss:   525.2349 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 215 - Loss:   640.6290 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 216 - Loss:   608.7301 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 217 - Loss:   675.1268 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 218 - Loss:   500.3629 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 219 - Loss:   734.5307 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 220 - Loss:   740.6555 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 221 - Loss:   408.5905 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 222 - Loss:   535.1982 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 223 - Loss:   856.9959 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 224 - Loss:   527.7972 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 225 - Loss:   608.0225 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 226 - Loss:   429.6430 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 227 - Loss:   580.3032 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 228 - Loss:   623.6196 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 229 - Loss:   473.9488 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 230 - Loss:   402.0417 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 231 - Loss:   696.9194 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 232 - Loss:   330.5766 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 233 - Loss:   627.3975 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 234 - Loss:   302.4434 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 235 - Loss:   429.0022 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 236 - Loss:   227.7599 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 237 - Loss:   506.4516 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 238 - Loss:   488.4012 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 239 - Loss:   672.7909 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 240 - Loss:   496.3408 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 241 - Loss:   432.2809 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 242 - Loss:   523.9093 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 243 - Loss:   637.1768 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 244 - Loss:   465.4743 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 245 - Loss:   771.9028 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 246 - Loss:   744.2706 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 247 - Loss:   481.2453 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 248 - Loss:   407.4435 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 249 - Loss:   555.3183 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 250 - Loss:   353.9882 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 251 - Loss:   479.4660 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 252 - Loss:   496.5570 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 253 - Loss:   597.4742 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 254 - Loss:   679.4562 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 255 - Loss:   297.7525 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 256 - Loss:   380.4042 Validation Accuracy: 0.808594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch 257 - Loss:   329.5090 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 258 - Loss:   491.7665 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 259 - Loss:   800.7369 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 260 - Loss:   703.8407 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 261 - Loss:   592.6467 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 262 - Loss:   542.3805 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 263 - Loss:   247.6235 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 264 - Loss:   414.5144 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 265 - Loss:   374.7832 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 266 - Loss:   482.8857 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 267 - Loss:   610.5169 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 268 - Loss:   605.7927 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 269 - Loss:   554.0134 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 270 - Loss:   686.2127 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 271 - Loss:   319.1492 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 272 - Loss:   808.2424 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 273 - Loss:   502.2898 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 274 - Loss:   643.3184 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 275 - Loss:   289.1191 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 276 - Loss:   552.5701 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 277 - Loss:   314.1652 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 278 - Loss:   681.5161 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 279 - Loss:   903.3911 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 280 - Loss:   566.8427 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 281 - Loss:   535.0596 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 282 - Loss:   342.1574 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 283 - Loss:   538.4334 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 284 - Loss:   724.6154 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 285 - Loss:   512.5201 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 286 - Loss:   460.0696 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 287 - Loss:   629.2709 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 288 - Loss:   526.2913 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 289 - Loss:   604.2415 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 290 - Loss:   474.6730 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 291 - Loss:   562.0057 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 292 - Loss:   567.4081 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 293 - Loss:   347.0863 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 294 - Loss:   541.4839 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 295 - Loss:   755.5559 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 296 - Loss:   434.0717 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 297 - Loss:   484.9415 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 298 - Loss:   490.3647 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 299 - Loss:   764.5198 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 300 - Loss:   574.5790 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 301 - Loss:   235.2473 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 302 - Loss:   315.3071 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 303 - Loss:   728.4194 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 304 - Loss:   443.1548 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 305 - Loss:   651.6118 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 306 - Loss:   563.6719 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 307 - Loss:   318.3124 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 308 - Loss:   697.8063 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 309 - Loss:   711.7266 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 310 - Loss:   436.3002 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 311 - Loss:   447.8259 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 312 - Loss:   646.2371 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 313 - Loss:   684.4833 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 314 - Loss:   426.8110 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 315 - Loss:   445.6863 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 316 - Loss:   338.7550 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 317 - Loss:   432.5767 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 318 - Loss:   564.3638 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 319 - Loss:   478.1152 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 320 - Loss:   537.3186 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 321 - Loss:   658.4861 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 322 - Loss:   575.8181 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 323 - Loss:   535.1908 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 324 - Loss:   464.6436 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 325 - Loss:   383.2079 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 326 - Loss:   580.4666 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 327 - Loss:   609.5590 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 328 - Loss:   585.4252 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 329 - Loss:   447.7563 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 330 - Loss:   577.2446 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 331 - Loss:   429.0215 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 332 - Loss:   580.1401 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 333 - Loss:   468.3175 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 334 - Loss:   507.1387 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 335 - Loss:   403.1902 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 336 - Loss:   455.5750 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 337 - Loss:   415.7586 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 338 - Loss:   343.7520 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 339 - Loss:   377.2440 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 340 - Loss:   516.8977 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 341 - Loss:   445.1721 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 342 - Loss:   514.0098 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 343 - Loss:   511.7159 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 344 - Loss:   374.4061 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 345 - Loss:   313.4383 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 346 - Loss:   460.1117 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 347 - Loss:   401.8970 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 348 - Loss:   596.4651 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 349 - Loss:   542.3536 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 350 - Loss:   413.1788 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 351 - Loss:   392.6493 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 352 - Loss:   650.9688 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 353 - Loss:   429.8124 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 354 - Loss:   451.2317 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 355 - Loss:   315.8766 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 356 - Loss:   410.7550 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 357 - Loss:   565.0864 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 358 - Loss:   389.0776 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 359 - Loss:   598.8223 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 360 - Loss:   322.7700 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 361 - Loss:   615.4543 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 362 - Loss:   326.8813 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 363 - Loss:   457.0567 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 364 - Loss:   558.2222 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 365 - Loss:   454.4394 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 366 - Loss:   569.9258 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 367 - Loss:   330.9005 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 368 - Loss:   445.6588 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 369 - Loss:   532.5868 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 370 - Loss:   257.6190 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 371 - Loss:   497.1072 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 372 - Loss:   391.9951 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 373 - Loss:   579.1206 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 374 - Loss:   580.2825 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 375 - Loss:   604.3558 Validation Accuracy: 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4, Batch 376 - Loss:   280.1678 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 377 - Loss:   585.4136 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 378 - Loss:   493.8848 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 379 - Loss:   660.9659 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 380 - Loss:   329.1421 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 381 - Loss:   524.8317 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 382 - Loss:   543.9380 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 383 - Loss:   478.4713 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 384 - Loss:   552.7919 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 385 - Loss:   395.8598 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 386 - Loss:   486.6583 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 387 - Loss:   438.6273 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 388 - Loss:   656.4114 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 389 - Loss:   554.3280 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 390 - Loss:   344.1722 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 391 - Loss:   656.2426 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 392 - Loss:   499.7273 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 393 - Loss:   471.6515 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 394 - Loss:   304.0081 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 395 - Loss:   442.9518 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 396 - Loss:   442.9428 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 397 - Loss:   479.3477 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 398 - Loss:   456.9884 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 399 - Loss:   347.2898 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 400 - Loss:   337.3823 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 401 - Loss:   507.3337 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 402 - Loss:   567.6345 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 403 - Loss:   267.7881 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 404 - Loss:   319.8787 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 405 - Loss:   403.2227 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 406 - Loss:   533.9860 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 407 - Loss:   328.7665 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 408 - Loss:   521.5523 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 409 - Loss:   312.4487 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 410 - Loss:   526.9580 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 411 - Loss:   366.3633 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 412 - Loss:   299.4118 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 413 - Loss:   342.4955 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 414 - Loss:   337.6136 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 415 - Loss:   359.9095 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 416 - Loss:   493.9678 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 417 - Loss:   516.3561 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 418 - Loss:   660.6058 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 419 - Loss:   498.7760 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 420 - Loss:   442.1825 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 421 - Loss:   480.2215 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 422 - Loss:   746.8699 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 423 - Loss:   457.4788 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 424 - Loss:   611.2083 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 425 - Loss:   459.3452 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 426 - Loss:   527.0770 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 427 - Loss:   571.8911 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 428 - Loss:   464.6895 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 429 - Loss:   285.8911 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch   1 - Loss:   500.9472 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch   2 - Loss:   344.0182 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch   3 - Loss:   595.7488 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch   4 - Loss:   391.2827 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch   5 - Loss:   516.0199 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch   6 - Loss:   361.6103 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch   7 - Loss:   504.9286 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch   8 - Loss:   411.6661 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch   9 - Loss:   387.8690 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  10 - Loss:   381.5201 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  11 - Loss:   667.9194 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  12 - Loss:   363.2110 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  13 - Loss:   425.0027 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  14 - Loss:   542.0281 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  15 - Loss:   520.1363 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  16 - Loss:   264.9877 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  17 - Loss:   376.3263 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  18 - Loss:   549.4944 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  19 - Loss:   315.8036 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  20 - Loss:   367.5119 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  21 - Loss:   526.4979 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  22 - Loss:   417.1369 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  23 - Loss:   494.0677 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  24 - Loss:   500.5738 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  25 - Loss:   461.2681 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  26 - Loss:   497.5842 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  27 - Loss:   414.9654 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  28 - Loss:   453.6309 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  29 - Loss:   489.3302 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  30 - Loss:   556.9377 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  31 - Loss:   412.6948 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  32 - Loss:   441.3627 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch  33 - Loss:   369.9654 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  34 - Loss:   580.1564 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  35 - Loss:   421.0681 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  36 - Loss:   510.5383 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  37 - Loss:   520.8428 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  38 - Loss:   443.1908 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  39 - Loss:   541.6102 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  40 - Loss:   625.3832 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  41 - Loss:   422.8532 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  42 - Loss:   570.1568 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  43 - Loss:   520.7510 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  44 - Loss:   470.7357 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  45 - Loss:   389.3612 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  46 - Loss:   671.2615 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  47 - Loss:   209.8638 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  48 - Loss:   632.9511 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  49 - Loss:   534.3600 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  50 - Loss:   527.1356 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  51 - Loss:   649.8488 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  52 - Loss:   425.0211 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  53 - Loss:   437.8354 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  54 - Loss:   395.7751 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  55 - Loss:   576.1219 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  56 - Loss:   300.6573 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  57 - Loss:   595.2466 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  58 - Loss:   510.5204 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  59 - Loss:   617.7850 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  60 - Loss:   246.6025 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  61 - Loss:   410.2051 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  62 - Loss:   524.1729 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  63 - Loss:   624.2366 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  64 - Loss:   329.0295 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  65 - Loss:   409.0646 Validation Accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch  66 - Loss:   382.2885 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  67 - Loss:   410.1107 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  68 - Loss:   286.8733 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  69 - Loss:   594.7911 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  70 - Loss:   509.3953 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  71 - Loss:   495.3033 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  72 - Loss:   308.1716 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  73 - Loss:   458.5591 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  74 - Loss:   260.4152 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  75 - Loss:   460.6841 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  76 - Loss:   467.1891 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  77 - Loss:   342.9665 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  78 - Loss:   492.3617 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  79 - Loss:   393.5638 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  80 - Loss:   631.4186 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  81 - Loss:   452.9622 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  82 - Loss:   524.3743 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  83 - Loss:   507.6862 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  84 - Loss:   515.5704 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  85 - Loss:   729.1161 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch  86 - Loss:   504.0156 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  87 - Loss:   406.8281 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch  88 - Loss:   416.2574 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  89 - Loss:   449.2477 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  90 - Loss:   373.5304 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  91 - Loss:   334.7786 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  92 - Loss:   750.6143 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  93 - Loss:   439.2512 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  94 - Loss:   419.5715 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch  95 - Loss:   582.4283 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  96 - Loss:   500.0948 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch  97 - Loss:   635.1625 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  98 - Loss:   350.2560 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch  99 - Loss:   255.9801 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 100 - Loss:   482.5059 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 101 - Loss:   280.8915 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 102 - Loss:   387.0892 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 103 - Loss:   431.8218 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 104 - Loss:   240.6487 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 105 - Loss:   530.2672 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 106 - Loss:   344.6078 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 107 - Loss:   611.0081 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 108 - Loss:   394.9992 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 109 - Loss:   589.7686 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 110 - Loss:   381.8367 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 111 - Loss:   789.8453 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 112 - Loss:   538.4164 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 113 - Loss:   671.4976 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 114 - Loss:   596.3579 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 115 - Loss:   286.0038 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 116 - Loss:   549.1527 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 117 - Loss:   442.8541 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 118 - Loss:   599.6894 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 119 - Loss:   583.1906 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 120 - Loss:   455.3538 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 121 - Loss:   401.2887 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 122 - Loss:   650.0488 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 123 - Loss:   389.5930 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 124 - Loss:   276.1070 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 125 - Loss:   586.9002 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 126 - Loss:   296.8150 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 127 - Loss:   452.4563 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 128 - Loss:   434.2533 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 129 - Loss:   584.8401 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 130 - Loss:   554.1508 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 131 - Loss:   257.1945 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 132 - Loss:   325.4965 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 133 - Loss:   483.8304 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 134 - Loss:   636.9575 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 135 - Loss:   420.4686 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 136 - Loss:   396.6487 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 137 - Loss:   625.9790 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 138 - Loss:   534.2850 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 139 - Loss:   582.8096 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 140 - Loss:   541.7989 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 141 - Loss:   331.3229 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 142 - Loss:   495.2277 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 143 - Loss:   378.9391 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 144 - Loss:   463.7081 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 145 - Loss:   467.9243 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 146 - Loss:   564.9825 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 147 - Loss:   535.1573 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 148 - Loss:   391.1880 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 149 - Loss:   658.1483 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 150 - Loss:   355.0273 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 151 - Loss:   544.0160 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 152 - Loss:   382.6851 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 153 - Loss:   372.9449 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 154 - Loss:   440.0875 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 155 - Loss:   423.9717 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 156 - Loss:   180.6280 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 157 - Loss:   350.9206 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 158 - Loss:   366.6241 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 159 - Loss:   548.1761 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 160 - Loss:   497.9314 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 161 - Loss:   486.7683 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 162 - Loss:   322.8795 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 163 - Loss:   442.6312 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 164 - Loss:   572.5903 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 165 - Loss:   412.4257 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 166 - Loss:   404.9375 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 167 - Loss:   456.6019 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 168 - Loss:   394.3110 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 169 - Loss:   382.6819 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 170 - Loss:   452.4995 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 171 - Loss:   568.8489 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 172 - Loss:   586.2361 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 173 - Loss:   303.9281 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 174 - Loss:   492.3724 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 175 - Loss:   423.7740 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 176 - Loss:   373.5524 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 177 - Loss:   354.1684 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 178 - Loss:   382.8181 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 179 - Loss:   264.2288 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 180 - Loss:   355.6176 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 181 - Loss:   386.5715 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 182 - Loss:   260.6691 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 183 - Loss:   565.8716 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 184 - Loss:   561.0027 Validation Accuracy: 0.832031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch 185 - Loss:   443.2770 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 186 - Loss:   213.1736 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 187 - Loss:   382.2551 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 188 - Loss:   377.5659 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 189 - Loss:   660.8179 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 190 - Loss:   356.7187 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 191 - Loss:   337.5821 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 192 - Loss:   417.9756 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 193 - Loss:   501.4031 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 194 - Loss:   428.7911 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 195 - Loss:   471.3898 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 196 - Loss:   415.9320 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 197 - Loss:   486.9232 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 198 - Loss:   444.2195 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 199 - Loss:   418.0032 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 200 - Loss:   575.5027 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 201 - Loss:   293.5268 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 202 - Loss:   232.2280 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 203 - Loss:   293.2699 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 204 - Loss:   358.9672 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 205 - Loss:   393.4686 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 206 - Loss:   579.9113 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 207 - Loss:   499.8473 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 208 - Loss:   428.3813 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 209 - Loss:   323.3645 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 210 - Loss:   483.8774 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 211 - Loss:   353.3884 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 212 - Loss:   385.1145 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 213 - Loss:   488.3796 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 214 - Loss:   460.8661 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 215 - Loss:   451.8852 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 216 - Loss:   261.5005 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 217 - Loss:   531.3010 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 218 - Loss:   348.2956 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 219 - Loss:   501.4951 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 220 - Loss:   432.1633 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 221 - Loss:   408.7617 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 222 - Loss:   491.5384 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 223 - Loss:   415.2971 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 224 - Loss:   571.8195 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 225 - Loss:   533.0829 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 226 - Loss:   419.2120 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 227 - Loss:   533.2747 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 228 - Loss:   388.3504 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 229 - Loss:   541.9355 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 230 - Loss:   423.7362 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 231 - Loss:   445.3075 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 232 - Loss:   737.5187 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 233 - Loss:   378.8584 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 234 - Loss:   416.7904 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 235 - Loss:   327.9614 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 236 - Loss:   664.4014 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 237 - Loss:   392.3631 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 238 - Loss:   299.9016 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 239 - Loss:   501.8595 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 240 - Loss:   444.2920 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 241 - Loss:   226.2372 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 242 - Loss:   355.8433 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 243 - Loss:   348.7076 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 244 - Loss:   456.6405 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 245 - Loss:   362.0341 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 246 - Loss:   347.6206 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 247 - Loss:   489.8246 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 248 - Loss:   236.7560 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 249 - Loss:   563.3911 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 250 - Loss:   485.7431 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 251 - Loss:   480.9679 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 252 - Loss:   542.4178 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 253 - Loss:   413.7026 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 254 - Loss:   390.4175 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 255 - Loss:   431.2690 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 256 - Loss:   387.9469 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 257 - Loss:   420.3723 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 258 - Loss:   407.3964 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 259 - Loss:   592.9475 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 260 - Loss:   485.6089 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 261 - Loss:   539.9861 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 262 - Loss:   447.0936 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 263 - Loss:   422.5823 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 264 - Loss:   427.6351 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 265 - Loss:   159.0213 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 266 - Loss:   249.1068 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 267 - Loss:   420.5559 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 268 - Loss:   327.2841 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 269 - Loss:   370.1504 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 270 - Loss:   463.0240 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 271 - Loss:   359.9957 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 272 - Loss:   432.7478 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 273 - Loss:   430.9854 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 274 - Loss:   322.3516 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 275 - Loss:   533.7131 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 276 - Loss:   553.2836 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 277 - Loss:   418.0189 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 278 - Loss:   490.3032 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 279 - Loss:   492.2898 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 280 - Loss:   423.7920 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 281 - Loss:   447.7056 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 282 - Loss:   409.1088 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 283 - Loss:   677.3900 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 284 - Loss:   434.8677 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 285 - Loss:   510.3237 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 286 - Loss:   443.4992 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 287 - Loss:   405.6602 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 288 - Loss:   497.9181 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 289 - Loss:   330.1691 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 290 - Loss:   401.5046 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 291 - Loss:   386.5203 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 292 - Loss:   293.6058 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 293 - Loss:   336.7865 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 294 - Loss:   434.0677 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 295 - Loss:   392.0578 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 296 - Loss:   267.5270 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 297 - Loss:   249.9756 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 298 - Loss:   689.7172 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 299 - Loss:   449.9149 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 300 - Loss:   423.3439 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 301 - Loss:   435.3112 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 302 - Loss:   443.4781 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 303 - Loss:   389.2149 Validation Accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch 304 - Loss:   205.6932 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 305 - Loss:   383.9231 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 306 - Loss:   411.7532 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 307 - Loss:   410.1636 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 308 - Loss:   426.0336 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 309 - Loss:   496.2642 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 310 - Loss:   516.9398 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 311 - Loss:   349.5902 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 312 - Loss:   507.5421 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 313 - Loss:   386.1833 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 314 - Loss:   549.2927 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 315 - Loss:   384.6654 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 316 - Loss:   382.3524 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 317 - Loss:   438.9705 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 318 - Loss:   367.2709 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 319 - Loss:   482.2620 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 320 - Loss:   439.5279 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 321 - Loss:   433.0894 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 322 - Loss:   354.6256 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 323 - Loss:   397.7983 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 324 - Loss:   633.0446 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 325 - Loss:   396.1099 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 326 - Loss:   482.8767 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 327 - Loss:   308.3175 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 328 - Loss:   447.8004 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 329 - Loss:   290.4337 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 330 - Loss:   507.9852 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 331 - Loss:   237.7984 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 332 - Loss:   443.0104 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 333 - Loss:   410.8546 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 334 - Loss:   330.0637 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 335 - Loss:   513.4448 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 336 - Loss:   412.8050 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 337 - Loss:   425.6853 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 338 - Loss:   416.0656 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 339 - Loss:   477.4061 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 340 - Loss:   214.3281 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 341 - Loss:   416.8862 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 342 - Loss:   369.0507 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 343 - Loss:   369.1828 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 344 - Loss:   339.3446 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 345 - Loss:   273.0855 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 346 - Loss:   468.5593 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 347 - Loss:   471.8487 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 348 - Loss:   397.6891 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 349 - Loss:   228.4246 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 350 - Loss:   424.6876 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 351 - Loss:   376.0559 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 352 - Loss:   419.6714 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 353 - Loss:   256.4573 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 354 - Loss:   423.4894 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 355 - Loss:   380.2491 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 356 - Loss:   456.5155 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 357 - Loss:   280.1139 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 358 - Loss:   303.8213 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 359 - Loss:   345.5797 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 360 - Loss:   408.5292 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 361 - Loss:   284.7339 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 362 - Loss:   527.8603 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 363 - Loss:   309.4008 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 364 - Loss:   388.5974 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 365 - Loss:   510.8978 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 366 - Loss:   327.4755 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 367 - Loss:   450.6370 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 368 - Loss:   568.4044 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 369 - Loss:   271.5855 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 370 - Loss:   365.2828 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 371 - Loss:   432.6542 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 372 - Loss:   312.2957 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 373 - Loss:   275.2566 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 374 - Loss:   429.3351 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 375 - Loss:   268.6017 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 376 - Loss:   290.2656 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 377 - Loss:   521.1899 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 378 - Loss:   312.7205 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 379 - Loss:   337.6169 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 380 - Loss:   352.6147 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 381 - Loss:   253.9333 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 382 - Loss:   395.7104 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 383 - Loss:   529.8605 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 384 - Loss:   279.8181 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 385 - Loss:   507.4209 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 386 - Loss:   302.9360 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 387 - Loss:   536.7450 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 388 - Loss:   215.6697 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 389 - Loss:   328.7357 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 390 - Loss:   251.3009 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 391 - Loss:   557.5867 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 392 - Loss:   316.0898 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 393 - Loss:   380.5623 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 394 - Loss:   250.9233 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 395 - Loss:   339.9041 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 396 - Loss:   346.6418 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 397 - Loss:   426.9172 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 398 - Loss:   539.0969 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 399 - Loss:   370.2115 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 400 - Loss:   382.3744 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 401 - Loss:   300.7356 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 402 - Loss:   394.2675 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 403 - Loss:   359.8587 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 404 - Loss:   532.7931 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 405 - Loss:   412.3119 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 406 - Loss:   467.7917 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 407 - Loss:   414.6655 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 408 - Loss:   301.3416 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 409 - Loss:   335.2092 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 410 - Loss:   238.5556 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 411 - Loss:   310.0315 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 412 - Loss:   351.3683 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 413 - Loss:   483.9597 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 414 - Loss:   414.5437 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 415 - Loss:   438.2251 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 416 - Loss:   496.5854 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 417 - Loss:   243.5647 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 418 - Loss:   393.8952 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 419 - Loss:   283.0668 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 420 - Loss:   524.2595 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 421 - Loss:   258.7581 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 422 - Loss:   431.9591 Validation Accuracy: 0.839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5, Batch 423 - Loss:   382.2659 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 424 - Loss:   368.9159 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 425 - Loss:   293.4322 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 426 - Loss:   316.7186 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 427 - Loss:   483.1703 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 428 - Loss:   529.5312 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 429 - Loss:   314.5543 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch   1 - Loss:   363.9670 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch   2 - Loss:   393.7911 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch   3 - Loss:   394.6754 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch   4 - Loss:   187.4645 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch   5 - Loss:   406.8525 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch   6 - Loss:   338.3420 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch   7 - Loss:   242.3544 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch   8 - Loss:   386.7979 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch   9 - Loss:   592.0303 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  10 - Loss:   197.2632 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  11 - Loss:   428.5949 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  12 - Loss:   322.0272 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  13 - Loss:   434.8547 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  14 - Loss:   441.6780 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  15 - Loss:   266.7768 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  16 - Loss:   426.6186 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  17 - Loss:   364.2424 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  18 - Loss:   391.7369 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  19 - Loss:   346.1452 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  20 - Loss:   337.2578 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  21 - Loss:   391.1359 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  22 - Loss:   379.3565 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  23 - Loss:   256.6729 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  24 - Loss:   350.7900 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  25 - Loss:   509.8803 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  26 - Loss:   311.4928 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  27 - Loss:   300.8179 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  28 - Loss:   443.7596 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  29 - Loss:   499.3737 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  30 - Loss:   349.8859 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  31 - Loss:   260.2505 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  32 - Loss:   322.2802 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  33 - Loss:   382.0372 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  34 - Loss:   420.7607 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  35 - Loss:   370.2564 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  36 - Loss:   440.4391 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  37 - Loss:   473.4767 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  38 - Loss:   461.2070 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  39 - Loss:   366.1452 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  40 - Loss:   283.8511 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  41 - Loss:   329.7226 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  42 - Loss:   279.9834 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  43 - Loss:   306.4975 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  44 - Loss:   400.7544 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  45 - Loss:   245.5993 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  46 - Loss:   404.7116 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  47 - Loss:   478.6667 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  48 - Loss:   399.2964 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  49 - Loss:   422.4155 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  50 - Loss:   356.1575 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  51 - Loss:   401.1799 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  52 - Loss:   478.3966 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  53 - Loss:   401.2374 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  54 - Loss:   296.9227 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  55 - Loss:   497.0320 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  56 - Loss:   373.4725 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  57 - Loss:   291.4378 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  58 - Loss:   383.6968 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  59 - Loss:   454.7305 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  60 - Loss:   278.1895 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  61 - Loss:   499.1938 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  62 - Loss:   476.4664 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  63 - Loss:   296.4189 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  64 - Loss:   253.8026 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  65 - Loss:   248.2433 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  66 - Loss:   231.9814 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  67 - Loss:   551.4310 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  68 - Loss:   432.9090 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  69 - Loss:   114.4278 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  70 - Loss:   391.2444 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  71 - Loss:   327.3729 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  72 - Loss:   235.1836 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  73 - Loss:   631.2611 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  74 - Loss:   250.7057 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  75 - Loss:   310.8096 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  76 - Loss:   595.6188 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  77 - Loss:   323.5669 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  78 - Loss:   457.9523 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  79 - Loss:   302.8842 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  80 - Loss:   386.4344 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  81 - Loss:   271.5374 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  82 - Loss:   342.3846 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch  83 - Loss:   355.7777 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  84 - Loss:   365.3584 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  85 - Loss:   580.1769 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  86 - Loss:   421.4650 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  87 - Loss:   220.7256 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  88 - Loss:   492.0783 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  89 - Loss:   425.9746 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  90 - Loss:   277.3353 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  91 - Loss:   174.3526 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch  92 - Loss:   603.2647 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  93 - Loss:   508.7861 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  94 - Loss:   546.8402 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  95 - Loss:   271.5763 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  96 - Loss:   251.0184 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  97 - Loss:   421.8392 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  98 - Loss:   540.1758 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  99 - Loss:   279.9504 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 100 - Loss:   405.3357 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 101 - Loss:   439.8450 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 102 - Loss:   344.2499 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 103 - Loss:   542.4003 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 104 - Loss:   365.2993 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 105 - Loss:   465.3006 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 106 - Loss:   530.2864 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 107 - Loss:   288.3882 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 108 - Loss:   480.5962 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 109 - Loss:   333.7268 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 110 - Loss:   320.6286 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 111 - Loss:   393.1302 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 112 - Loss:   455.1814 Validation Accuracy: 0.824219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch 113 - Loss:   323.1816 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 114 - Loss:   301.8705 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 115 - Loss:   283.0786 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 116 - Loss:   492.4966 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 117 - Loss:   534.2202 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 118 - Loss:   364.1276 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 119 - Loss:   563.5433 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 120 - Loss:   405.2617 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 121 - Loss:   530.0829 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 122 - Loss:   320.7630 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 123 - Loss:   460.0171 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 124 - Loss:   354.2201 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 125 - Loss:   425.8245 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 126 - Loss:   500.2089 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 127 - Loss:   288.0388 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 128 - Loss:   426.7065 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 129 - Loss:   269.9735 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 130 - Loss:   311.6550 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 131 - Loss:   216.3484 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 132 - Loss:   321.4887 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 133 - Loss:   281.8652 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 134 - Loss:   601.4197 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 135 - Loss:   368.2609 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 136 - Loss:   348.9837 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 137 - Loss:   348.8346 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 138 - Loss:   317.9651 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 139 - Loss:   401.6476 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 140 - Loss:   420.3536 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 141 - Loss:   527.1108 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 142 - Loss:   371.7719 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 143 - Loss:   215.3003 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 144 - Loss:   278.5873 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 145 - Loss:   274.0049 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 146 - Loss:   288.1034 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 147 - Loss:   213.3371 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 148 - Loss:   334.5242 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 149 - Loss:   462.6047 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 150 - Loss:   436.1137 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 151 - Loss:   382.7204 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 152 - Loss:   366.2945 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 153 - Loss:   157.8759 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 154 - Loss:   198.2931 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 155 - Loss:   433.3678 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 156 - Loss:   599.9264 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 157 - Loss:   323.0538 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 158 - Loss:   419.0306 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 159 - Loss:   434.4804 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 160 - Loss:   491.6855 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 161 - Loss:   303.3129 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 162 - Loss:   525.6147 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 163 - Loss:   535.5867 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 164 - Loss:   469.2793 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 165 - Loss:   268.1769 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 166 - Loss:   262.3560 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 167 - Loss:   312.7372 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 168 - Loss:   339.9106 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 169 - Loss:   335.4367 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 170 - Loss:   290.9078 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 171 - Loss:   351.8881 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 172 - Loss:   298.4867 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 173 - Loss:   256.1237 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 174 - Loss:   381.5500 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 175 - Loss:   384.8283 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 176 - Loss:   457.7728 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 177 - Loss:   333.9589 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 178 - Loss:   423.6574 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 179 - Loss:   371.5589 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 180 - Loss:   404.3554 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 181 - Loss:   293.7955 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 182 - Loss:   215.7610 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 183 - Loss:   280.8253 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 184 - Loss:   516.3715 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 185 - Loss:   324.5125 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 186 - Loss:   368.1888 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 187 - Loss:   384.5483 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 188 - Loss:   507.7461 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 189 - Loss:   335.0221 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 190 - Loss:   310.8036 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 191 - Loss:   165.6969 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 192 - Loss:   172.5560 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 193 - Loss:   294.3213 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 194 - Loss:   212.3891 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 195 - Loss:   349.3560 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 196 - Loss:   375.3823 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 197 - Loss:   243.4384 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 198 - Loss:   229.7421 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 199 - Loss:   325.9954 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 200 - Loss:   271.7969 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 201 - Loss:   394.7466 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 202 - Loss:   377.1856 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 203 - Loss:   334.1014 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 204 - Loss:   478.2696 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 205 - Loss:   284.5795 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 206 - Loss:   354.0778 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 207 - Loss:   363.1580 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 208 - Loss:   421.4329 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 209 - Loss:   393.4029 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 210 - Loss:   650.1265 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 211 - Loss:   373.5329 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 212 - Loss:   447.2609 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 213 - Loss:   160.7181 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 214 - Loss:   343.8924 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 215 - Loss:   505.8997 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 216 - Loss:   382.5522 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 217 - Loss:   275.7901 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 218 - Loss:   287.9662 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 219 - Loss:   473.4543 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 220 - Loss:   300.2486 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 221 - Loss:   312.7872 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 222 - Loss:   130.9721 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 223 - Loss:   319.5333 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 224 - Loss:   467.5679 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 225 - Loss:   191.7116 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 226 - Loss:   293.6052 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 227 - Loss:   222.7074 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 228 - Loss:   287.3002 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 229 - Loss:   358.7592 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 230 - Loss:   194.1870 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 231 - Loss:   515.0357 Validation Accuracy: 0.847656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch 232 - Loss:   384.5540 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 233 - Loss:   332.6804 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 234 - Loss:   500.7583 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 235 - Loss:   254.4253 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 236 - Loss:   195.8636 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 237 - Loss:   467.3762 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 238 - Loss:   335.8312 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 239 - Loss:   272.5854 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 240 - Loss:   315.4634 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 241 - Loss:   489.4300 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 242 - Loss:   205.8216 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 243 - Loss:   388.2153 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 244 - Loss:   292.6017 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 245 - Loss:   279.5955 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 246 - Loss:   329.2382 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 247 - Loss:   355.4177 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 248 - Loss:   367.9439 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 249 - Loss:   632.7668 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 250 - Loss:   295.7353 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 251 - Loss:   353.3753 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 252 - Loss:   188.9624 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 253 - Loss:   271.5203 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 254 - Loss:   480.2982 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 255 - Loss:   286.8503 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 256 - Loss:   414.4534 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 257 - Loss:   402.6666 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 258 - Loss:   357.3474 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 259 - Loss:   505.1248 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 260 - Loss:   273.9583 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 261 - Loss:   415.2146 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 262 - Loss:   235.0153 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 263 - Loss:   534.6025 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 264 - Loss:   390.9505 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 265 - Loss:   387.9861 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 266 - Loss:   565.5298 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 267 - Loss:   416.0017 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 268 - Loss:   350.5446 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 269 - Loss:   517.2083 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 270 - Loss:   136.2259 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 271 - Loss:   267.6747 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 272 - Loss:   302.0474 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 273 - Loss:   346.3837 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 274 - Loss:   528.4160 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 275 - Loss:   292.8950 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 276 - Loss:   368.4885 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 277 - Loss:   448.8232 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 278 - Loss:   266.4287 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 279 - Loss:   242.5332 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 280 - Loss:   249.2653 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 281 - Loss:   296.2595 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 282 - Loss:   426.8907 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 283 - Loss:   218.6938 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 284 - Loss:   303.4737 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 285 - Loss:   399.9873 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 286 - Loss:   378.6190 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 287 - Loss:   309.7741 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 288 - Loss:   345.1874 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 289 - Loss:   285.2338 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 290 - Loss:   585.6657 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 291 - Loss:   404.4486 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 292 - Loss:   409.0889 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 293 - Loss:   400.2366 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 294 - Loss:   307.4592 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 295 - Loss:   372.1646 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 296 - Loss:   240.3030 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 297 - Loss:   434.2697 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 298 - Loss:   410.7116 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 299 - Loss:   430.1908 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 300 - Loss:   346.7936 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 301 - Loss:   329.5208 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 302 - Loss:   356.6279 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 303 - Loss:   381.6972 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 304 - Loss:   315.3940 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 305 - Loss:   320.3725 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 306 - Loss:   336.9398 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 307 - Loss:   430.6738 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 308 - Loss:   493.3013 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 309 - Loss:   486.8834 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 310 - Loss:   361.7144 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 311 - Loss:   517.6741 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 312 - Loss:   419.3057 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 313 - Loss:   303.2686 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 314 - Loss:   384.5869 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 315 - Loss:   482.4602 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 316 - Loss:   325.2204 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 317 - Loss:   294.3751 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 318 - Loss:   378.2200 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 319 - Loss:   228.5110 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 320 - Loss:   347.1458 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 321 - Loss:   381.5664 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 322 - Loss:   523.3989 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 323 - Loss:   345.8406 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 324 - Loss:   383.5980 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 325 - Loss:   269.2585 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 326 - Loss:   301.3863 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 327 - Loss:   160.5988 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 328 - Loss:   467.2739 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 329 - Loss:   266.7663 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 330 - Loss:   261.9200 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 331 - Loss:   237.6732 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 332 - Loss:   329.4275 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 333 - Loss:   284.8090 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 334 - Loss:   288.2217 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 335 - Loss:   345.0425 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 336 - Loss:   274.5918 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 337 - Loss:   294.6290 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 338 - Loss:   341.9588 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 339 - Loss:   408.4349 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 340 - Loss:   203.1150 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 341 - Loss:   344.8866 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 342 - Loss:   509.7603 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 343 - Loss:   329.7228 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 344 - Loss:   338.4507 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 345 - Loss:   337.6718 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 346 - Loss:   181.8212 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 347 - Loss:   429.8450 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 348 - Loss:   447.1062 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 349 - Loss:   401.1145 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 350 - Loss:   368.9304 Validation Accuracy: 0.847656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch 351 - Loss:   551.4600 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 352 - Loss:   345.0399 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 353 - Loss:   288.6309 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 354 - Loss:   344.6901 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 355 - Loss:   385.8202 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 356 - Loss:   460.8354 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 357 - Loss:   272.5352 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 358 - Loss:   230.7794 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 359 - Loss:   386.6497 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 360 - Loss:   432.4469 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 361 - Loss:   232.8109 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 362 - Loss:   413.8914 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 363 - Loss:   329.1949 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 364 - Loss:   285.1351 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 365 - Loss:   432.6309 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 366 - Loss:   380.4729 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 367 - Loss:   325.8693 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 368 - Loss:   483.0431 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 369 - Loss:   540.8698 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 370 - Loss:   414.9601 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 371 - Loss:   340.9471 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 372 - Loss:   262.9734 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 373 - Loss:   350.6433 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 374 - Loss:   404.6483 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 375 - Loss:   328.3192 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 376 - Loss:   397.1237 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 377 - Loss:   326.1783 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 378 - Loss:   236.3916 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 379 - Loss:   414.1497 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 380 - Loss:   304.9800 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 381 - Loss:   260.6989 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 382 - Loss:   251.4770 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 383 - Loss:   225.0445 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 384 - Loss:   321.5163 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 385 - Loss:   293.2710 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 386 - Loss:   401.8102 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 387 - Loss:   342.6576 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 388 - Loss:   428.2914 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 389 - Loss:   416.6464 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 390 - Loss:   358.8801 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 391 - Loss:   323.4535 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 392 - Loss:   365.5538 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 393 - Loss:   415.3298 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 394 - Loss:   376.5254 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 395 - Loss:   370.0574 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 396 - Loss:   201.0842 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 397 - Loss:   167.4100 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 398 - Loss:   356.5761 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 399 - Loss:   355.9463 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 400 - Loss:   207.1375 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 401 - Loss:   585.5195 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 402 - Loss:   193.1232 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 403 - Loss:   392.8876 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 404 - Loss:   237.9645 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 405 - Loss:   377.5142 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 406 - Loss:   244.1901 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 407 - Loss:   270.3355 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 408 - Loss:   256.9346 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 409 - Loss:   403.4482 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 410 - Loss:   264.9626 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 411 - Loss:   342.6583 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch 412 - Loss:   625.8852 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 413 - Loss:   353.8593 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 414 - Loss:   325.4406 Validation Accuracy: 0.832031\n",
      "Epoch  6, Batch 415 - Loss:   356.6865 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 416 - Loss:   370.5256 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 417 - Loss:   390.6129 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 418 - Loss:   338.9784 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 419 - Loss:   343.8576 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 420 - Loss:   477.3969 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 421 - Loss:   351.3386 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 422 - Loss:   226.5093 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 423 - Loss:   325.6046 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 424 - Loss:   261.5568 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 425 - Loss:   364.5326 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 426 - Loss:   528.1682 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 427 - Loss:   181.8538 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 428 - Loss:   500.9366 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 429 - Loss:   258.6162 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   1 - Loss:   292.6285 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   2 - Loss:   338.9971 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch   3 - Loss:   467.2853 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   4 - Loss:   375.9460 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   5 - Loss:   434.8404 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch   6 - Loss:   584.7382 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   7 - Loss:   360.5972 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   8 - Loss:   227.1900 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch   9 - Loss:   274.9624 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  10 - Loss:   274.6709 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  11 - Loss:   208.6919 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  12 - Loss:   273.4343 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  13 - Loss:   256.2560 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  14 - Loss:   381.1902 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  15 - Loss:   415.4915 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  16 - Loss:   272.8602 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  17 - Loss:   305.8779 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  18 - Loss:   420.1790 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  19 - Loss:   431.4853 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  20 - Loss:   399.5002 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  21 - Loss:   391.9476 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  22 - Loss:   419.3376 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  23 - Loss:   235.2877 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  24 - Loss:   232.4808 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  25 - Loss:   255.2013 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  26 - Loss:   381.9265 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  27 - Loss:   357.8376 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  28 - Loss:   353.9026 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  29 - Loss:   442.1349 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  30 - Loss:   314.9662 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  31 - Loss:   344.9631 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  32 - Loss:   452.7518 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  33 - Loss:   405.1792 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  34 - Loss:   246.4903 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  35 - Loss:   315.6356 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  36 - Loss:   320.7762 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  37 - Loss:   320.9949 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  38 - Loss:   153.7520 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  39 - Loss:   261.0856 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  40 - Loss:   342.8138 Validation Accuracy: 0.839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch  41 - Loss:   395.8562 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  42 - Loss:   405.9604 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  43 - Loss:   353.9551 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  44 - Loss:   250.3049 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  45 - Loss:   400.0865 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  46 - Loss:   533.6028 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  47 - Loss:   340.7589 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  48 - Loss:   526.3497 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  49 - Loss:   378.1227 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  50 - Loss:   340.6278 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  51 - Loss:   403.3973 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  52 - Loss:   364.9512 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  53 - Loss:   280.0244 Validation Accuracy: 0.832031\n",
      "Epoch  7, Batch  54 - Loss:   196.9540 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  55 - Loss:   340.9064 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  56 - Loss:   357.3858 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  57 - Loss:   428.9568 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  58 - Loss:   298.7297 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  59 - Loss:   399.8939 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  60 - Loss:   310.1297 Validation Accuracy: 0.832031\n",
      "Epoch  7, Batch  61 - Loss:   258.1258 Validation Accuracy: 0.832031\n",
      "Epoch  7, Batch  62 - Loss:   397.8364 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  63 - Loss:   328.2298 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  64 - Loss:   417.1837 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  65 - Loss:   422.9367 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  66 - Loss:   378.1318 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  67 - Loss:   350.7136 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  68 - Loss:   309.6653 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  69 - Loss:   296.1216 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  70 - Loss:   270.3138 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  71 - Loss:   279.1436 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  72 - Loss:   243.7089 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  73 - Loss:   415.2903 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  74 - Loss:   463.2690 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  75 - Loss:   237.2944 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  76 - Loss:   269.7953 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  77 - Loss:   327.8650 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  78 - Loss:   278.7450 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  79 - Loss:   183.0470 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  80 - Loss:   242.9053 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  81 - Loss:   334.6866 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  82 - Loss:   483.4103 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  83 - Loss:   300.7337 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  84 - Loss:   316.2947 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  85 - Loss:   312.6591 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  86 - Loss:   311.6982 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  87 - Loss:   567.8665 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  88 - Loss:   300.6577 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  89 - Loss:   641.8191 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  90 - Loss:   342.8096 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  91 - Loss:   274.1108 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  92 - Loss:   241.5534 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  93 - Loss:   277.4580 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch  94 - Loss:   198.3996 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  95 - Loss:   331.9375 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch  96 - Loss:   322.6873 Validation Accuracy: 0.832031\n",
      "Epoch  7, Batch  97 - Loss:   155.7676 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  98 - Loss:   424.9661 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  99 - Loss:   297.5126 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 100 - Loss:   183.1336 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 101 - Loss:   229.0503 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 102 - Loss:   333.6350 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 103 - Loss:   444.1594 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 104 - Loss:   258.9887 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 105 - Loss:   291.5798 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 106 - Loss:   345.8605 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 107 - Loss:   316.3336 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 108 - Loss:   302.7541 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 109 - Loss:   396.4750 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 110 - Loss:   214.3949 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 111 - Loss:   298.0073 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 112 - Loss:   396.8790 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 113 - Loss:   375.6757 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 114 - Loss:   345.4639 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 115 - Loss:   290.8524 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 116 - Loss:   256.6115 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 117 - Loss:   381.0246 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 118 - Loss:   349.4970 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 119 - Loss:   414.6765 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 120 - Loss:   274.4434 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 121 - Loss:   320.4305 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 122 - Loss:   271.1918 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 123 - Loss:   335.3023 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 124 - Loss:   274.0955 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 125 - Loss:   307.6152 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 126 - Loss:   399.1742 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 127 - Loss:   251.4744 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 128 - Loss:   252.7076 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 129 - Loss:   155.9157 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 130 - Loss:   267.8099 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 131 - Loss:   231.6609 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 132 - Loss:   182.4467 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 133 - Loss:   293.1396 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 134 - Loss:   207.4378 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 135 - Loss:   241.8932 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 136 - Loss:   356.7238 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 137 - Loss:   290.3267 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 138 - Loss:   294.6432 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 139 - Loss:   244.6401 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 140 - Loss:   241.5074 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 141 - Loss:   392.9867 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 142 - Loss:   368.5464 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 143 - Loss:   273.5559 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 144 - Loss:   282.2556 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 145 - Loss:   390.5545 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 146 - Loss:   348.3022 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 147 - Loss:   479.7101 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 148 - Loss:   187.7898 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 149 - Loss:   277.6124 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 150 - Loss:   172.0600 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 151 - Loss:   287.3621 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 152 - Loss:   344.6956 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 153 - Loss:   152.4564 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 154 - Loss:   405.9365 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 155 - Loss:   375.7571 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 156 - Loss:   290.4516 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 157 - Loss:   267.0598 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 158 - Loss:   278.3255 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 159 - Loss:   356.3804 Validation Accuracy: 0.839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch 160 - Loss:   448.5944 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 161 - Loss:   412.2450 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 162 - Loss:   394.0370 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 163 - Loss:   278.3653 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 164 - Loss:   256.8483 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 165 - Loss:   311.4027 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 166 - Loss:   249.2834 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 167 - Loss:   141.1933 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 168 - Loss:   170.3075 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 169 - Loss:   187.5739 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 170 - Loss:   503.7253 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 171 - Loss:   352.8835 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 172 - Loss:   401.1836 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 173 - Loss:   318.6467 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 174 - Loss:   263.5801 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 175 - Loss:   172.7228 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 176 - Loss:   377.5488 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 177 - Loss:   280.2308 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 178 - Loss:   553.2955 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 179 - Loss:   294.0341 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 180 - Loss:   320.5958 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 181 - Loss:   264.2803 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 182 - Loss:   261.2459 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 183 - Loss:   387.7440 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 184 - Loss:   393.6407 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 185 - Loss:   350.8993 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 186 - Loss:   457.5923 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 187 - Loss:   308.4640 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 188 - Loss:   343.2201 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 189 - Loss:   320.3590 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 190 - Loss:   214.7813 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 191 - Loss:   213.2231 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 192 - Loss:   237.6301 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 193 - Loss:   329.5471 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 194 - Loss:   283.9315 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 195 - Loss:   216.6113 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 196 - Loss:   195.0978 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 197 - Loss:   432.9967 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 198 - Loss:   369.5463 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 199 - Loss:   290.4925 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 200 - Loss:   324.9495 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 201 - Loss:   252.6454 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 202 - Loss:   241.4579 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 203 - Loss:   264.2293 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 204 - Loss:   307.0422 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 205 - Loss:   365.4097 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 206 - Loss:   492.8135 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 207 - Loss:   308.8546 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 208 - Loss:   462.8914 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 209 - Loss:   346.5548 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 210 - Loss:   227.5710 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 211 - Loss:   263.0337 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 212 - Loss:   416.1188 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 213 - Loss:   206.2901 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 214 - Loss:   258.7861 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 215 - Loss:   163.0532 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 216 - Loss:   232.5963 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 217 - Loss:   495.3587 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 218 - Loss:   492.7996 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 219 - Loss:   302.3718 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 220 - Loss:   389.3571 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 221 - Loss:   225.7998 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 222 - Loss:   145.7536 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 223 - Loss:   241.7404 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 224 - Loss:   245.7641 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 225 - Loss:   431.3894 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 226 - Loss:   304.3147 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 227 - Loss:   467.4012 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 228 - Loss:   280.5111 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 229 - Loss:   528.4001 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 230 - Loss:   249.0572 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 231 - Loss:   336.7960 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 232 - Loss:   282.2274 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 233 - Loss:   446.5383 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 234 - Loss:   381.4458 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 235 - Loss:   330.1581 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 236 - Loss:   275.3773 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 237 - Loss:   354.4043 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 238 - Loss:   336.9412 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 239 - Loss:   276.3804 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 240 - Loss:   303.0435 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 241 - Loss:   389.5201 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 242 - Loss:   340.1662 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 243 - Loss:   322.5738 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 244 - Loss:   232.4225 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 245 - Loss:   373.1585 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 246 - Loss:   246.6336 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 247 - Loss:   243.7708 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 248 - Loss:   234.6905 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 249 - Loss:   243.7211 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 250 - Loss:   432.0799 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 251 - Loss:   328.0580 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 252 - Loss:   212.3486 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 253 - Loss:   303.4287 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 254 - Loss:   371.5682 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 255 - Loss:   384.1130 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 256 - Loss:   362.7234 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 257 - Loss:   304.1682 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 258 - Loss:   305.1077 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 259 - Loss:   318.8583 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 260 - Loss:   225.7103 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 261 - Loss:   181.5114 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 262 - Loss:   320.9143 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 263 - Loss:   113.4354 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 264 - Loss:   345.0435 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 265 - Loss:   522.4385 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 266 - Loss:   217.1709 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 267 - Loss:   283.6360 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 268 - Loss:   345.4418 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 269 - Loss:   304.1480 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 270 - Loss:   194.6723 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 271 - Loss:   119.1253 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 272 - Loss:   330.2345 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 273 - Loss:   273.5089 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 274 - Loss:   337.3156 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 275 - Loss:   283.5283 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 276 - Loss:   328.3945 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 277 - Loss:   151.9322 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 278 - Loss:   561.9204 Validation Accuracy: 0.855469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch 279 - Loss:   327.7963 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 280 - Loss:   235.1599 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 281 - Loss:   453.0876 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 282 - Loss:   245.3413 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 283 - Loss:   230.4329 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 284 - Loss:   173.0569 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 285 - Loss:   276.7943 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 286 - Loss:   321.3744 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 287 - Loss:   259.3274 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 288 - Loss:   395.6364 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 289 - Loss:   428.3286 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 290 - Loss:   288.7656 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 291 - Loss:   363.7537 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 292 - Loss:   283.4684 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 293 - Loss:   360.5317 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 294 - Loss:   213.4233 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 295 - Loss:   284.8577 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 296 - Loss:   207.5203 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 297 - Loss:   296.5540 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 298 - Loss:   247.3409 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 299 - Loss:   341.5225 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 300 - Loss:   256.7332 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 301 - Loss:   287.3629 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 302 - Loss:   221.7506 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 303 - Loss:   310.5823 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 304 - Loss:   325.9882 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 305 - Loss:   374.8141 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 306 - Loss:   439.7383 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 307 - Loss:   199.5427 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 308 - Loss:   295.2548 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 309 - Loss:   374.7985 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 310 - Loss:   439.8403 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 311 - Loss:   280.7378 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 312 - Loss:   183.2913 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 313 - Loss:   182.2549 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 314 - Loss:   230.7330 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 315 - Loss:   420.9249 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 316 - Loss:   419.4168 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 317 - Loss:   443.3698 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 318 - Loss:   264.8822 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 319 - Loss:   263.2874 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 320 - Loss:   251.3305 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 321 - Loss:   199.8283 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 322 - Loss:   218.7292 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 323 - Loss:   219.6835 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 324 - Loss:   321.3409 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 325 - Loss:   256.8300 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 326 - Loss:   384.9856 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 327 - Loss:   376.3996 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 328 - Loss:   194.3861 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 329 - Loss:   217.6651 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 330 - Loss:   269.7853 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 331 - Loss:   445.3195 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 332 - Loss:   237.1430 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 333 - Loss:   327.3145 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 334 - Loss:   251.8793 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 335 - Loss:   305.0511 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 336 - Loss:   264.8480 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 337 - Loss:   309.0369 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 338 - Loss:   331.0069 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 339 - Loss:   324.6794 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 340 - Loss:   390.8545 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 341 - Loss:   236.7985 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 342 - Loss:   185.6701 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 343 - Loss:   293.4918 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 344 - Loss:   225.6618 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 345 - Loss:   192.5894 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 346 - Loss:   247.0347 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 347 - Loss:   269.4999 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 348 - Loss:   524.4103 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 349 - Loss:   297.3965 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 350 - Loss:   258.8862 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 351 - Loss:   225.9408 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 352 - Loss:   327.7027 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 353 - Loss:   363.7070 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 354 - Loss:   185.6029 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 355 - Loss:   362.3861 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 356 - Loss:   221.8783 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 357 - Loss:   249.1892 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 358 - Loss:   231.4659 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 359 - Loss:   169.7728 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 360 - Loss:   350.2467 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 361 - Loss:   268.7755 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 362 - Loss:   465.3459 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 363 - Loss:   294.5695 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 364 - Loss:   343.1205 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 365 - Loss:   320.4576 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 366 - Loss:   269.1696 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 367 - Loss:   306.5700 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 368 - Loss:   285.0047 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 369 - Loss:   257.9060 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 370 - Loss:   204.4984 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 371 - Loss:   337.2134 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 372 - Loss:   345.9204 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 373 - Loss:   251.7174 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 374 - Loss:   298.0209 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 375 - Loss:   457.6075 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 376 - Loss:   228.7875 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 377 - Loss:   208.4712 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 378 - Loss:   266.6750 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 379 - Loss:   235.4642 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 380 - Loss:   111.3178 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 381 - Loss:   205.5441 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 382 - Loss:   288.0242 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 383 - Loss:   474.3528 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 384 - Loss:   340.1027 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 385 - Loss:   261.5510 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 386 - Loss:   295.8268 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 387 - Loss:   342.5020 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 388 - Loss:   322.0574 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 389 - Loss:   312.5547 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 390 - Loss:   362.2919 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 391 - Loss:   562.8127 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 392 - Loss:   240.3053 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 393 - Loss:   274.0719 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 394 - Loss:   366.7843 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 395 - Loss:   332.1832 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 396 - Loss:   155.0916 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 397 - Loss:   358.4321 Validation Accuracy: 0.835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7, Batch 398 - Loss:   314.8450 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 399 - Loss:   435.8417 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 400 - Loss:   257.7600 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 401 - Loss:   257.7530 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 402 - Loss:   151.7947 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 403 - Loss:   244.5438 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 404 - Loss:   337.4113 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 405 - Loss:   391.9653 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 406 - Loss:   172.9183 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 407 - Loss:   258.2701 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 408 - Loss:   262.6886 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 409 - Loss:   256.7303 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 410 - Loss:   431.7794 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 411 - Loss:   205.4436 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 412 - Loss:   408.5957 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 413 - Loss:   337.4942 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 414 - Loss:   391.5108 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 415 - Loss:   278.4675 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 416 - Loss:   243.0815 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 417 - Loss:   381.0071 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 418 - Loss:   317.0667 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 419 - Loss:   229.7792 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 420 - Loss:   332.3923 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 421 - Loss:   227.4036 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 422 - Loss:   366.7470 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 423 - Loss:   351.7907 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 424 - Loss:   254.8627 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 425 - Loss:   266.1381 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 426 - Loss:   387.0133 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 427 - Loss:   293.7868 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 428 - Loss:   334.8145 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 429 - Loss:   166.0238 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   1 - Loss:   330.8489 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   2 - Loss:   432.3347 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   3 - Loss:   246.9244 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   4 - Loss:   233.5883 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   5 - Loss:   275.0088 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   6 - Loss:   337.6162 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch   7 - Loss:   113.3470 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch   8 - Loss:   272.2449 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   9 - Loss:   283.4560 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  10 - Loss:   213.2764 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  11 - Loss:   372.4289 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  12 - Loss:   431.2555 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  13 - Loss:   320.9426 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  14 - Loss:   437.1897 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  15 - Loss:   245.6977 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  16 - Loss:   371.6611 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  17 - Loss:   263.2476 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  18 - Loss:   350.1974 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch  19 - Loss:   338.5641 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  20 - Loss:   281.0585 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  21 - Loss:   355.1270 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  22 - Loss:   193.1447 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  23 - Loss:   250.7175 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  24 - Loss:   376.8750 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  25 - Loss:   395.6674 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  26 - Loss:   442.4757 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  27 - Loss:   264.2211 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  28 - Loss:   247.8869 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  29 - Loss:   181.1696 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  30 - Loss:   383.3743 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  31 - Loss:   335.9844 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  32 - Loss:    70.6301 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  33 - Loss:   294.6838 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  34 - Loss:   252.3948 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  35 - Loss:   212.9757 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  36 - Loss:   202.8384 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  37 - Loss:   363.5741 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  38 - Loss:   374.2698 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  39 - Loss:   244.6556 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  40 - Loss:   364.2253 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  41 - Loss:   342.6552 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  42 - Loss:   215.9730 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  43 - Loss:   245.2879 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  44 - Loss:   342.2060 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  45 - Loss:   296.2349 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  46 - Loss:   298.1019 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  47 - Loss:   317.5841 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  48 - Loss:   265.0037 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  49 - Loss:   240.4814 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  50 - Loss:   259.1046 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  51 - Loss:   244.9164 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  52 - Loss:   261.0779 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  53 - Loss:   289.3080 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  54 - Loss:   329.7142 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  55 - Loss:   172.0973 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  56 - Loss:   350.7111 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  57 - Loss:   189.2253 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  58 - Loss:   201.9720 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  59 - Loss:   482.4972 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  60 - Loss:   250.0414 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  61 - Loss:   295.9596 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  62 - Loss:   291.6501 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  63 - Loss:   260.2885 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  64 - Loss:   487.7767 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  65 - Loss:   249.0285 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  66 - Loss:   207.5494 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  67 - Loss:   183.8925 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  68 - Loss:   311.0891 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  69 - Loss:   373.4902 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  70 - Loss:   379.6826 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  71 - Loss:   308.1482 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  72 - Loss:   323.7936 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  73 - Loss:   396.5283 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  74 - Loss:   246.6290 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  75 - Loss:   307.4263 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  76 - Loss:   201.3856 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  77 - Loss:   327.7438 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  78 - Loss:   177.4686 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  79 - Loss:   297.3816 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  80 - Loss:   192.9463 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  81 - Loss:   359.6676 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  82 - Loss:   377.5098 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  83 - Loss:   280.5198 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  84 - Loss:   159.3611 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  85 - Loss:   309.8063 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  86 - Loss:   240.0578 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  87 - Loss:   239.5303 Validation Accuracy: 0.851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch  88 - Loss:   399.8672 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  89 - Loss:   235.6390 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  90 - Loss:   244.3480 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  91 - Loss:   383.7460 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch  92 - Loss:   267.3710 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  93 - Loss:   462.3468 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch  94 - Loss:   316.9354 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  95 - Loss:   290.3187 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch  96 - Loss:   342.2375 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  97 - Loss:   231.3766 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  98 - Loss:   237.3192 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch  99 - Loss:   250.5053 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 100 - Loss:   314.3482 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 101 - Loss:   232.7421 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 102 - Loss:   309.4030 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 103 - Loss:   238.9872 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 104 - Loss:   221.6880 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 105 - Loss:   325.3595 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 106 - Loss:   323.3602 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 107 - Loss:   212.1548 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 108 - Loss:   299.0750 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 109 - Loss:   108.3611 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 110 - Loss:   281.2065 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 111 - Loss:   193.7615 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 112 - Loss:   232.2561 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 113 - Loss:   251.9032 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 114 - Loss:   162.0658 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 115 - Loss:   195.7578 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 116 - Loss:   313.6766 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 117 - Loss:   432.3578 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 118 - Loss:   297.5900 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 119 - Loss:   293.3917 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 120 - Loss:   231.7038 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 121 - Loss:   360.1041 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 122 - Loss:   368.7578 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 123 - Loss:   279.3987 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 124 - Loss:   262.9827 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 125 - Loss:   296.8979 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 126 - Loss:   317.1632 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 127 - Loss:   315.2839 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 128 - Loss:   209.5908 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 129 - Loss:   179.9645 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 130 - Loss:   282.6042 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 131 - Loss:   255.4942 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 132 - Loss:   250.8366 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 133 - Loss:   151.7178 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 134 - Loss:   290.2834 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 135 - Loss:   369.6591 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 136 - Loss:   231.8549 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 137 - Loss:   257.1935 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 138 - Loss:   317.3824 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 139 - Loss:   148.9546 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 140 - Loss:   239.1293 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 141 - Loss:   406.9594 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 142 - Loss:   313.0381 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 143 - Loss:   341.5495 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 144 - Loss:   386.1512 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 145 - Loss:   224.7682 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 146 - Loss:   248.7762 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 147 - Loss:   202.9595 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 148 - Loss:   309.2472 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 149 - Loss:   211.1265 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 150 - Loss:   362.1860 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 151 - Loss:   270.5007 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 152 - Loss:   233.0174 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 153 - Loss:   194.7036 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 154 - Loss:   242.4070 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 155 - Loss:   391.7327 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 156 - Loss:   260.1306 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 157 - Loss:   333.6900 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 158 - Loss:   295.3734 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 159 - Loss:   234.6501 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 160 - Loss:   221.4423 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 161 - Loss:   344.7325 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 162 - Loss:   347.9382 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 163 - Loss:   315.4198 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 164 - Loss:   185.0319 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 165 - Loss:   220.2694 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 166 - Loss:   275.5634 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 167 - Loss:   195.2999 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 168 - Loss:   243.0928 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 169 - Loss:   163.0222 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 170 - Loss:   202.6059 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 171 - Loss:   280.1376 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 172 - Loss:   365.6285 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 173 - Loss:   248.6418 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 174 - Loss:   325.6044 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 175 - Loss:   177.1129 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 176 - Loss:   230.4946 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 177 - Loss:   392.5952 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 178 - Loss:   341.0775 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 179 - Loss:   338.9745 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 180 - Loss:   215.2698 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 181 - Loss:   148.4751 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 182 - Loss:   251.7008 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 183 - Loss:   381.2961 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 184 - Loss:   421.8720 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 185 - Loss:   302.7116 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 186 - Loss:   224.5982 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 187 - Loss:   236.0724 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 188 - Loss:   316.2293 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 189 - Loss:   457.7845 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 190 - Loss:   228.1376 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 191 - Loss:   286.4626 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 192 - Loss:   170.9689 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 193 - Loss:   297.0729 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 194 - Loss:   384.2431 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 195 - Loss:   271.4232 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 196 - Loss:   277.4670 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 197 - Loss:   240.7558 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 198 - Loss:   249.0140 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 199 - Loss:    83.6531 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 200 - Loss:   185.6481 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 201 - Loss:   342.9651 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 202 - Loss:   314.9672 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 203 - Loss:   370.1259 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 204 - Loss:   226.7402 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 205 - Loss:   338.2598 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 206 - Loss:   373.1719 Validation Accuracy: 0.851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch 207 - Loss:   307.4498 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 208 - Loss:   255.7403 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 209 - Loss:   426.6273 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 210 - Loss:   244.1416 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 211 - Loss:   361.3225 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 212 - Loss:   319.8130 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 213 - Loss:   158.6961 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 214 - Loss:   164.3384 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 215 - Loss:   302.2089 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 216 - Loss:   233.8714 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 217 - Loss:   149.5678 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 218 - Loss:   374.9202 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 219 - Loss:   170.8130 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 220 - Loss:   149.6032 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 221 - Loss:   158.7359 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 222 - Loss:   320.3887 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 223 - Loss:   320.1001 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 224 - Loss:   271.8652 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 225 - Loss:   240.3456 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 226 - Loss:   339.8152 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 227 - Loss:   208.4168 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 228 - Loss:   382.8793 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 229 - Loss:   308.4226 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 230 - Loss:   276.4995 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 231 - Loss:   353.3659 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 232 - Loss:   153.5463 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 233 - Loss:   285.3036 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 234 - Loss:   314.6321 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 235 - Loss:   270.6032 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 236 - Loss:   156.2760 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 237 - Loss:   353.8363 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 238 - Loss:   388.9142 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 239 - Loss:   306.1037 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 240 - Loss:   237.5346 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 241 - Loss:   152.2558 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 242 - Loss:   204.7457 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 243 - Loss:   258.4301 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 244 - Loss:   233.5422 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 245 - Loss:   257.5246 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 246 - Loss:   194.6201 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 247 - Loss:   437.1775 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 248 - Loss:   312.2862 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 249 - Loss:    96.8239 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 250 - Loss:   187.6127 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 251 - Loss:   219.2856 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 252 - Loss:   346.4207 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 253 - Loss:   227.4769 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 254 - Loss:   230.1053 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 255 - Loss:   360.0157 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 256 - Loss:   359.1267 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 257 - Loss:   257.9960 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 258 - Loss:   135.6909 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 259 - Loss:   224.8540 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 260 - Loss:   265.8365 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 261 - Loss:   202.1921 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 262 - Loss:   340.4088 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 263 - Loss:   235.1071 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 264 - Loss:   350.5852 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 265 - Loss:   334.1587 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 266 - Loss:   248.1656 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 267 - Loss:   222.5946 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 268 - Loss:   332.1763 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 269 - Loss:   187.6752 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 270 - Loss:   121.0849 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 271 - Loss:   229.8293 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 272 - Loss:   415.2291 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 273 - Loss:   326.6759 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 274 - Loss:   191.5238 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 275 - Loss:   268.0219 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 276 - Loss:   353.3665 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 277 - Loss:   393.5936 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 278 - Loss:   202.1215 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 279 - Loss:   260.1119 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 280 - Loss:   389.3983 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 281 - Loss:   275.3222 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 282 - Loss:   268.0487 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 283 - Loss:   298.1027 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 284 - Loss:   170.5034 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 285 - Loss:   176.0879 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 286 - Loss:   142.2949 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 287 - Loss:   149.8236 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 288 - Loss:   291.7609 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 289 - Loss:   283.7437 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 290 - Loss:   384.7025 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 291 - Loss:   356.6080 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 292 - Loss:   406.6288 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 293 - Loss:   380.3881 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 294 - Loss:   199.8416 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 295 - Loss:   421.2520 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 296 - Loss:   244.9744 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 297 - Loss:   290.4658 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 298 - Loss:   229.7533 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 299 - Loss:   262.8680 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 300 - Loss:   227.6184 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 301 - Loss:   191.0997 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 302 - Loss:   294.4858 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 303 - Loss:   195.2094 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 304 - Loss:   314.9758 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 305 - Loss:   239.9924 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 306 - Loss:   255.9189 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 307 - Loss:   239.9415 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 308 - Loss:   259.3886 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 309 - Loss:   426.1347 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 310 - Loss:   256.8878 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 311 - Loss:   333.7753 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 312 - Loss:   560.8402 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 313 - Loss:   162.6639 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 314 - Loss:   330.8159 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 315 - Loss:   221.2672 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 316 - Loss:   196.8215 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 317 - Loss:   279.9247 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 318 - Loss:   125.6436 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 319 - Loss:   349.3245 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 320 - Loss:   308.4234 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 321 - Loss:   255.9297 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 322 - Loss:   210.5129 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 323 - Loss:   328.6582 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 324 - Loss:   348.8284 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 325 - Loss:   321.4099 Validation Accuracy: 0.851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8, Batch 326 - Loss:   229.3365 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 327 - Loss:   174.1498 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 328 - Loss:   320.9316 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 329 - Loss:   199.3333 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 330 - Loss:   198.9912 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 331 - Loss:   180.5254 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 332 - Loss:   220.7680 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 333 - Loss:   310.4145 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 334 - Loss:   255.4534 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 335 - Loss:   313.0204 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 336 - Loss:   383.8036 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 337 - Loss:   388.2163 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 338 - Loss:   222.3912 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 339 - Loss:   333.6397 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 340 - Loss:   222.0007 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 341 - Loss:   270.9014 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 342 - Loss:   240.5086 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 343 - Loss:   296.3289 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 344 - Loss:   276.1423 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 345 - Loss:   250.0573 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 346 - Loss:   380.9897 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 347 - Loss:    92.4272 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 348 - Loss:   286.0020 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 349 - Loss:   428.7734 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 350 - Loss:   330.4205 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 351 - Loss:   359.1452 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 352 - Loss:   372.9491 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 353 - Loss:   293.5013 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 354 - Loss:   337.6604 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 355 - Loss:   315.6439 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 356 - Loss:   373.2932 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 357 - Loss:   201.0200 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 358 - Loss:   345.9861 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 359 - Loss:   284.1249 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 360 - Loss:   139.3898 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 361 - Loss:   197.1465 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 362 - Loss:   192.1350 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 363 - Loss:   271.3771 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 364 - Loss:   327.2726 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 365 - Loss:   218.4355 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 366 - Loss:   205.2215 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 367 - Loss:   290.1896 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 368 - Loss:   329.9425 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 369 - Loss:   218.4862 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 370 - Loss:   261.0989 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 371 - Loss:   199.5983 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 372 - Loss:   345.1076 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 373 - Loss:   203.2233 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 374 - Loss:   233.3059 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 375 - Loss:   405.0211 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 376 - Loss:   288.5841 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 377 - Loss:   257.1110 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 378 - Loss:   210.8489 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 379 - Loss:    65.9215 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 380 - Loss:   305.8331 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 381 - Loss:   426.3440 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 382 - Loss:   344.8536 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 383 - Loss:   341.8337 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 384 - Loss:   263.8636 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 385 - Loss:   162.2816 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 386 - Loss:   251.9380 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 387 - Loss:   204.3605 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 388 - Loss:   449.2957 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 389 - Loss:   189.9133 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 390 - Loss:   330.0826 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 391 - Loss:   303.6874 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 392 - Loss:   372.3494 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 393 - Loss:   189.8158 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 394 - Loss:   196.6730 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 395 - Loss:   250.4050 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 396 - Loss:   319.4606 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 397 - Loss:   356.4075 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 398 - Loss:   204.2720 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 399 - Loss:   183.4608 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 400 - Loss:   257.3537 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 401 - Loss:   406.3322 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 402 - Loss:   196.3973 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 403 - Loss:   268.3607 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 404 - Loss:   223.6600 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 405 - Loss:   139.7435 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 406 - Loss:   221.5554 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 407 - Loss:   276.5420 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 408 - Loss:   209.9735 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 409 - Loss:   260.9754 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 410 - Loss:   233.5138 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 411 - Loss:   340.7504 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 412 - Loss:   207.8734 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 413 - Loss:   163.5512 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 414 - Loss:   247.2271 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 415 - Loss:   322.0375 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 416 - Loss:   160.8638 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 417 - Loss:   392.8653 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 418 - Loss:   211.1511 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 419 - Loss:   303.4161 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 420 - Loss:   257.7220 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 421 - Loss:   463.6400 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 422 - Loss:   302.3105 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 423 - Loss:   174.1494 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 424 - Loss:   253.8913 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 425 - Loss:   188.9332 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 426 - Loss:   262.8731 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 427 - Loss:   197.3517 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 428 - Loss:   219.5746 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 429 - Loss:   218.2041 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch   1 - Loss:   376.9610 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   2 - Loss:   239.5730 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch   3 - Loss:   175.1970 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch   4 - Loss:   220.1230 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   5 - Loss:   310.2120 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch   6 - Loss:   281.6860 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch   7 - Loss:   214.3281 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   8 - Loss:   360.8045 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   9 - Loss:   227.0630 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  10 - Loss:   254.1339 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  11 - Loss:   142.4413 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  12 - Loss:   164.7620 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  13 - Loss:   459.6829 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  14 - Loss:   210.0715 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  15 - Loss:   265.1275 Validation Accuracy: 0.851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch  16 - Loss:   159.4912 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  17 - Loss:   280.1726 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  18 - Loss:   431.1865 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  19 - Loss:   223.7803 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  20 - Loss:   278.2163 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  21 - Loss:   311.0595 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  22 - Loss:   214.2592 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  23 - Loss:   295.6546 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  24 - Loss:   159.2580 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  25 - Loss:   169.6923 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  26 - Loss:   272.2446 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  27 - Loss:   330.9249 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  28 - Loss:   178.8950 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  29 - Loss:   252.0535 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  30 - Loss:   359.6694 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  31 - Loss:   100.3439 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  32 - Loss:   129.8672 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  33 - Loss:   269.0061 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  34 - Loss:   212.4010 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  35 - Loss:   181.6107 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  36 - Loss:   368.5729 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  37 - Loss:   207.6009 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  38 - Loss:   331.8288 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  39 - Loss:   154.4339 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  40 - Loss:   268.2056 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  41 - Loss:   159.0870 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  42 - Loss:   185.5225 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  43 - Loss:   219.1279 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  44 - Loss:   278.2635 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  45 - Loss:   328.7710 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  46 - Loss:   213.4113 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  47 - Loss:   169.7700 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  48 - Loss:   239.4894 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  49 - Loss:   203.9590 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  50 - Loss:   263.2012 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  51 - Loss:   303.0992 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  52 - Loss:   346.3875 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  53 - Loss:   330.9650 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  54 - Loss:    92.4533 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  55 - Loss:   302.6500 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  56 - Loss:   341.9763 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  57 - Loss:   268.2409 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  58 - Loss:   238.4694 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  59 - Loss:   412.6909 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  60 - Loss:   235.8891 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  61 - Loss:   184.6819 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  62 - Loss:   191.8658 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  63 - Loss:   262.9698 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  64 - Loss:   291.6892 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  65 - Loss:   304.2131 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  66 - Loss:   293.8510 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  67 - Loss:   160.6222 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  68 - Loss:   243.8045 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  69 - Loss:   237.3978 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  70 - Loss:   256.7573 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  71 - Loss:   269.0543 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  72 - Loss:   361.8763 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  73 - Loss:   166.1883 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  74 - Loss:   305.1879 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  75 - Loss:   206.4290 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  76 - Loss:   224.5777 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  77 - Loss:   293.7922 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  78 - Loss:   218.0686 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  79 - Loss:   384.5036 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  80 - Loss:   221.6566 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  81 - Loss:   240.7041 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  82 - Loss:   314.2281 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  83 - Loss:   300.6331 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  84 - Loss:   230.6748 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  85 - Loss:   281.4765 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  86 - Loss:   162.7162 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  87 - Loss:   234.5540 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  88 - Loss:   367.1299 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  89 - Loss:   246.7815 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  90 - Loss:   222.9774 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  91 - Loss:   241.3533 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  92 - Loss:   329.7416 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  93 - Loss:   403.9081 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  94 - Loss:   312.6864 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  95 - Loss:   196.6558 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  96 - Loss:   121.5354 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  97 - Loss:   333.7125 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  98 - Loss:   314.5840 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  99 - Loss:   222.9873 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 100 - Loss:   264.0824 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 101 - Loss:   331.6063 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 102 - Loss:   299.0400 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 103 - Loss:   318.6852 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 104 - Loss:   342.7169 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 105 - Loss:   208.6552 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 106 - Loss:   222.7264 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 107 - Loss:   215.3426 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 108 - Loss:   297.2889 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 109 - Loss:   428.9831 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 110 - Loss:   164.3600 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 111 - Loss:   216.4473 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 112 - Loss:   208.4119 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 113 - Loss:   302.7159 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 114 - Loss:   332.9555 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 115 - Loss:   301.5601 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 116 - Loss:   257.2609 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 117 - Loss:   256.2544 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 118 - Loss:   118.5665 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 119 - Loss:   180.8651 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 120 - Loss:   284.7942 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 121 - Loss:   215.5121 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 122 - Loss:   271.9406 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 123 - Loss:   287.0880 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 124 - Loss:   252.6040 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 125 - Loss:   301.1557 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 126 - Loss:   175.2054 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 127 - Loss:   199.0453 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 128 - Loss:   221.0660 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 129 - Loss:   368.5658 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 130 - Loss:   198.6863 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 131 - Loss:   239.0994 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 132 - Loss:   252.1338 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 133 - Loss:   218.7494 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 134 - Loss:   348.1926 Validation Accuracy: 0.839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch 135 - Loss:   323.8280 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 136 - Loss:   164.6302 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 137 - Loss:   230.0345 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 138 - Loss:   356.3048 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 139 - Loss:   292.8719 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 140 - Loss:   210.5674 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 141 - Loss:   329.1776 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 142 - Loss:   192.3062 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 143 - Loss:   243.6019 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 144 - Loss:   225.0093 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 145 - Loss:   360.7568 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 146 - Loss:   181.2497 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 147 - Loss:   340.4533 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 148 - Loss:   183.4942 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 149 - Loss:   181.5056 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 150 - Loss:   362.6829 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 151 - Loss:   289.1610 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 152 - Loss:   231.6123 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 153 - Loss:   244.9285 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 154 - Loss:   301.4729 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 155 - Loss:   183.7975 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 156 - Loss:   263.8465 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 157 - Loss:   368.8170 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 158 - Loss:   308.5088 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 159 - Loss:   178.7020 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 160 - Loss:   282.5192 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 161 - Loss:   286.6802 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 162 - Loss:   159.0286 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 163 - Loss:   218.0244 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 164 - Loss:   254.9311 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 165 - Loss:   283.1063 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 166 - Loss:   278.7940 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 167 - Loss:   232.2434 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 168 - Loss:   164.6452 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 169 - Loss:   182.5232 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 170 - Loss:   236.2778 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 171 - Loss:   259.7411 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 172 - Loss:   195.9346 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 173 - Loss:   311.7925 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 174 - Loss:   416.4769 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 175 - Loss:   147.3202 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 176 - Loss:   174.1802 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 177 - Loss:   207.3924 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 178 - Loss:   302.9711 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 179 - Loss:   181.1298 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 180 - Loss:   275.6837 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 181 - Loss:   253.7747 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 182 - Loss:   220.2555 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 183 - Loss:   261.4537 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 184 - Loss:   352.3370 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 185 - Loss:   134.8882 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 186 - Loss:   291.9164 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 187 - Loss:   199.8957 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 188 - Loss:   188.4024 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 189 - Loss:   222.3602 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 190 - Loss:   182.2252 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 191 - Loss:   220.6787 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 192 - Loss:   237.9185 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 193 - Loss:   193.7134 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 194 - Loss:   310.0035 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 195 - Loss:   276.4728 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 196 - Loss:   246.7017 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 197 - Loss:   171.9662 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 198 - Loss:   148.6898 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 199 - Loss:   268.6664 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 200 - Loss:   151.1436 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 201 - Loss:   337.2378 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 202 - Loss:   282.1678 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 203 - Loss:   228.0772 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 204 - Loss:   241.6044 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 205 - Loss:   219.7525 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 206 - Loss:   224.6034 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 207 - Loss:   286.9011 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 208 - Loss:   282.0457 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 209 - Loss:   344.9495 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 210 - Loss:   291.7721 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 211 - Loss:   217.5785 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 212 - Loss:   253.6871 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 213 - Loss:   218.1111 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 214 - Loss:   139.7039 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 215 - Loss:   247.1476 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 216 - Loss:   154.9429 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 217 - Loss:   289.6375 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 218 - Loss:   224.4962 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 219 - Loss:   258.8503 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 220 - Loss:   198.2841 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 221 - Loss:   279.8493 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 222 - Loss:   213.2634 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 223 - Loss:   239.4071 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 224 - Loss:   231.0366 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 225 - Loss:   219.4391 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 226 - Loss:   208.8150 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 227 - Loss:   127.3170 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 228 - Loss:   258.5737 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 229 - Loss:   300.6794 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 230 - Loss:   252.7313 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 231 - Loss:   319.3144 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 232 - Loss:   254.3961 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 233 - Loss:    56.7134 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 234 - Loss:   112.4175 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 235 - Loss:   190.7977 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 236 - Loss:   310.9576 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 237 - Loss:   347.5750 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 238 - Loss:   188.5838 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 239 - Loss:   233.5340 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 240 - Loss:   378.9023 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 241 - Loss:   118.2646 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 242 - Loss:   272.0039 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 243 - Loss:   239.0388 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 244 - Loss:   113.4066 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 245 - Loss:   253.3880 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 246 - Loss:   338.8831 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 247 - Loss:   376.8662 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 248 - Loss:   172.4352 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 249 - Loss:   343.6463 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 250 - Loss:   243.6904 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 251 - Loss:   177.3459 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 252 - Loss:   301.6392 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 253 - Loss:   207.0811 Validation Accuracy: 0.835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch 254 - Loss:   427.1846 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 255 - Loss:   401.2687 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 256 - Loss:   294.7639 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 257 - Loss:   278.8843 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 258 - Loss:   343.1645 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 259 - Loss:    45.9215 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 260 - Loss:   172.3329 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 261 - Loss:   219.4222 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 262 - Loss:   207.6068 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 263 - Loss:   214.5562 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 264 - Loss:   228.6439 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 265 - Loss:   228.8332 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 266 - Loss:   213.2115 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 267 - Loss:   300.1365 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 268 - Loss:   385.5266 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 269 - Loss:   350.7335 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 270 - Loss:   209.0257 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 271 - Loss:   174.7025 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 272 - Loss:   278.3807 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 273 - Loss:   167.1411 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 274 - Loss:   203.3252 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 275 - Loss:   179.8551 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 276 - Loss:   290.9199 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 277 - Loss:   326.9722 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 278 - Loss:   315.6321 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 279 - Loss:   160.0829 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 280 - Loss:   111.0646 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 281 - Loss:   319.7138 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 282 - Loss:   191.0147 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 283 - Loss:   268.1455 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 284 - Loss:   289.8756 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 285 - Loss:   240.0679 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 286 - Loss:   207.2050 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 287 - Loss:   251.7844 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 288 - Loss:   283.5527 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 289 - Loss:   145.0915 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 290 - Loss:   199.2979 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 291 - Loss:   344.8359 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 292 - Loss:   233.5057 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 293 - Loss:   171.2728 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 294 - Loss:   241.0020 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 295 - Loss:   260.5664 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 296 - Loss:   270.9821 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 297 - Loss:   269.7485 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 298 - Loss:   405.6761 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 299 - Loss:   116.6167 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 300 - Loss:   258.9610 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 301 - Loss:   224.9880 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 302 - Loss:   308.6531 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 303 - Loss:   224.8675 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 304 - Loss:   185.7799 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 305 - Loss:   173.2326 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 306 - Loss:   254.0281 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 307 - Loss:   218.4916 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 308 - Loss:   327.8382 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 309 - Loss:   325.7198 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 310 - Loss:   249.9738 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 311 - Loss:   285.8530 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 312 - Loss:   222.1496 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 313 - Loss:   182.9985 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 314 - Loss:   307.8587 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 315 - Loss:   105.0017 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 316 - Loss:   304.2757 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 317 - Loss:   176.5866 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 318 - Loss:   206.3677 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 319 - Loss:   340.8762 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 320 - Loss:   186.3103 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 321 - Loss:   201.9357 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 322 - Loss:   617.5910 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 323 - Loss:   271.2387 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 324 - Loss:   151.1138 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 325 - Loss:   289.2241 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 326 - Loss:   173.9243 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 327 - Loss:   272.2181 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 328 - Loss:   183.6142 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 329 - Loss:   232.8522 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 330 - Loss:   205.2693 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 331 - Loss:   250.6046 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 332 - Loss:   138.2699 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 333 - Loss:   175.8665 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 334 - Loss:   213.4596 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 335 - Loss:   327.5397 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 336 - Loss:   303.0580 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 337 - Loss:   180.0576 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 338 - Loss:   171.8420 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 339 - Loss:   300.1099 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 340 - Loss:   293.5404 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 341 - Loss:   208.6206 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 342 - Loss:   284.5517 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 343 - Loss:   195.3555 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 344 - Loss:   161.3540 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 345 - Loss:   236.8597 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 346 - Loss:   153.7939 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 347 - Loss:   219.6614 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 348 - Loss:   170.4358 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 349 - Loss:   244.5184 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 350 - Loss:   215.3209 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 351 - Loss:   216.8306 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 352 - Loss:   314.3333 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 353 - Loss:   379.1502 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 354 - Loss:   255.1370 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 355 - Loss:   312.1816 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 356 - Loss:   242.5829 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 357 - Loss:   279.0750 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 358 - Loss:   462.0947 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 359 - Loss:   385.4274 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 360 - Loss:   204.4418 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 361 - Loss:   239.1826 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 362 - Loss:   179.3625 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 363 - Loss:   233.8622 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 364 - Loss:   337.2137 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 365 - Loss:   300.4221 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 366 - Loss:   197.7279 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 367 - Loss:   297.4245 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 368 - Loss:   278.3976 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 369 - Loss:   226.6103 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 370 - Loss:   145.6640 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 371 - Loss:   199.9383 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 372 - Loss:   276.4966 Validation Accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9, Batch 373 - Loss:   284.7850 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 374 - Loss:   239.9878 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 375 - Loss:   300.4342 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 376 - Loss:   161.1885 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 377 - Loss:   253.6481 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 378 - Loss:   319.4118 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 379 - Loss:   412.0541 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 380 - Loss:   303.7771 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 381 - Loss:   315.6238 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 382 - Loss:   313.6613 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 383 - Loss:   147.2929 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 384 - Loss:   258.0200 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 385 - Loss:   260.1269 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 386 - Loss:   121.5603 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 387 - Loss:   288.9484 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 388 - Loss:   135.8396 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 389 - Loss:   290.1928 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 390 - Loss:   247.3738 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 391 - Loss:   255.0086 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 392 - Loss:   202.7455 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 393 - Loss:   130.9722 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 394 - Loss:   155.3288 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 395 - Loss:   250.1889 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 396 - Loss:   326.4809 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 397 - Loss:   198.6059 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 398 - Loss:   372.9228 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 399 - Loss:   196.2574 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 400 - Loss:   257.8632 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 401 - Loss:   200.4161 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 402 - Loss:   325.6646 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 403 - Loss:   277.3140 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 404 - Loss:   164.0670 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 405 - Loss:   277.6533 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 406 - Loss:   192.0184 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 407 - Loss:   238.9027 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 408 - Loss:   236.7425 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 409 - Loss:    92.3542 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 410 - Loss:   327.8355 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 411 - Loss:   284.6020 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 412 - Loss:   341.4498 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 413 - Loss:   247.4818 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 414 - Loss:   332.3253 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 415 - Loss:   182.5838 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 416 - Loss:   194.0762 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 417 - Loss:   222.1576 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 418 - Loss:   265.0128 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 419 - Loss:   176.6480 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 420 - Loss:   292.3006 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 421 - Loss:   216.3183 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 422 - Loss:   186.3680 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 423 - Loss:   120.4041 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 424 - Loss:   244.5833 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 425 - Loss:   197.0037 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 426 - Loss:   264.3004 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 427 - Loss:   265.0957 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 428 - Loss:   222.1960 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 429 - Loss:   171.2111 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch   1 - Loss:   251.0482 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch   2 - Loss:   228.5571 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch   3 - Loss:   217.3953 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch   4 - Loss:   285.4768 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch   5 - Loss:   266.6120 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch   6 - Loss:   126.5412 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch   7 - Loss:   296.9120 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch   8 - Loss:   370.0806 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch   9 - Loss:   228.9115 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  10 - Loss:   384.7186 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  11 - Loss:   228.3810 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  12 - Loss:   216.2682 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  13 - Loss:   173.4776 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  14 - Loss:   215.1688 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  15 - Loss:   270.2034 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  16 - Loss:   159.8647 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  17 - Loss:   185.5346 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  18 - Loss:   190.3430 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  19 - Loss:   291.4193 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  20 - Loss:   180.1926 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  21 - Loss:   202.0475 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  22 - Loss:   314.4943 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  23 - Loss:   239.5007 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  24 - Loss:   415.8394 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  25 - Loss:   183.2520 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  26 - Loss:   293.5671 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  27 - Loss:   174.0055 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  28 - Loss:   450.2296 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  29 - Loss:   154.8787 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  30 - Loss:   259.7697 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  31 - Loss:   229.5108 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  32 - Loss:   208.0433 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  33 - Loss:   265.1705 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  34 - Loss:   206.4344 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  35 - Loss:   168.4845 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  36 - Loss:   270.9196 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  37 - Loss:   103.2836 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  38 - Loss:   254.4606 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  39 - Loss:   226.9788 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  40 - Loss:   251.5169 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  41 - Loss:   185.3305 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  42 - Loss:   129.8175 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  43 - Loss:   303.3081 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  44 - Loss:   346.5770 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  45 - Loss:   215.7707 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  46 - Loss:   110.6870 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  47 - Loss:   262.9620 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  48 - Loss:   448.3722 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  49 - Loss:   218.2635 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  50 - Loss:   263.0940 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  51 - Loss:   139.4466 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  52 - Loss:   198.3793 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  53 - Loss:   311.2830 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  54 - Loss:   179.1222 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  55 - Loss:   176.9245 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  56 - Loss:   334.9249 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  57 - Loss:   337.2172 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  58 - Loss:   227.8292 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  59 - Loss:   207.7182 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  60 - Loss:   282.5707 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  61 - Loss:   215.1234 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  62 - Loss:   109.4897 Validation Accuracy: 0.843750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch  63 - Loss:   184.8791 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  64 - Loss:   276.8091 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  65 - Loss:   170.9408 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  66 - Loss:   121.3169 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  67 - Loss:   326.8722 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  68 - Loss:   242.5665 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  69 - Loss:   313.8791 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  70 - Loss:   131.7284 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  71 - Loss:   116.7048 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  72 - Loss:   149.1029 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  73 - Loss:   198.1626 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  74 - Loss:   180.6437 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  75 - Loss:   177.5403 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  76 - Loss:   219.5627 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  77 - Loss:   399.8160 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  78 - Loss:   213.6862 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  79 - Loss:    93.8656 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  80 - Loss:   154.2388 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  81 - Loss:   274.7533 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  82 - Loss:   233.8485 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  83 - Loss:   341.0258 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  84 - Loss:   225.2820 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  85 - Loss:   137.0777 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  86 - Loss:   216.8158 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  87 - Loss:   147.4658 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  88 - Loss:   139.6413 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  89 - Loss:   212.0613 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  90 - Loss:   171.7175 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  91 - Loss:   320.1911 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  92 - Loss:   233.4221 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  93 - Loss:   297.1044 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  94 - Loss:   243.8847 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  95 - Loss:   251.2318 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  96 - Loss:   231.7822 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  97 - Loss:   193.2041 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  98 - Loss:   215.1029 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  99 - Loss:   331.0642 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 100 - Loss:   312.0320 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 101 - Loss:    79.4994 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 102 - Loss:   206.9930 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 103 - Loss:   228.8797 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 104 - Loss:   239.9521 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 105 - Loss:   245.3900 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 106 - Loss:   354.1313 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 107 - Loss:   309.7202 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 108 - Loss:   164.6670 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 109 - Loss:   199.2647 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 110 - Loss:   358.2329 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 111 - Loss:   232.7925 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 112 - Loss:   231.3417 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 113 - Loss:   205.2557 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 114 - Loss:   164.5082 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 115 - Loss:   305.8320 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 116 - Loss:   305.4694 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 117 - Loss:   165.3183 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 118 - Loss:   134.7345 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 119 - Loss:   294.7950 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 120 - Loss:   162.7649 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 121 - Loss:   174.5440 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 122 - Loss:   197.3868 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 123 - Loss:   253.2328 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 124 - Loss:   205.0582 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 125 - Loss:   116.8989 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 126 - Loss:   547.6431 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 127 - Loss:   159.4746 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 128 - Loss:   207.6971 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 129 - Loss:   174.2739 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 130 - Loss:   291.8047 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 131 - Loss:   157.1533 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 132 - Loss:   320.9347 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 133 - Loss:   189.3876 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 134 - Loss:   219.3576 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 135 - Loss:   132.0292 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 136 - Loss:   225.1020 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 137 - Loss:   207.7288 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 138 - Loss:   167.6885 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 139 - Loss:   305.3541 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 140 - Loss:   307.5878 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 141 - Loss:   350.6789 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 142 - Loss:   303.9789 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 143 - Loss:   293.8380 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 144 - Loss:   231.0734 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 145 - Loss:   258.9487 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 146 - Loss:   369.1694 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 147 - Loss:   257.1932 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 148 - Loss:   250.1107 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 149 - Loss:   101.3984 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 150 - Loss:   252.1361 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 151 - Loss:   142.1187 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 152 - Loss:   302.1381 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 153 - Loss:   157.9205 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 154 - Loss:   279.4402 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 155 - Loss:   255.1029 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 156 - Loss:   240.3894 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 157 - Loss:   278.9388 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 158 - Loss:   271.4974 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 159 - Loss:   107.5139 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 160 - Loss:   235.3898 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 161 - Loss:   148.1413 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 162 - Loss:   257.5089 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 163 - Loss:   179.7437 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 164 - Loss:   234.1735 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 165 - Loss:   235.3065 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 166 - Loss:   128.7092 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 167 - Loss:   201.6371 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 168 - Loss:   202.7547 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 169 - Loss:   314.8815 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 170 - Loss:   172.5421 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 171 - Loss:   246.3328 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 172 - Loss:   103.3768 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 173 - Loss:   272.4230 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 174 - Loss:   183.5876 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 175 - Loss:   241.9889 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 176 - Loss:   372.6820 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 177 - Loss:   239.8703 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 178 - Loss:   368.3304 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 179 - Loss:   221.5403 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 180 - Loss:   184.7201 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 181 - Loss:   297.6601 Validation Accuracy: 0.832031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 182 - Loss:   199.5548 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 183 - Loss:   214.7185 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 184 - Loss:   196.7523 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 185 - Loss:   320.5714 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 186 - Loss:   355.1827 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 187 - Loss:   111.4176 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 188 - Loss:   181.3265 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 189 - Loss:   247.8883 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 190 - Loss:   192.8175 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 191 - Loss:   158.0123 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 192 - Loss:   152.8733 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 193 - Loss:   333.6830 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 194 - Loss:   283.4893 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 195 - Loss:   250.2013 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 196 - Loss:    82.2912 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 197 - Loss:   209.5570 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 198 - Loss:   314.8899 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 199 - Loss:   225.4811 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 200 - Loss:   363.6177 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 201 - Loss:   203.3422 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 202 - Loss:   161.8706 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 203 - Loss:   239.0209 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 204 - Loss:   219.1082 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 205 - Loss:   163.8999 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 206 - Loss:   143.5102 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 207 - Loss:   277.1283 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 208 - Loss:   261.5461 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 209 - Loss:   197.0338 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 210 - Loss:   201.9002 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 211 - Loss:   310.5284 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 212 - Loss:   216.6125 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 213 - Loss:   251.6582 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 214 - Loss:   200.3662 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 215 - Loss:   179.0925 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 216 - Loss:   192.4519 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 217 - Loss:   222.6098 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 218 - Loss:   173.4278 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 219 - Loss:   280.3548 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 220 - Loss:   359.7136 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 221 - Loss:   145.6350 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 222 - Loss:   145.6008 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 223 - Loss:   281.2656 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 224 - Loss:   223.8092 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 225 - Loss:   225.0298 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 226 - Loss:   218.8898 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 227 - Loss:   207.7973 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 228 - Loss:   222.4000 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 229 - Loss:   139.5285 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 230 - Loss:   281.5689 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 231 - Loss:   272.8702 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 232 - Loss:   274.4065 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 233 - Loss:   253.5345 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 234 - Loss:   244.5930 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 235 - Loss:   309.2068 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 236 - Loss:   165.8681 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 237 - Loss:   253.1355 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 238 - Loss:   187.5463 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 239 - Loss:   118.9053 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 240 - Loss:   187.5464 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 241 - Loss:   268.1484 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 242 - Loss:   264.3326 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 243 - Loss:   222.8092 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 244 - Loss:   139.4348 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 245 - Loss:   159.5227 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 246 - Loss:   236.4565 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 247 - Loss:   204.1336 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 248 - Loss:   159.9632 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 249 - Loss:   421.2136 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 250 - Loss:   286.8538 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 251 - Loss:   271.3446 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 252 - Loss:   173.5112 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 253 - Loss:   323.6042 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 254 - Loss:   255.5703 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 255 - Loss:   247.6726 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 256 - Loss:   128.9382 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 257 - Loss:   189.6090 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 258 - Loss:   248.6584 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 259 - Loss:   209.8892 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 260 - Loss:   191.5404 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 261 - Loss:   183.4282 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 262 - Loss:   275.2362 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 263 - Loss:   154.3456 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 264 - Loss:   164.1205 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 265 - Loss:   151.4891 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 266 - Loss:   161.6614 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 267 - Loss:   244.1390 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 268 - Loss:   231.6132 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 269 - Loss:   172.3172 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 270 - Loss:   278.6530 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 271 - Loss:   281.2275 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 272 - Loss:   260.6235 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 273 - Loss:   162.7697 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 274 - Loss:   192.3079 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 275 - Loss:   215.2676 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 276 - Loss:   200.5933 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 277 - Loss:   251.1071 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 278 - Loss:   254.1072 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 279 - Loss:   170.4762 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 280 - Loss:   225.4472 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 281 - Loss:   326.0268 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 282 - Loss:   193.3464 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 283 - Loss:   138.0888 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 284 - Loss:   218.3962 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 285 - Loss:   186.3538 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 286 - Loss:   256.9830 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 287 - Loss:   228.6927 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 288 - Loss:   164.0456 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 289 - Loss:   348.7422 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 290 - Loss:   251.2200 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 291 - Loss:   314.4505 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 292 - Loss:   105.3721 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 293 - Loss:   202.9925 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 294 - Loss:   116.4700 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 295 - Loss:   200.3416 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 296 - Loss:   237.4305 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 297 - Loss:   175.8238 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 298 - Loss:   268.8852 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 299 - Loss:   182.5253 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 300 - Loss:   314.5014 Validation Accuracy: 0.843750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 301 - Loss:   182.7169 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 302 - Loss:   137.4120 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 303 - Loss:   145.5731 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 304 - Loss:   166.7135 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 305 - Loss:   138.6474 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 306 - Loss:   240.4493 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 307 - Loss:   135.0242 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 308 - Loss:   349.9445 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 309 - Loss:   293.2075 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 310 - Loss:   320.1349 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 311 - Loss:   278.1601 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 312 - Loss:   226.8885 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 313 - Loss:   125.5888 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 314 - Loss:   164.3333 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 315 - Loss:   322.4858 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 316 - Loss:   134.2345 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 317 - Loss:   196.1244 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 318 - Loss:   201.9369 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 319 - Loss:   268.2403 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 320 - Loss:   202.9636 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 321 - Loss:   168.1723 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 322 - Loss:   183.0497 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 323 - Loss:   257.5858 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 324 - Loss:   303.9427 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 325 - Loss:   211.5122 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 326 - Loss:   232.5665 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 327 - Loss:   312.2742 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 328 - Loss:   309.0137 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 329 - Loss:   261.3452 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 330 - Loss:   197.3438 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 331 - Loss:   165.9542 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 332 - Loss:   347.7283 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 333 - Loss:   237.0736 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 334 - Loss:   195.1567 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 335 - Loss:   407.0327 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 336 - Loss:   210.6628 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 337 - Loss:   245.1992 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 338 - Loss:   157.6671 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 339 - Loss:   151.7280 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 340 - Loss:   220.7930 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 341 - Loss:   295.7153 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 342 - Loss:   198.8551 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 343 - Loss:   349.9739 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 344 - Loss:   205.0624 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 345 - Loss:   174.8456 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 346 - Loss:   209.1213 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 347 - Loss:   275.8068 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 348 - Loss:   143.2803 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 349 - Loss:   182.9113 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 350 - Loss:   203.6896 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 351 - Loss:   293.5036 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 352 - Loss:   296.0613 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 353 - Loss:   224.3917 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 354 - Loss:   264.7113 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 355 - Loss:   302.4610 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 356 - Loss:   209.1642 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 357 - Loss:   221.3571 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 358 - Loss:   193.6823 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 359 - Loss:   349.6797 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 360 - Loss:   384.4474 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 361 - Loss:   364.7785 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 362 - Loss:   288.6804 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 363 - Loss:   211.6133 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 364 - Loss:   132.3886 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 365 - Loss:   217.9769 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 366 - Loss:    96.5555 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 367 - Loss:   357.9828 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 368 - Loss:   158.4993 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 369 - Loss:   153.9028 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 370 - Loss:   227.9063 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 371 - Loss:   222.8600 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 372 - Loss:   248.9981 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 373 - Loss:   253.8564 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 374 - Loss:   145.6530 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 375 - Loss:   293.0500 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 376 - Loss:   118.3565 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 377 - Loss:   188.9600 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 378 - Loss:   287.2777 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 379 - Loss:   117.8803 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 380 - Loss:   266.7461 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 381 - Loss:   168.6394 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 382 - Loss:   246.9660 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 383 - Loss:   189.4159 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 384 - Loss:   290.1141 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 385 - Loss:   166.3161 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 386 - Loss:   102.7262 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 387 - Loss:   258.4871 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 388 - Loss:   390.9883 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 389 - Loss:   217.8523 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 390 - Loss:   277.3853 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 391 - Loss:   264.6498 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 392 - Loss:   216.3858 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 393 - Loss:   129.2454 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 394 - Loss:   160.6223 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 395 - Loss:   213.1272 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 396 - Loss:   232.0051 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 397 - Loss:   218.6948 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 398 - Loss:   213.5020 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 399 - Loss:   256.4308 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 400 - Loss:   161.1821 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 401 - Loss:   138.3145 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 402 - Loss:   185.7429 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 403 - Loss:   125.1138 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 404 - Loss:   276.7426 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 405 - Loss:   253.9249 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 406 - Loss:   123.8576 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 407 - Loss:   182.5658 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 408 - Loss:   139.3744 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 409 - Loss:   161.3170 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 410 - Loss:   286.8034 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 411 - Loss:   189.9801 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 412 - Loss:   217.6041 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 413 - Loss:   156.8797 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 414 - Loss:   157.9703 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 415 - Loss:   246.9149 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 416 - Loss:   191.3954 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 417 - Loss:    80.8238 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 418 - Loss:   170.0746 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 419 - Loss:   272.9395 Validation Accuracy: 0.843750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 420 - Loss:   167.1504 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 421 - Loss:   393.8227 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 422 - Loss:   233.3181 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 423 - Loss:   266.0900 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 424 - Loss:   195.6492 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 425 - Loss:   186.8279 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 426 - Loss:   235.1970 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 427 - Loss:   243.5236 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 428 - Loss:   242.8977 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 429 - Loss:   210.2206 Validation Accuracy: 0.843750\n",
      "Testing Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#data\n",
    "#mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
